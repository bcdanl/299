[
  {
    "objectID": "listing-danl-299-lec.html",
    "href": "listing-danl-299-lec.html",
    "title": "DANL 299 - Lecture",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nLecture 1\n\n\nSyllabus and Course Outline\n\n\nAugust 25, 2025\n\n\n\n\nLecture 2\n\n\nPrologue; DANL Tools; Building a Website; Markdown\n\n\nAugust 27, 2025\n\n\n\n\nLecture 3\n\n\nGetting Started with Jupyter Notebook and Quarto\n\n\nSeptember 4, 2025\n\n\n\n\nLecture 4\n\n\nPy Basics - Variables, Data Types, Operators, Casting, Containers\n\n\nSeptember 8, 2025\n\n\n\n\nLecture 5\n\n\nPy Basics - if-else; Slicing; Functions; while & for; List & Dict; try-except\n\n\nSeptember 10, 2025\n\n\n\n\nLecture 6\n\n\npandas - Loading Data\n\n\nSeptember 17, 2025\n\n\n\n\nLecture 7\n\n\npandas - Getting a Data Summary; Selecting Variables; Counting\n\n\nSeptember 22, 2025\n\n\n\n\nLecture 8\n\n\npandas - Sorting Methods; Setting a New Index; Locating Observations/Values\n\n\nSeptember 24, 2025\n\n\n\n\nLecture 9\n\n\npandas - Adding, Removing, & Renaming Variables; Data Types\n\n\nSeptember 29, 2025\n\n\n\n\nLecture 10\n\n\npandas - Filtering by a Condition\n\n\nOctober 1, 2025\n\n\n\n\nLecture 11\n\n\npandas - Missing Values; Duplicates\n\n\nOctober 2, 2025\n\n\n\n\nLecture 12\n\n\npandas - Reshaping DataFrames\n\n\nOctober 6, 2025\n\n\n\n\nLecture 13\n\n\npandas - Joining DataFrames; Concatenating DataFrames\n\n\nOctober 8, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html",
    "href": "danl-hw/danl-299-hw-02.html",
    "title": "Homework 2",
    "section": "",
    "text": "import pandas as pd\nfrom itables import init_notebook_mode, show # for displaying an interactive DataFrame"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#variable-description",
    "href": "danl-hw/danl-299-hw-02.html#variable-description",
    "title": "Homework 2",
    "section": "Variable Description",
    "text": "Variable Description\n\nFiscal_Year: Fiscal Year;\nPayroll_Number: Payroll Number;\nAgency_Name: The Payroll agency that the employee works for;\nLast_Name: Last name of employee;\nFirst_Name: First name of employee;\nMid_Init: Middle initial of employee;\nAgency_Start_Date: Date which employee began working for their current agency;\nWork_Location_Borough: Borough of employee’s primary work location;\nTitle_Description: Civil service title description of the employee;\nLeave_Status_as_of_June_30: Status of employee as of the close of the relevant fiscal year;\nBase_Salary: Base Salary assigned to the employee;\nPay_Basis: Lists whether the employee is paid on an hourly, per diem or annual basis;\nRegular_Hours: Number of regular hours employee worked in the fiscal year;\nRegular_Gross_Paid: The amount paid to the employee for base salary during the fiscal year;\nOT_Hours: Overtime Hours worked by employee in the fiscal year;\nTotal_OT_Paid: Total overtime pay paid to the employee in the fiscal year;\nTotal_Other_Pay: Includes any compensation in addition to gross salary and overtime pay, ie Differentials, lump sums, uniform allowance, meal allowance, retroactive pay increases, settlement amounts, and bonus pay, if applicable."
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-1",
    "href": "danl-hw/danl-299-hw-02.html#question-1",
    "title": "Homework 2",
    "section": "Question 1",
    "text": "Question 1\nSelect “First_Name”, “Last_Name”, “Base_Salary”, and “Total_OT_Paid”, then sort the DataFrame with these selected variables by “Base_Salary” in descending order and display the top 10 entries.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-2",
    "href": "danl-hw/danl-299-hw-02.html#question-2",
    "title": "Homework 2",
    "section": "Question 2",
    "text": "Question 2\nUsing set_index(), change the DataFrame’s index to “Last_Name”, then locate the data for a specific last name, say “BROWN”, and display their “Agency_Name”, “Base_Salary”, and “Total_OT_Paid”.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-3",
    "href": "danl-hw/danl-299-hw-02.html#question-3",
    "title": "Homework 2",
    "section": "Question 3",
    "text": "Question 3\nFind the 5 employees with the highest “Regular_Gross_Paid” and calculate their average “OT_Hours”. Also, reset the index if you have changed it previously.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-4",
    "href": "danl-hw/danl-299-hw-02.html#question-4",
    "title": "Homework 2",
    "section": "Question 4",
    "text": "Question 4\nSort the DataFrame by “Fiscal_Year” and “Total_Other_Pay” in descending order, then set “First_Name” as the index and use the loc accessor to retrieve the “Total_Other_Pay” for a specific first name, say “MICHAEL”.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-5",
    "href": "danl-hw/danl-299-hw-02.html#question-5",
    "title": "Homework 2",
    "section": "Question 5",
    "text": "Question 5\nSort the DataFrame first by “Work_Location_Borough” alphabetically, and then by “Total_Compensation” (sum of “Base_Salary” and “Total_OT_Paid”) in descending order within each borough.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-6",
    "href": "danl-hw/danl-299-hw-02.html#question-6",
    "title": "Homework 2",
    "section": "Question 6",
    "text": "Question 6\n\nSelect employees who have “OT_Hours” greater than 0, calculate their “OT_Rate” (“Total_OT_Paid” / “OT_Hours”), and then find the employee with the highest “OT_Rate”. Display their full name and “OT_Rate”.\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-7",
    "href": "danl-hw/danl-299-hw-02.html#question-7",
    "title": "Homework 2",
    "section": "Question 7",
    "text": "Question 7\nCreate a new DataFrame that includes employees from the “DEPARTMENT OF EDUCATION ADMIN” agency where the variables are “First_Name”, “Last_Name”, “Title_Description”, “Base_Salary”, and “Total_OT_Paid”. Additionally, include a new variable “Total_Compensation” which is the sum of “Base_Salary” and “Total_OT_Paid”.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-8",
    "href": "danl-hw/danl-299-hw-02.html#question-8",
    "title": "Homework 2",
    "section": "Question 8",
    "text": "Question 8\n\nHow many employees have a “Base_Salary” within the top 10% of the DataFrame?\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-9",
    "href": "danl-hw/danl-299-hw-02.html#question-9",
    "title": "Homework 2",
    "section": "Question 9",
    "text": "Question 9\nFilter the DataFrame for employees who have “OT_Hours” greater than 0 but less than 100, and their “Leave_Status_as_of_June_30” is “ACTIVE”.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-10",
    "href": "danl-hw/danl-299-hw-02.html#question-10",
    "title": "Homework 2",
    "section": "Question 10",
    "text": "Question 10\nFind the unique job titles in the “DEPARTMENT OF EDUCATION ADMIN” agency and count how many there are.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-11",
    "href": "danl-hw/danl-299-hw-02.html#question-11",
    "title": "Homework 2",
    "section": "Question 11",
    "text": "Question 11\n\nIdentify the employee(s) with the highest “Total_OT_Paid” in the DataFrame.\n\nInclude their “First_Name”, “Last_Name”, and “Total_OT_Paid”.\n\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-12",
    "href": "danl-hw/danl-299-hw-02.html#question-12",
    "title": "Homework 2",
    "section": "Question 12",
    "text": "Question 12\n\nWhat percentage of the values is missing for each variable?\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-13",
    "href": "danl-hw/danl-299-hw-02.html#question-13",
    "title": "Homework 2",
    "section": "Question 13",
    "text": "Question 13\n\nFill missing values in the “Last_Name” variable with “UNKNOWN”.\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#variable-description-1",
    "href": "danl-hw/danl-299-hw-02.html#variable-description-1",
    "title": "Homework 2",
    "section": "Variable description",
    "text": "Variable description\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nweek: Season week.\nposteam: String abbreviation for the team with possession.\nqtr: Quarter of the game (5 is overtime).\nhalf_seconds_remaining: Numeric seconds remaining in the half.\ndown: The down for the given play.\n\nBasically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it).\nIf you make 10 yards then you get another set of four downs.\n\npass: Binary indicator if the play was a pass play.\nwp: Estimated winning probability for the posteam given the current situation at the start of the given play."
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-14",
    "href": "danl-hw/danl-299-hw-02.html#question-14",
    "title": "Homework 2",
    "section": "Question 14",
    "text": "Question 14\nIn DataFrame, NFL2022_stuffs, remove observations for which the value of posteam is missing.\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-15",
    "href": "danl-hw/danl-299-hw-02.html#question-15",
    "title": "Homework 2",
    "section": "Question 15",
    "text": "Question 15\n\nCalculate the mean value of pass for the BUF posteam when all the following conditions hold:\n\nwp is greater than 20% and less than 75%;\ndown is less than or equal to 2; and\nhalf_seconds_remaining is greater than 120.\n\n\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-16",
    "href": "danl-hw/danl-299-hw-02.html#question-16",
    "title": "Homework 2",
    "section": "Question 16",
    "text": "Question 16\n\nConsider the following DataFrame, NFL2022_epa:\n\n\nNFL2022_epa = pd.read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n\n\n\n\n  \n\n\n\n\nVariable Description for NFL2022_epa\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks)\nreceiver: Name of the receiver.\nepa: Expected points added (EPA) by the posteam for the given play.\n\n\n\nCreate the following DataFrame, NFL2022_stuffs_EPA, that includes\n\nAll the variables and the observations in the DataFrame, NFL2022_stuffs;\nThe variables, passer, receiver, and epa, from the DataFrame, NFL2022_epa by joining the two DataFrames.\n\nIn the resulting DataFrame, NFL2022_stuffs_EPA, please remove observations with NaN in passer after the join.\n\n\n\n\n\n\n\n\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#variable-description-2",
    "href": "danl-hw/danl-299-hw-02.html#variable-description-2",
    "title": "Homework 2",
    "section": "Variable Description",
    "text": "Variable Description\n\n\n\n\n\n\n\n\nvariable\ntype\ndescription\n\n\n\n\nName\nstring\nName of the Trash Wheel\n\n\nDumpster\ninteger\nDumpster number over time; The Trash Wheel can have multiple dumpsters in a day\n\n\nMonth\nstring\nMonth\n\n\nYear\ninteger\nYear\n\n\nDate\nstring\nDate (Daily)\n\n\nWeight\nfloat\nWeight in tons\n\n\nVolume\ninteger\nVolume in cubic yards\n\n\nPlasticBottles\nfloat\nNumber of plastic bottles\n\n\nPolystyrene\nfloat\nNumber of polystyrene items\n\n\nCigaretteButts\nfloat\nNumber of cigarette butts\n\n\nGlassBottles\nfloat\nNumber of glass bottles\n\n\nPlasticBags\nfloat\nNumber of plastic bags\n\n\nWrappers\nfloat\nNumber of wrappers\n\n\nSportsBalls\nfloat\nNumber of sports balls\n\n\nHomesPowered\ninteger\nHomes Powered - Each ton of trash equates to on average 500 kilowatts of electricity. An average household will use 30 kilowatts per day."
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#meet-the-mr.-trash-wheel-family",
    "href": "danl-hw/danl-299-hw-02.html#meet-the-mr.-trash-wheel-family",
    "title": "Homework 2",
    "section": "Meet the Mr. Trash Wheel Family",
    "text": "Meet the Mr. Trash Wheel Family\n\n\n\n\n\n\nMister Trash Wheel\n\n\n\n\nInstalled: May 9, 2014\nLocation: Jones Falls stream, Inner Harbor, Baltimore, MD\n\n\n\n\n\n\n\n\nProfessor Trash Wheel\n\n\n\n\nInstalled: December 4, 2016\nLocation: Harris Creek, Canton neighborhood, Baltimore, MD\n\n\n\n\n\n\n\n\nCaptain Trash Wheel\n\n\n\n\n\nInstalled: June 5, 2018\nLocation: Masonville Cove, Baltimore, MD\n\n\n\n\n\n\n\n\nGwynnda Trash Wheel\n\n\n\n\n\nInstalled: June 3, 2021\nLocation: Gwynns Falls, West Baltimore, MD"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#question-17",
    "href": "danl-hw/danl-299-hw-02.html#question-17",
    "title": "Homework 2",
    "section": "Question 17",
    "text": "Question 17\n\nReshape the trashwheel DataFrame into a DataFrame called trashwheel_long that includes variables for “Name”, “Date”, “Dumpster”, “Trash_Type”, and “Number”.\n\nThe “Trash_Type” variable should indicate the type of trash from the original DataFrame, and “Number” should contain the corresponding values.\nFinally, sort trashwheel_long by “Name”, “Date”, “Dumpster”, and “Trash_Type” in ascending order.\nThe following displays the trashwheel_long DataFrame:\n\n\n\n\n\n\n\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-299-hw-02.html#variable-description-3",
    "href": "danl-hw/danl-299-hw-02.html#variable-description-3",
    "title": "Homework 2",
    "section": "Variable Description",
    "text": "Variable Description\n\npid: playlist ID; unique ID for playlist\nplaylist_name: a name of playlist\npos: a position of the track within a playlist (starting from 0)\nartist_name: name of the track’s primary artist\ntrack_name: name of the track\nduration_ms: duration of the track in milliseconds\nalbum_name: name of the track’s album\n\n\n\nWrite a blog post about your favorite artist(s) in the spotify DataFrame using Jupyter Notebook, and add it to your online blog.\n\nIn your blog post, utilize counting, sorting, indexing, and filtering methods."
  },
  {
    "objectID": "listing-danl-299-wk.html",
    "href": "listing-danl-299-wk.html",
    "title": "Weeks",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-wk/wk-05.html",
    "href": "danl-wk/wk-05.html",
    "title": "Week 5",
    "section": "",
    "text": "In Week 5, we’ll continue to discuss Pandas basics."
  },
  {
    "objectID": "danl-wk/wk-05.html#lecture-slides",
    "href": "danl-wk/wk-05.html#lecture-slides",
    "title": "Week 5",
    "section": "🏫 Lecture Slides",
    "text": "🏫 Lecture Slides\n\nLecture 7 — Getting a Data Summary; Selecting Variables; Counting\nView Slides\nLecture 8 - Sorting Methods; Setting a New Index; Locating Observations/Values\nView Slides\nLecture 9 - Adding, Removing, & Renaming Variables; Data Types\nView Slides\n\n🎥 Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-05.html#classwork",
    "href": "danl-wk/wk-05.html#classwork",
    "title": "Week 5",
    "section": "✍️ Classwork",
    "text": "✍️ Classwork\n\nClasswork 4 - Python Basics\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-05.html#discussion",
    "href": "danl-wk/wk-05.html#discussion",
    "title": "Week 5",
    "section": "💬 Discussion",
    "text": "💬 Discussion\nWelcome to our Week 5 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 5.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 5 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-02.html",
    "href": "danl-wk/wk-02.html",
    "title": "Week 2",
    "section": "",
    "text": "In our second week, we will explore Jupyter Notebook and Quarto, along with website management and web communication."
  },
  {
    "objectID": "danl-wk/wk-02.html#lecture-slides",
    "href": "danl-wk/wk-02.html#lecture-slides",
    "title": "Week 2",
    "section": "🏫 Lecture Slides",
    "text": "🏫 Lecture Slides\nEither click on the slide area below or click here to view it in fullscreen.\n\n\n\n\n🎥 Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-02.html#classwork",
    "href": "danl-wk/wk-02.html#classwork",
    "title": "Week 2",
    "section": "✍️ Classwork",
    "text": "✍️ Classwork\n🚧 Please complete Classwork 2 and Classwork 2 to practice using Markdown and to manage your personal website for web communication."
  },
  {
    "objectID": "danl-wk/wk-02.html#recommended-reading",
    "href": "danl-wk/wk-02.html#recommended-reading",
    "title": "Week 2",
    "section": "📚 Recommended Reading",
    "text": "📚 Recommended Reading\n\nCheck the end of slides for the list of references cited in the lecture."
  },
  {
    "objectID": "danl-wk/wk-02.html#discussion",
    "href": "danl-wk/wk-02.html#discussion",
    "title": "Week 2",
    "section": "💬 Discussion",
    "text": "💬 Discussion\nWelcome to our Week 2 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 2.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 2 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-01.html",
    "href": "danl-wk/wk-01.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to DANL 299! 👋\nIn this first week, we will explore what you can expect to learn in this course and review the logistics, including the structure of lectures, classes, and assessments, as well as how we will interact throughout the semester. This week also introduces the framework for building and managing a personal website for data analytics."
  },
  {
    "objectID": "danl-wk/wk-01.html#lecture-slides",
    "href": "danl-wk/wk-01.html#lecture-slides",
    "title": "Week 1",
    "section": "🏫 Lecture Slides",
    "text": "🏫 Lecture Slides\n\nSyllabus\nEither click on the slide area below or click here to view it in fullscreen.\n\n\n\n\n\n\nIntroduction and DANL tools\nEither click on the slide area below or click here to view it in fullscreen.\n\n\n\n\n🎥 Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-01.html#classwork",
    "href": "danl-wk/wk-01.html#classwork",
    "title": "Week 1",
    "section": "✍️ Classwork",
    "text": "✍️ Classwork\n🚧 Please complete Classwork 1 to practice building and working with a personal website hosted on GitHub."
  },
  {
    "objectID": "danl-wk/wk-01.html#recommended-reading",
    "href": "danl-wk/wk-01.html#recommended-reading",
    "title": "Week 1",
    "section": "📚 Recommended Reading",
    "text": "📚 Recommended Reading\n\nCheck the end of slides for the list of references cited in the lecture."
  },
  {
    "objectID": "danl-wk/wk-01.html#discussion",
    "href": "danl-wk/wk-01.html#discussion",
    "title": "Week 1",
    "section": "💬 Discussion",
    "text": "💬 Discussion\nWelcome to our Week 1 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 1.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 1 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!"
  },
  {
    "objectID": "listing-danl-299-cw.html",
    "href": "listing-danl-299-cw.html",
    "title": "DANL 299 - Classwork",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nClasswork 7\n\n\nPandas - Reshaping DataFrames; Joining DataFrames; Data Concatenation\n\n\nOctober 6, 2025\n\n\n\n\nClasswork 6\n\n\nPandas - Convering Data Types; Filtering Data; Missing Values/Duplicates\n\n\nSeptember 29, 2025\n\n\n\n\nClasswork 5\n\n\nPandas - Loading, Summarizing, Selecting, Counting, Sorting, and Indexing Data\n\n\nSeptember 22, 2025\n\n\n\n\nClasswork 4\n\n\nPython Basics\n\n\nSeptember 8, 2025\n\n\n\n\nClasswork 3\n\n\nQuarto Website Basics\n\n\nSeptember 4, 2025\n\n\n\n\nClasswork 2\n\n\nMarkdown Basics\n\n\nAugust 27, 2025\n\n\n\n\nClasswork 1\n\n\nBuilding a Personal Website using Git, GitHub, and RStudio with Quarto\n\n\nAugust 25, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-299-cw-02.html",
    "href": "danl-cw/danl-299-cw-02.html",
    "title": "Classwork 2",
    "section": "",
    "text": "Markdown is a lightweight markup language with plain-text formatting syntax. Its main goal is to be readable and easy to write, even when viewed as plain text. Markdown is widely used for creating formatted text on the web and in various applications such as Quarto.\n\n\n\n\nHeadings are created by adding one or more # symbols before your heading text. The number of # symbols indicates the level of the heading.\n# Heading 1\n## Heading 2\n### Heading 3\n\n\n\nYou can make text bold by wrapping it with two asterisks **, and italic by using one asterisk *.\n*italic* or _italic_\n**bold** or __bold__\n\n\n\nUnordered lists are created using *, -, or +, while ordered lists are numbered.\n- Item 1\n- Item 2\n  - Subitem 2.1\n  - Subitem 2.2\n1. First item\n2. Second item\n\n\n\nLinks are created using [Link Text](URL)\n[DANL 210](https://bcdanl.github.io/210)\n\n\n\nImages are created using ![Alt Text](Image URL).\n![Geneseo Logo](https://bcdanl.github.io/img/geneseo-logo.gif)\n\n\n\n\n\n\n&gt; Be yourself. Everyone else is already taken. - Oscar Wilde.\n\n\n\n\nA ton of markdown emojis are available here 😄 (:smile:)\n\nhttps://github.com/ikatyang/emoji-cheat-sheet\n\n\n\n\n\nCode blocks are created by using triple backticks (```). Optionally, you can specify the language for syntax highlighting.\n```\n\"string\"\n```\n```python\n# Python code block\nimport numpy as np\n```\n\n\n\n\n\nDo the following tasks on this Classwork 2 Discussion Board:\n\nBasic Syntax: Write a comment with a heading, an unordered list, an ordered list, a link, and an image.\nAdvanced Syntax: Write a comment that includes a Python code block, a blockquote, and an emoji.\n\n\n\n\n\n\nQuarto Markdown Basics\nStart writing on GitHub"
  },
  {
    "objectID": "danl-cw/danl-299-cw-02.html#basic-syntax",
    "href": "danl-cw/danl-299-cw-02.html#basic-syntax",
    "title": "Classwork 2",
    "section": "",
    "text": "Headings are created by adding one or more # symbols before your heading text. The number of # symbols indicates the level of the heading.\n# Heading 1\n## Heading 2\n### Heading 3\n\n\n\nYou can make text bold by wrapping it with two asterisks **, and italic by using one asterisk *.\n*italic* or _italic_\n**bold** or __bold__\n\n\n\nUnordered lists are created using *, -, or +, while ordered lists are numbered.\n- Item 1\n- Item 2\n  - Subitem 2.1\n  - Subitem 2.2\n1. First item\n2. Second item\n\n\n\nLinks are created using [Link Text](URL)\n[DANL 210](https://bcdanl.github.io/210)\n\n\n\nImages are created using ![Alt Text](Image URL).\n![Geneseo Logo](https://bcdanl.github.io/img/geneseo-logo.gif)"
  },
  {
    "objectID": "danl-cw/danl-299-cw-02.html#advanced-syntax",
    "href": "danl-cw/danl-299-cw-02.html#advanced-syntax",
    "title": "Classwork 2",
    "section": "",
    "text": "&gt; Be yourself. Everyone else is already taken. - Oscar Wilde.\n\n\n\n\nA ton of markdown emojis are available here 😄 (:smile:)\n\nhttps://github.com/ikatyang/emoji-cheat-sheet\n\n\n\n\n\nCode blocks are created by using triple backticks (```). Optionally, you can specify the language for syntax highlighting.\n```\n\"string\"\n```\n```python\n# Python code block\nimport numpy as np\n```"
  },
  {
    "objectID": "danl-cw/danl-299-cw-02.html#practice-problems",
    "href": "danl-cw/danl-299-cw-02.html#practice-problems",
    "title": "Classwork 2",
    "section": "",
    "text": "Do the following tasks on this Classwork 2 Discussion Board:\n\nBasic Syntax: Write a comment with a heading, an unordered list, an ordered list, a link, and an image.\nAdvanced Syntax: Write a comment that includes a Python code block, a blockquote, and an emoji."
  },
  {
    "objectID": "danl-cw/danl-299-cw-02.html#references",
    "href": "danl-cw/danl-299-cw-02.html#references",
    "title": "Classwork 2",
    "section": "",
    "text": "Quarto Markdown Basics\nStart writing on GitHub"
  },
  {
    "objectID": "danl-cw/danl-299-cw-01.html",
    "href": "danl-cw/danl-299-cw-01.html",
    "title": "Classwork 1",
    "section": "",
    "text": "Getting a GitHub account\nStep 1. Create the GitHub account with your Geneseo email.\n\nGo to GitHub.\nClick “Sign up for GitHub”.\n\n\nChoose your GitHub username carefully:\n\nhttps://USERNAME.github.io will be the address for your website.\nByeong-Hak’s GitHub username is bcdanl, so that Byeong-Hak owns the web address https://bcdanl.github.io.\n\nIt is recommended to have a username with all lower cases.\n\n\n\n\n\nInstalling git if you do not have one.\nStep 2.\n\nCheck whether git is installed in your laptop.\n\n\nFrom the Console Pane in RStudio, click Terminal tab.\n\n\n\n\n\nFrom the Terminal, run the following command to check if your laptop has git installed.\n\ngit --version\n\nIf your computer has git installed, you will see the message below and you do not need to install git:\n\ngit version 2.xx\n\nIf your computer does not have git installed, you will see the message below and you need to install git:\n\n'git' is not recognized as an internal or external command\n\n\nInstall git if you do not have one. Move to the next step if you have git installed in your laptop.\n\n\n\n\nMac\n\nGo to http://git-scm.com/downloads, and download the file.\nClick “macOS”, scroll down the webpage, and then click “installer” from the Binary installer section.\nRun the downloaded file.\n\n\n\n\nWindows\n\nGo to https://gitforwindows.org, and download the file.\nRun the downloaded file.\n\n\n\n\n\nKeep clicking “Next” to complete the installation of git.\nAfter the git installation is done, close RStudio and re-open it.\n\n\nHow to open git installation file on Mac?\n\nRun the downloaded file.\nClick Okay\nGo to “Setting” &gt; “Privacy and Security”\nGo to “General” or scroll down\nClick “Open Anyway”\n\n\n\n\n\n\n\n\nSetting up GitHub Credential on your local Git.\nStep 3. In Terminal, run the following commands one by one:\ngit config --global user.email \"YOUR_EMAIL_ADDRESS\"\ngit config --global user.name \"YOUR_USERNAME\"\nFor example, the email address for my GitHub account is bchoe@geneseo.edu, and my GitHub username is bcdanl, so that I ran below:\ngit config --global user.email \"bchoe@geneseo.edu\"\ngit config --global user.name \"bcdanl\"\n\nStep 4. Obtain a personal access token (PAT) from GitHub.\n\nIn RStudio Console, run the followings line by line:\n\ninstall.packages(\"usethis\")\nusethis::create_github_token()\n\nThen, click “Generate token” in the pop-upped web browser.\nWe can think of GitHub’s personal access token as a password that expires. You can decide how long it remains valid. My recommendation is to set its expiration for May 31, 2025, or later.\n\n\n\n\n\nThen, copy the generated PAT, and paste it to your clipboard or R script.\n\n\nStep 5. Set the GitHub credential using the PAT.\n\nIn RStudio Console, run the followings line by line:\n\ninstall.packages(\"gitcreds\")\ngitcreds::gitcreds_set()\n\nYou will be asked to provide your PAT.\nPaste your PAT to the RStudio Console, and then hit Enter.\n\n\n\n\n\n\n\nNote\n\n\n\n\nIt does not harm to create multiple PAT for one GitHub account.\nAfter the PAT expires, you should repeat the following if you want to update your GitHub website:\n\n\nCreate a new PAT:\n\nusethis::create_github_token()\n\nReplace the current PAT with the new PAT:\n\ngitcreds::gitcreds_set()\n\nSelect the option 2: Replace these credentials by typing 2 and hitting Enter on R Console.\n\n\n\n\n\n\nEstablishing the Connection between GitHub repo and your local Git\nStep 6. Login to your GitHib and make the repository.\n\nFrom https://github.com, click the plus [+] icon in the upper right corner and select “New repository”.\nName this repo USERNAME.github.io, which will be the domain for your website.\n\n\ne.g., If your GitHub username is abc9, the name of your repo should be abc9.github.io, not abc_9.github.io.\n\n\nThen, copy the web address of your GitHub repo, https://github.com/USERNAME/USERNAME.github.io\n\n\nFor example, the web address for Byeong-Hak’s GitHub repo is https://github.com/bcdanl/bcdanl.github.io.\n\n\nStep 7. Create a RStudio project with Version Control\n\n\n\n\nClick “Project (None)” at the top-right corner in RStudio.\nClick “New Project” &gt; “Version Control” &gt; “Git”\nPaste the web address of your GitHub repo to the Repository URL menu.\nClick “Browse” to select the parent directory for your local project directory (I recommend “Documents” folder.)\nClick “Create”\n\n\n\n\n\n\n\nNote\n\n\n\nIf Step 7 does not work on your laptop, try below Steps 7-1 and 7-2 instead. If Step 7 DOES work well, skip Steps 7-1 and 7-2.\n\n\nStep 7-1. Use git clone to establish the connection between GitHub repo and your local laptop:\n\nChange directory to “Documents” in Terminal using cd command.\n\ncd &lt;pathname of \"Documents\" directory&gt;\n\nHere, you need to know the pathname of “Documents” directory.\nFor example, LAPTOP_USERNAME below is not your GitHub username but one for your local laptop.\n\nMac\ncd /Users/LAPTOP_USERNAME/Documents\nWindows\ncd C:/Users/LAPTOP_USERNAME/Documents\n\nUse git clone to creates a local copy of the GitHub Repository.\n\ngit clone &lt;repository-url&gt;\n\nFor example,\n\ngit clone https://github.com/USERNAME/USERNAME.github.io\n\nStep 7-2. Create a RStudio project from Existing Directory\n\nClick “Project (None)” at the top-right corner in RStudio.\nClick “New Project” &gt; “Existing Directory”\nClick “Browse” to select the local copy of the GitHub Repository\nClick “Create Project”\n\n\n\n\nDownloading Website Template Files\nStep 8. Download the files of website template:\n\nGo to the following webpage: https://github.com/bcdanl/danl-website-template\nFrom the webpage above, click the green icon &lt; &gt; Code, and then click “Download Zip”\nExtract the Zip file you have downloaded\nIf there are the files, .gitignore, .DS_Store, or *.Rproj, in the folder, delete all of them.\nMove all the files that were compressed in the Zip file to your local project directory, USERNAME.github.io.\n\n\nSelect all the files in the danl-website-template folder (Tip: Ctrl + A (Windows) / command + A (Mac) selects all files in a directory).\nThen, Ctrl + C (Windows) / command + C (Mac) to copy them.\nThen, go to your local project directory USERNAME.github.io.\nThen, Ctrl + V (Windows) / command + V (Mac) to paste them to your local project directory USERNAME.github.io.\n\n\nRemove the danl-website-template directory from your local project directory, if you have one.\n\n\nAll the website files should be located at the same level with the R Project file (USERNAME.github.io.Rproj), shown below.\n\n\n\n\n\n\n\nPushing the Website Files to the GitHub repository\n\n\n\nStep 8. Push the files to your GitHub repository\n\nOn Terminal within RStudio, execute the following 3-step git commands, which will stage, commit, and push all the files in the local working directory to your GitHub repository:\n\n\ngit add . adds changes in your local working directory (e.g., edited files, new files, deleted files) to the staging area, which is a temporary area where you can prepare your next commit\n\ngit add .\n\ngit commit -m \"...\" records the changes in the staging area as a new snapshot in the local working directory, along with a message describing the changes.\n\ngit commit -m \"any message to describe the changes\"\n\ngit push uploads the local changes to the online repository in GitHub.\n\ngit push\n\nStep 9. Check whether the files are well uploaded.\n\nGo to the webpages of your GitHub repository and your website:\n\nhttps://github.com/USERNAME/USERNAME.github.io.git\nhttps://USERNAME.github.io\nRefresh the webpages (Ctrl + R for Windows users; cmd + R for Mac users)\n\nAdd a URL for your website (https://YOUR_GITHUB_USERNAME.github.io/) in About section in your GihtHub repository webpage by clicking the setting. Below describes how to do it:\n\n\n\n\nDiscussion\nWelcome to our Classwork 1 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Classwork 1.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Classwork 1 materials or need clarification on any points, don’t hesitate to ask here.\nAll comments will be stored here.\nLet’s collaborate and learn from each other!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-299-cw-05.html",
    "href": "danl-cw/danl-299-cw-05.html",
    "title": "Classwork 5",
    "section": "",
    "text": "Direction\n\n\n\nThe nfl.csv file (with its pathname https://bcdanl.github.io/data/nfl.csv) contains a list of players in the National Football League with similar Name, Team, Position, Birthday, and Salary variables in the nfl.csv file.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\nHow can we read the nfl.csv file, and assign it to a DataFrame object, nfl?\nWhat is an effective way to convert the values in its Birthday variable to datetimes?\n\nAnswer:\n\n\n\nQuestion 2\n\nHow many observations are in nfl?\nWhat are the mean, median, standard deviation, minimum, and maximum of Salary in nfl?\n\nAnswer:\n\n\n\nQuestion 3\n\nHow can we count the number of players per team in nfl?\nHow many unique teams are in nfl?\n\nAnswer:\n\n\n\nQuestion 4\n\nWho are the five highest-paid players?\nWho is the oldest player?\n\nAnswer:\n\n\n\nQuestion 5\nHow can we sort the DataFrame first by Team in alphabetical order and then by Salary in descending order?\nAnswer:\n\n\n\nQuestion 6\nHow do we set the player names as the DataFrame index?\nAnswer:\n\n\n\nQuestion 7\nWho is the oldest player on the Kansas City Chiefs roster, and what is his birthday?\nAnswer:\n\n\n\nDiscussion\nWelcome to our Classwork 5 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Classwork 5.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Classwork 5 materials or need clarification on any points, don’t hesitate to ask here.\nAll comments will be stored here.\nLet’s collaborate and learn from each other!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html",
    "href": "danl-cw/danl-299-cw-06.html",
    "title": "Classwork 6",
    "section": "",
    "text": "The netflix.csv file (with its pathname https://bcdanl.github.io/data/netflix.csv) contains a list of 6,000 titles that were available to watch in November 2019 on the video streaming service Netflix. It includes four variables: the video’s title, director, the date Netflix added it (date_added), and its type (category)."
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#direction",
    "href": "danl-cw/danl-299-cw-06.html#direction",
    "title": "Classwork 6",
    "section": "",
    "text": "The netflix.csv file (with its pathname https://bcdanl.github.io/data/netflix.csv) contains a list of 6,000 titles that were available to watch in November 2019 on the video streaming service Netflix. It includes four variables: the video’s title, director, the date Netflix added it (date_added), and its type (category)."
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#question-1",
    "href": "danl-cw/danl-299-cw-06.html#question-1",
    "title": "Classwork 6",
    "section": "Question 1",
    "text": "Question 1\nOptimize the DataFrame for limited memory use and maximum utility by using the astype() method.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#question-2",
    "href": "danl-cw/danl-299-cw-06.html#question-2",
    "title": "Classwork 6",
    "section": "Question 2",
    "text": "Question 2\nFind all observations with a director of “Martin Scorsese”.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#question-3",
    "href": "danl-cw/danl-299-cw-06.html#question-3",
    "title": "Classwork 6",
    "section": "Question 3",
    "text": "Question 3\nFind all observations with a title of “Limitless” and a type of “Movie”.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#question-4",
    "href": "danl-cw/danl-299-cw-06.html#question-4",
    "title": "Classwork 6",
    "section": "Question 4",
    "text": "Question 4\nFind all observations with either a date_added of “2018-06-15” or a director of “Bong Joon Ho”.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#question-5",
    "href": "danl-cw/danl-299-cw-06.html#question-5",
    "title": "Classwork 6",
    "section": "Question 5",
    "text": "Question 5\nFind all observations with a director of “Ethan Coen”, “Joel Coen”, and “Quentin Tarantino”.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#question-6",
    "href": "danl-cw/danl-299-cw-06.html#question-6",
    "title": "Classwork 6",
    "section": "Question 6",
    "text": "Question 6\nFind all observations with a date_added value between January 1, 2019 and February 1, 2019.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#question-7",
    "href": "danl-cw/danl-299-cw-06.html#question-7",
    "title": "Classwork 6",
    "section": "Question 7",
    "text": "Question 7\nDrop all observations with a NaN value in the director variable.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-06.html#question-8",
    "href": "danl-cw/danl-299-cw-06.html#question-8",
    "title": "Classwork 6",
    "section": "Question 8",
    "text": "Question 8\nIdentify the days when Netflix added only one movie to its catalog.\nAnswer:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#instructor-1",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#instructor-1",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nCurrent Appointment & Education\n\nName: Byeong-Hak Choe.\nAssistant Professor of Data Analytics and Economics, School of Business at SUNY Geneseo.\nPh.D. in Economics from University of Wyoming.\nM.S. in Economics from Arizona State University.\nM.A. in Economics from SUNY Stony Brook.\nB.A. in Economics & B.S. in Applied Mathematics from Hanyang University at Ansan, South Korea.\n\nMinor in Business Administration.\nConcentration in Finance."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#instructor-2",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#instructor-2",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H., 2021. “Social Media Campaigns, Lobbying and Legislation: Evidence from #climatechange and Energy Lobbies.”\nQuestion: To what extent do social media campaigns compete with fossil fuel lobbying on climate change legislation?\nData include:\n\n5.0 million tweets with #climatechange/#globalwarming around the globe;\n12.0 million retweets/likes to those tweets;\n0.8 million Twitter users who wrote those tweets;\n1.4 million Twitter users who retweeted or liked those tweets;\n0.3 million US Twitter users with their location at a city level;\nFirm-level lobbying data (expenses, targeted bills, etc.)."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#instructor-3",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#instructor-3",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H. and Ore-Monago, T., 2024. “Governance and Climate Finance in the Developing World”\nClimate finance refers to the financial resources allocated for mitigating and adapting to climate change, including support for initiatives that reduce greenhouse gas emissions and enhance resilience to climate impacts.\n\nWe focus on transnational financing that rich countries provide poor countries with financial resources, in order to help them adapt to climate change and mitigate greenhouse gas (GHG) emissions.\nSince the GHG emissions in developing countries are rapidly growing, it is crucial to assess the effectiveness of climate finance.\nPoor governance (e.g., legal system, rule of law, and accountability) can be significant barriers to emissions reductions."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#instructor-4",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#instructor-4",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H. and Newbold, Steve, “Estimating the Value of Statistical Life (VSL) through Big Data”\nVSL is the monetary value associated with reducing the risk of death.\n\nHow much value would that be? How can we measure it?\nHow do government agencies use the VSL to decide which policies are worth the cost when they reduce the risk of death?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-1",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-1",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nEmail, Class & Office Hours\n\nEmail: bchoe@geneseo.edu\nClass Homepage:\n\nGitHub Course Website\nBrightspace Course Shell\n\nOffice: South Hall 227B\nOffice Hours:\n\nMondays and Wednesdays 3:30 P.M.–5:00 P.M.\nBy appointment via email."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-2",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-2",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Description\n\nThis course is designed to provide a comprehensive overview of data handling techniques, focusing on practical application through case studies.\nKey topics include:\n\ndata loading, cleaning, transformation, merging, and reshaping;\ntechniques for slicing, dicing, and summarizing datasets;\ndata collection via web scraping and APIs.\n\nThese areas will be explored through detailed, real-world examples to address common data analysis challenges.\nThroughout the course, students will gain hands-on experience with Python and its data analysis libraries, along with practical applications of git and GitHub."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-3",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-3",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nReference Materials\n\nPython for Data Analysis (3rd Edition) by Wes McKinney\n\nA free online version of this book is available.\n\nPython Programming for Data Science by Tomas Beuzen\nCoding for Economists by Arthur Turrell\nPython for Econometrics in Economics by Fabian H. C. Raters\nQuantEcon DataScience - Python Fundamentals by Chase Coleman, Spencer Lyon, and Jesse Perla\nQuantEcon DataScience - pandas by Chase Coleman, Spencer Lyon, and Jesse Perla\nGuide for Quarto"
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-4",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-4",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Requirements\n\nLaptop: You should bring your own laptop (Mac or Windows) to the classroom.\n\nThe minimum specification for your laptop in this course is 2+ core CPU, 4+ GB RAM, and 500+ GB disk storage.\n\nHomework: There will be six homework assignments.\nProject: There will be one project on a personal website.\nExams: There will be two Midterm Exams and one Final Exam.\n\nThe Midterm Exam 2 is comprehensive.\nThe Final Exam is comprehensive.\n\nDiscussions: You are encouraged to participate in GitHub-based online discussions and class discussion, and office hours.\n\nCheckout the netiquette policy in the syllabus."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-5",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-5",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nPersonal Website\n\nYou will create your own website using Quarto, R Studio, and Git.\nYou will publish your homework assignments and a project on your website.\nYour website will be hosted in GitHub.\nThe basics in Markdown will be discussed.\nReferences:\n\nQuarto Guide"
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-6",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-6",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nWhy Personal Website?\n\n\nHere is the example website:\n\nDANL Website Template\n\nProfessional Showcase: Display skills and projects\nVisibility and Networking: Increase online presence\nContent Sharing and Engagement: Publish articles, insights\nJob Opportunities: Attract potential employers and clients\nLong-term Asset: A growing repository of your career journey"
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-7",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-7",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nProject\n\nThe project report should include data collection and exploratory data analysis using summary statistics, visual representations, and data wrangling.\nThe document for the project must be published in each member’s website."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-8",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-8",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nClass Schedule and Exams\n\nThere will be tentatively 28 class sessions.\nThe Midterm Exam I is scheduled on October 8, 2025, Wednesday, during the class time.\nThe Midterm Exam II is scheduled on November 12, 2025, Wednesday, during the class time.\nThe Final Exam is to be determined.\nThe due for the project is December 16, 2025, Tuesday, 11:59 P.M., Eastern Time"
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-9",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-9",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nClass Schedule and Exams\n\nNo class on\n\nSeptember 1 (Labor Day)\nOctober 13 (Fall Break)\nNovember 26 (Thanksgiving Break)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-10",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-10",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents\n\n\n\n\n\n\n\n\nThe first part of the course covers Python basics and pandas basics."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-11",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-11",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents\n\n\n\n\n\n\n\n\nThe second part of the course covers data collection."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-12",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-12",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents\n\n\n\n\n\n\n\n\nThe third part of the course covers advanced pandas."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-13",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-13",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n(\\text{Total Percentage Grade}) =&\\quad\\;\\, 0.05\\times(\\text{Attendance Score})\\notag\\\\\n&\\,+\\, 0.20\\times(\\text{Total Homework Score})\\notag\\\\\n&\\,+\\, 0.25\\times(\\text{Project and Website Score})\\notag\\\\\n&\\,+\\, 0.50\\times(\\text{Total Exam Score}).\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-14",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-14",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\nYou are allowed up to 4 absences without penalty.\n\nSend me an email if you have standard excused reasons (illness, family emergency, transportation problems, etc.).\n\nFor each absence beyond the initial five, there will be a deduction of 1% from the Total Percentage Grade.\nParticipation will be evaluated by quantity and quality of GitHub-based online discussions and in-person discussion.\nThe single lowest homework score will be dropped when calculating the total homework score."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-15",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-15",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n&(\\text{Midterm Exam Score}) \\\\\n=\\, &\\text{max}\\,\\left\\{0.50\\times(\\text{Midterm Exam I Score}) \\,+\\, 0.50\\times(\\text{Midterm Exam II Score})\\right.,\\notag\\\\\n&\\qquad\\;\\,\\left.0.33\\times(\\text{Midterm Exam I Score}) \\,+\\, 0.67\\times(\\text{Midterm Exam II Score})\\right\\}.\\notag\n\\end{align}\n\\]\n\nThe Midterm Exam Score is the maximum between\n\nthe simple average of the Midterm Exam I score and the Midterm Exam II Score and\nthe weighted average of them with one-third weight on the Midterm Exam I Score and two-third weight on the Midterm Exam II Score."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-16",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-16",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n&(\\text{Total Exam Score}) \\\\\n=\\, &\\text{max}\\,\\left\\{0.50\\times(\\text{Midterm Exam Score}) \\,+\\, 0.50\\times(\\text{Final Exam Score})\\right.,\\notag\\\\\n&\\qquad\\;\\,\\left.0.25\\times(\\text{Midterm Exam Score}) \\,+\\, 0.75\\times(\\text{Final Exam Score})\\right\\}.\\notag\n\\end{align}\n\\]\n\nThe Total Exam Score is the maximum between\n\nthe simple average of the Midterm Exam Score and the Final Exam Score and\nthe weighted average of them with one-fourth weight on the Midterm Exam Score and three-third weight on the Final Exam Score."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-17",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-17",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nMake-up Policy\n\nMake-up exams will not be given unless you have either a medically verified excuse or an absence excused by the University.\nIf you cannot take exams because of religious obligations, notify me by email at least two weeks in advance so that an alternative exam time may be set.\nA missed exam without an excused absence earns a grade of zero.\nLate submissions for homework assignment will be accepted with a penalty.\nA zero will be recorded for a missed assignment."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-18",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-18",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAcademic Integrity and Plagiarism\n\nAll homework assignments and exams must be the original work by you.\nExamples of academic dishonesty include:\n\nrepresenting the work, thoughts, and ideas of another person as your own\nallowing others to represent your work, thoughts, or ideas as theirs, and\nbeing complicit in academic dishonesty by suspecting or knowing of it and not taking action.\n\nGeneseo’s Library offers frequent workshops to help you understand how to paraphrase, quote, and cite outside sources properly.\n\nSee https://www.geneseo.edu/library/library-workshops."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-19",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-19",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAccessibility\n\nThe Office of Accessibility will coordinate reasonable accommodations for persons with physical, emotional, or cognitive disabilities to ensure equal access to academic programs, activities, and services at Geneseo.\nPlease contact me and the Office of Accessibility Services for questions related to access and accommodations."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-20",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-20",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nWell-being\n\nYou are strongly encouraged to communicate your needs to faculty and staff and seek support if you are experiencing unmanageable stress or are having difficulties with daily functioning.\nLiz Felski, the School of Business Student Advocate (felski@geneseo.edu, South Hall 303), or the Dean of Students (585-245-5706) can assist and provide direction to appropriate campus resources.\nFor more information, see https://www.geneseo.edu/dean_students."
  },
  {
    "objectID": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-21",
    "href": "danl-lec/danl-299-lec-01-2025-0825.html#syllabus-21",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCareer Design\n\nTo get information about career development, you can visit the Career Development Events Calendar (https://www.geneseo.edu/career_development/events/calendar).\nYou can stop by South 112 to get assistance in completing your Handshake Profile https://app.joinhandshake.com/login.\n\nHandshake is ranked #1 by students as the best place to find full-time jobs.\n50% of the 2018-2020 graduates received a job or internship offer on Handshake.\nHandshake is trusted by all 500 of the Fortune 500."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#nba-dataframe",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#nba-dataframe",
    "title": "Lecture 8",
    "section": "nba DataFrame",
    "text": "nba DataFrame\n\n\nLet’s read the nba.csv file as nba:\n\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])"
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-a-single-variable-with-sort_values",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-a-single-variable-with-sort_values",
    "title": "Lecture 8",
    "section": "Sorting by a Single Variable with sort_values()",
    "text": "Sorting by a Single Variable with sort_values()\n# The two lines below are equivalent\nnba.sort_values([\"Name\"])\nnba.sort_values(by = [\"Name\"])\n\n\nThe sort_values() method’s first parameter, by, accepts the variables that pandas should use to sort observations."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-a-single-variable-with-sort_values-1",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-a-single-variable-with-sort_values-1",
    "title": "Lecture 8",
    "section": "Sorting by a Single Variable with sort_values()",
    "text": "Sorting by a Single Variable with sort_values()\nnba.sort_values([\"Name\"], ascending = False)\n\n\nThe sort_values() method’s ascending parameter determines the sort order.\n\nascending has a default argument of True.\nBy default, pandas will sort:\n\nA variable of numbers in increasing order;\nA variable of strings in alphabetical order;\nA variable of datetimes in chronological order."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#pandas-basics",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#pandas-basics",
    "title": "Lecture 8",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMethod Chaining\n(\n    nba\n    .sort_values(['Salary'])\n    .head(5)\n)\n\n\nDataFrame has various methods that modify the existing DataFrame.\nMethod Chaining: We can call methods sequentially without the need to store intermediate results."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest",
    "title": "Lecture 8",
    "section": "Sorting by a Single Variable with nsmallest() and nlargest()",
    "text": "Sorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(5, 'Salary')\nnba.nlargest(5, 'Salary')\n\nnsmallest() are useful to get the first n observations ordered by a variable in ascending order.\nnlargest() are useful to get the first n observations ordered by a variable in descending order."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest-1",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest-1",
    "title": "Lecture 8",
    "section": "Sorting by a Single Variable with nsmallest() and nlargest()",
    "text": "Sorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(4, 'Salary', keep = \"all\")\nnba.nlargest(4, 'Salary', keep = \"all\")\n\nkeep = \"all\" keeps all duplicates, even it means selecting more than n observations."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-multiple-variables-with-sort_values",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-multiple-variables-with-sort_values",
    "title": "Lecture 8",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values([\"Team\", \"Name\"])\nnba.sort_values(by = [\"Team\", \"Name\"])\n\nWe can sort a DataFrame by multiple columns by passing a list to the by parameter."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-multiple-variables-with-sort_values-1",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-multiple-variables-with-sort_values-1",
    "title": "Lecture 8",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = False)\n\nWe can pass a single Boolean to the ascending parameter to apply the same sort order to each variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-multiple-variables-with-sort_values-2",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-multiple-variables-with-sort_values-2",
    "title": "Lecture 8",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = [False, True])\n\nIf we want to sort each variable in a different order, we can pass a Boolean list to the ascending parameter."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-multiple-variables-with-sort_values-3",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-multiple-variables-with-sort_values-3",
    "title": "Lecture 8",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nQ. Which players on each team are paid the most?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-row-index-with-sort_index",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#sorting-by-row-index-with-sort_index",
    "title": "Lecture 8",
    "section": "Sorting by Row Index with sort_index()",
    "text": "Sorting by Row Index with sort_index()\n\n\n# Below lines are equivalent\nnba.sort_index()\nnba.sort_index(ascending = True)\n\nnba.sort_index(ascending = False)\n\n\n\nIf we assigned nba to nba DataFrame sorted by “Name”, how can we return it to its original form of DataFrame?\n\nOur nba DataFrame still has its numeric index labels.\nsort_index() sorts observations by their index labels (row names)."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#relocating-variables-with-sort_index",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#relocating-variables-with-sort_index",
    "title": "Lecture 8",
    "section": "Relocating Variables with sort_index()",
    "text": "Relocating Variables with sort_index()\n# The two lines below are equivalent\nnba.sort_index(axis = \"columns\")\nnba.sort_index(axis = 1)\n\nThe sort_index() method can also be used to change the order of variables in an alphabetical order.\n\nWe need to add an axis parameter and pass it an argument of \"columns\" or 1."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#setting-a-new-index-1",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#setting-a-new-index-1",
    "title": "Lecture 8",
    "section": "Setting a New Index",
    "text": "Setting a New Index\n\nWe can use the set_index() method when we want to change the current index of a DataFrame to one or more existing columns.\n\nThis is particularly useful when:\n\nWe have a column that uniquely identifies each observation (e.g., ID);\nWe sometimes want to use an unique identifier as the index for more efficient data wrangling."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#setting-a-new-index-with-set_index",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#setting-a-new-index-with-set_index",
    "title": "Lecture 8",
    "section": "Setting a New Index with set_index()",
    "text": "Setting a New Index with set_index()\n# The two lines below are equivalent\nnba.set_index(keys = \"Name\")\nnba.set_index(\"Name\")\n\nThe set_index() method returns a new DataFrame with a given column set as the index.\n\nIts first parameter, keys, accepts the column name."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#re-setting-an-index-with-reset_index",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#re-setting-an-index-with-reset_index",
    "title": "Lecture 8",
    "section": "Re-setting an Index with reset_index()",
    "text": "Re-setting an Index with reset_index()\nnba2 = nba.set_index(\"Name\")\nnba2.reset_index(inplace=True)    # Useful for the method chaining\n\nWe use the reset_index() method:\n\nWhen we want to convert the index back into a DataFrame column;\nWhen we need to reset the index to the default integer index.\n\nNote: With inplace=True, the operation alters the original DataFrame directly."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-1",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-1",
    "title": "Lecture 8",
    "section": "Locating Observations",
    "text": "Locating Observations\n\n\nLet’s read nba.csv as nba.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")"
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observationsvalues",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observationsvalues",
    "title": "Lecture 8",
    "section": "Locating Observations/Values",
    "text": "Locating Observations/Values\n\nWe can extract observations, variables, and values from a DataFrame by using the loc[] and iloc[] accessors.\n\nThese accessors work well when we know the index labels and positions of the observations/variables we want to target."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-by-.locindex-labels",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-by-.locindex-labels",
    "title": "Lecture 8",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n\n\nLet’s consider the nba with the Name index.\n\n# The two lines below are equivalent\nnba = nba.set_index(\"Name\")\nnba.set_index(\"Name\", inplace = True)\n\nBelow extracts observations:\n\n\nnba.loc[ \"LeBron James\" ]\nnba.loc[ [\"Kawhi Leonard\", \"Paul George\"] ]\n\nThe .loc attribute extracts an observation by index label (row name)."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-by-.locindex-labels-1",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-by-.locindex-labels-1",
    "title": "Lecture 8",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n(\n    nba\n    .sort_index()\n    .loc[\"Otto Porter\":\"Patrick Beverley\"]\n)\n\nWhat is the above code doing?\n\nNote: Both the starting value and the ending value are inclusive."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-by-.locindex-labels-2",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-by-.locindex-labels-2",
    "title": "Lecture 8",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n\n\n(\n    nba\n    .sort_index()\n    .loc[\"Zach Collins\":]\n)\n\n(\n    nba\n    .sort_index()\n    .loc[:\"Al Horford\"]\n)\n\n\n\nWe can use loc[:] to pull rows:\n\nFrom the middle of the DataFrame to its end;\nFrom the beginning of the DataFrame to a specific index label."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-by-.ilocindex-positions",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#locating-observations-by-.ilocindex-positions",
    "title": "Lecture 8",
    "section": "Locating Observations by .iloc[Index Positions]",
    "text": "Locating Observations by .iloc[Index Positions]\n\n\nnba.iloc[ 300 ]\nnba.iloc[ [100, 200, 300, 400] ]\n\nnba.iloc[400:404]\nnba.iloc[:2]\nnba.iloc[447:]\nnba.iloc[-10:-6]\nnba.iloc[0:10:2] # every other rows\n\n\n\nThe .iloc (index location) attribute locates rows by index position.\n\nThis can be helpful when the position of rows has significance in our data set.\nWe pass integers.\n\nThe .iloc[:] is similar to the slicing syntax with strings/lists.\n\nThe end value is NOT inclusive."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#pandas-basics-1",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#pandas-basics-1",
    "title": "Lecture 8",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 4-7 in Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#locating-values-by-locrows-columns-or-ilocrows-columns",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#locating-values-by-locrows-columns-or-ilocrows-columns",
    "title": "Lecture 8",
    "section": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]",
    "text": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.loc[\n    \"LeBron James\",\n    \"Team\"\n]\n\nnba.loc[\n     \"James Harden\", \n      [\"Position\", \"Birthday\"] \n]\n\nnba.loc[\n    [\"Russell Westbrook\", \"Anthony Davis\"],\n     [\"Team\", \"Salary\"]\n]\n\nnba.loc[\n    \"Joel Embiid\", \n    \"Position\":\"Salary\"\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .loc, we have to provide the column names."
  },
  {
    "objectID": "danl-lec/danl-299-lec-08-2025-0924.html#locating-values-by-locrows-columns-or-ilocrows-columns-1",
    "href": "danl-lec/danl-299-lec-08-2025-0924.html#locating-values-by-locrows-columns-or-ilocrows-columns-1",
    "title": "Lecture 8",
    "section": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]",
    "text": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.iloc[\n    57, \n    3\n]\n\nnba.iloc[\n    100:104, \n    :3\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .iloc, we have to provide the column position."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#building-a-personal-website-on-github",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#building-a-personal-website-on-github",
    "title": "Lecture 3",
    "section": "Building a Personal Website on GitHub",
    "text": "Building a Personal Website on GitHub\n\nFollow steps described in Classwork 1."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#lets-practice-markdown",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#lets-practice-markdown",
    "title": "Lecture 3",
    "section": "Let’s Practice Markdown!",
    "text": "Let’s Practice Markdown!\n\nJupyter Notebook, Quarto, and GitHub-based Discussion Boards use markdown as its underlying document syntax.\nLet’s do Classwork 2."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nYAML\n\n\n\n\n\n\nAn YAML (yet another markup language) header surrounded by ---.\n\nIt is commonly used for document configuration (e.g., title, author, date, style, …)."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html-1",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html-1",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nKnitting / Rendering\n\n\nWhen we knit the document, Quarto sends the .qmd file to jupyter/knitr, which executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output.\nThe markdown file (*.md) generated by jupyter/knitr is then processed by pandoc, which is responsible for creating the output file."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html-2",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html-2",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nMarkdown, Jupyter Notebook, and HTML\n\nThe very original version of Markdown was invented mainly to write HTML content more easily.\n\nFor example, - SOME_TEXT in “.md” is equivalent to &lt;ul&gt;&lt;li&gt; SOME_TEXT &lt;/li&gt; in ”.html”\n\nPandoc makes it possible to convert a Markdown document to a large variety of output formats, such as HTML."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html-3",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html-3",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nMarkdown, Jupyter Notebook, and HTML\n---\ntitle: \"Habits\"\nauthor: YOUR_NAME\ndate: January 27, 2025\nformat: \n  html\n---\n\nTo create an HTML document from Jupyter Notebook, we specify the html output format in the YAML metadata of our document.\n\nBy default, format: html is set.\n\nOpen an empty Jupyter Notebook file from Google Colab (or VSCode).\n\nCreate the first cell that is Text.\nType the above YAML metadata to the first Text cell."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html-4",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#getting-started-with-jupyter-notebook-and-html-4",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nMarkdown, Jupyter Notebook, and HTML\n---\ntitle: \"Python Basics\"\nauthor: YOUR_NAME\ndate: \"2025-01-27\"\n---\n\nDownload the Jupyter Notebook file, danl-299-python-basic.ipynb from Brightspace, and open it from Google Colab (or VSCode if you prefer).\nThe above syntax is part of YAML metadata in danl-299-python-basic.ipynb.\n\nYAML should be always in the first cell, and the first cell should be text, not code.\n\nIn YAML, indentation really matters!\n\ntab (or four spaces) defines a level in YAML."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-_quarto.yml",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-_quarto.yml",
    "title": "Lecture 3",
    "section": "Quarto Website: _quarto.yml",
    "text": "Quarto Website: _quarto.yml\n\n\n---\nproject:\n  type: website\n\nwebsite:\n  title: \"YOUR NAME\"\n  navbar:\n    left:\n      - text: Project\n        href: danl_proj_nba.ipynb\n      - text: Blog\n        href: blog-listing.qmd\n\nformat:\n  html:\n    theme: cosmo\n    css: styles.css\n    toc: false\n---\n\nThe _quarto.yml file configures the website settings.\nIndentation matters!\n\n\n\n\nIn RStudio, open the project USERNAME.github.io.Rporj.\n\nClick Project: (None) at the top-right corner.\nClick USERNAME.github.io.Rproj.\n\n_quarto.yml configures a website, and provides various options for HTML documents within the website."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nCustom CSS\n\nCascading Style Sheets (CSS) is used to format the layout of a webpage (color, font, text size, background, display, etc.).\n\nHTML will format the architecture of the house.\nCSS will be the carpet and walls to decorate the house.\nJavaScript adds interactive elements in the house, such as opening doors and lighting.\n\nWe are not front-end web developers.\n\nWe will not cover the use of CSS and JavaScript."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-1",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-1",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nRendering\n\n\nThe Render button (command/Ctrl + shift + K) renders a single Quarto document file (e.g., index.qmd) to create an output document.\nquarto render from Terminal renders ALL Quarto documents and Jupyter Notebook files in your local working directory:\n\nquarto render\n\nquarto render should be used if there is any change in _quarto.yml.\n\n\n\n\n\nTip\n\n\n\nEdit _quarto.yml, *.qmd, or *.ipynb files ONLY from your local laptop or Google Colab.\n\nDo not edit them from your GitHub repo for the website."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-2",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-2",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nAdding *.ipynb to a Quarto website\n\nBy default, quarto render doesn’t execute any code in .ipynb notebooks.\nquarto render renders .ipynb notebooks, so that corresponding html files are rendered.\n\nIf you need to update cell outputs in *.ipynb, run that *.ipynb on Google Colab, save the notebook, and download it to your local working directory."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-3",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-3",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nAppearance and Style\n\ntheme specifies the Bootstrap theme to use for the page (themes are drawn from the Bootswatch theme library).\n\nValid themes include default, bootstrap, cerulean, cosmo, darkly, flatly, journal, lumen, paper, readable, sandstone, simplex, spacelab, united, and yeti.\n\nhighlight-style specifies the code highlighting style.\n\nSupported styles include default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, and textmate."
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-4",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-4",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nAbout\n\nYour index.qmd sets a front page about you.\n\nDetails in about pages are available here:\nhttps://quarto.org/docs/websites/website-about.html.\n\nQuarto includes 5 built in templates:\n\njolla\ntrestles\nsolana\nmarquee\nbroadside"
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-5",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-5",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nIcons and Emojis\n\nA ton of Bootstrap icons are available here:\n\nhttps://icons.getbootstrap.com.\n\nA ton of markdown emojis are available here 😄:\n\nhttps://github.com/ikatyang/emoji-cheat-sheet\nhttps://gist.github.com/rxaviers/7360908"
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-6",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-6",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nNaviation and Adding Pages\nleft:\n  - text: Project\n    href: danl_proj_nba.ipynb\n  - text: Blog\n    href: blog-listing.qmd\n\nWe can add a new page to the website through navbar in _quarto.yml"
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-7",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-7",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nNaviation and Adding Pages\nleft:\n  - text: \"Python Data Analysis\"\n    menu:\n      - pandas_basic.ipynb\n      - seaborn_basic.ipynb\n\nWe can also create a drop-down menu by including a menu\nMore details about navbar are available here:\n\nhttps://quarto.org/docs/websites/website-navigation.html"
  },
  {
    "objectID": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-basics",
    "href": "danl-lec/danl-299-lec-03-2025-0904.html#quarto-website-basics",
    "title": "Lecture 3",
    "section": "Quarto Website Basics",
    "text": "Quarto Website Basics\n\nLet’s do Classwork 3."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#employment-data",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#employment-data",
    "title": "Lecture 10",
    "section": "Employment Data",
    "text": "Employment Data\n\n\nLet’s read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-condition-1",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-condition-1",
    "title": "Lecture 10",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with “Donna”.\n\npandas performs a vectorized operation (element-by-element operation) on Series."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-1",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-1",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-2",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-2",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[ donnas ]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-3",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-3",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to extract a subset of employees who are not on the “Marketing” team?\n\n\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not “Marketing”, and False indicates the Team value is “Marketing”"
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-4",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-4",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to retrieve all the managers in the company?\n\nManagers have a value of True in the Mgmt variable.\n\n\n\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-5",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-single-condition-5",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-condition-2",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-condition-2",
    "title": "Lecture 10",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ] # '|' is 'or' opeartor\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria.\nWhat if our next report asked for employees from 30 teams instead of three?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-with-the-isin-method",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-with-the-isin-method",
    "title": "Lecture 10",
    "section": "Filtering with the isin() method",
    "text": "Filtering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[ on_star_teams ]\n\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, array, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-condition-3",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-condition-3",
    "title": "Lecture 10",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000.\n\n\n\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ] # '&' is 'and' opeartor\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-with-the-between-method",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-with-the-between-method",
    "title": "Lecture 10",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[ between_90k_and_100k ]\n\nA slightly cleaner solution is to use a method called between().\n\nIt returns a Boolean Series where True denotes that an observation’s value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is also inclusive."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-with-the-between-method-1",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-with-the-between-method-1",
    "title": "Lecture 10",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[ name_starts_with_t ]\n\nWe can also apply the between() method to string variables.\n\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-condition-with-the-query-method",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#filtering-by-a-condition-with-the-query-method",
    "title": "Lecture 10",
    "section": "Filtering by a Condition with the query() method!",
    "text": "Filtering by a Condition with the query() method!\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 & `First Name` == 'Douglas'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\n\nquery() accepts a string value that describes filtering conditions.\n\nWhen using the query() method, if we have variable names with spaces, we can wrap the variable names in backtick (`)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#adding-a-variable-based-on-a-condition-using-np.where",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#adding-a-variable-based-on-a-condition-using-np.where",
    "title": "Lecture 10",
    "section": "Adding a Variable based on a Condition using np.where()",
    "text": "Adding a Variable based on a Condition using np.where()\n\n\nWe can use np.where from NumPy to add a new variable to a DataFrame based on a condition.\n\n\nimport numpy as np\n\n# Using np.where to add the 'pass_fail' column\nemp['high_salary'] = np.where(emp['Salary'] &gt;= 100000, 'Yes', 'No')\n\nWe want to add a new variable high_salary:\n\n“Yes” if score is greater than or equal to 100,000.\n“No” otherwise."
  },
  {
    "objectID": "danl-lec/danl-299-lec-10-2025-1001.html#pandas-basics",
    "href": "danl-lec/danl-299-lec-10-2025-1001.html#pandas-basics",
    "title": "Lecture 10",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 2-6 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#variables-are-names-not-places",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#variables-are-names-not-places",
    "title": "Lecture 4",
    "section": "Variables Are Names, Not Places",
    "text": "Variables Are Names, Not Places\n\n\n\n\nA value is datum (literal) such as a number or text.\nThere are different types of values:\n\n352.3 is known as a float or double;\n22 is an integer;\n“Hello World!” is a string."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#values-variables-and-types",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#values-variables-and-types",
    "title": "Lecture 4",
    "section": "Values, Variables, and Types",
    "text": "Values, Variables, and Types\na = 10\nprint(a)\n\n\n\n\n\n\n\nA variable is a name that refers to a value.\n\nWe can think of a variable as a box that has a value, or multiple values, packed inside it.\n\nA variable is just a name!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#values-variables-and-types-1",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#values-variables-and-types-1",
    "title": "Lecture 4",
    "section": "Values, Variables, and Types",
    "text": "Values, Variables, and Types\n\n\nSometimes you will hear variables referred to as objects.\nEverything that is not a literal value, such as 10, is an object."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#variable-in-dataframe",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#variable-in-dataframe",
    "title": "Lecture 4",
    "section": "Variable in DataFrame",
    "text": "Variable in DataFrame\n\n\n\n\n\n\nDefinition: A data.frame is a table-like data structure used for storing data in a tabular format with rows and columns.\nStructure: Consists of:\n\nVariables (Columns)\nObservations (Rows)\nValues (Cells): Individual data points within each cell of the data.frame."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#assignment",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#assignment",
    "title": "Lecture 4",
    "section": "Assignment ( = )",
    "text": "Assignment ( = )\n# Here we assign the integer value 5 to the variable x.\nx = 5   \n\n# Now we can use the variable x in the next line.\ny = x + 12  \ny\n\nIn Python, we use = to assign a value to a variable.\nIn math, = means equality of both sides.\nIn programs, = means assignment: assign the value on the right side to the variable on the left side."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#code-and-comment-style",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#code-and-comment-style",
    "title": "Lecture 4",
    "section": "Code and comment style",
    "text": "Code and comment style\n\nThe two main principles for coding and managing data are:\n\nMake things easier for your future self.\nDon’t trust your future self.\n\nThe # mark is Google Colab’s comment character.\n\nThe # character has many names: hash, sharp, pound, or octothorpe.\n# indicates that the rest of the line is to be ignored.\nWrite comments before the line that you want the comment to apply to.\n\nConsider adding more comments on code cells and their results using text cells."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#assignment-1",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#assignment-1",
    "title": "Lecture 4",
    "section": "Assignment ( = )",
    "text": "Assignment ( = )\n\nIn programming code, everything on the right side needs to have a value.\n\nThe right side can be a literal value, or a variable that has already been assigned a value, or a combination.\n\nWhen Python reads y = x + 12, it does the following:\n\nSees the = in the middle.\nKnows that this is an assignment.\nCalculates the right side (gets the value of the object referred to by x and adds it to 12).\nAssigns the result to the left-side variable, y."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#variables-are-names-not-places-1",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#variables-are-names-not-places-1",
    "title": "Lecture 4",
    "section": "Variables Are Names, Not Places",
    "text": "Variables Are Names, Not Places\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\ntype(list_example)\n\nThe most basic built-in data types that we’ll need to know about are:\n\nintegers 10\nfloats 1.23\nstrings \"like this\"\nbooleans True\nnothing None\n\nPython also has a built-in type of data container called a list (e.g., [10, 15, 20]) that can contain anything, even different types"
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#data-types",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#data-types",
    "title": "Lecture 4",
    "section": "Data Types",
    "text": "Data Types\n\n\n\n\nThe second column (Type) contains the Python name of that type.\nThe third column (Mutable?) indicates whether the value can be changed after creation."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#brackets",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#brackets",
    "title": "Lecture 4",
    "section": "Brackets",
    "text": "Brackets\n\n\nThere are several kinds of brackets in Python, including [], {}, and ().\n\n\n[]{}()\n\n\nvector = ['a', 'b']\nvector[0]\n\n[] is used to denote a list or to signify accessing a position using an index.\n\n\n\n{'a', 'b'}  # set\n{'first_letter': 'a', 'second_letter': 'b'}  # dictionary\n\n{} is used to denote a set or a dictionary (with key-value pairs).\n\n\n\nnum_tup = (1, 2, 3)\nsum(num_tup)\n\n() is used to denote\n\na tuple, or\nthe arguments to a function, e.g., function(x) where x is the input passed to the function."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#operators",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#operators",
    "title": "Lecture 4",
    "section": "Operators",
    "text": "Operators\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nAll of the basic operators we see in mathematics are available to use:\n\n\n\n\n+ for addition\n- for subtraction\n\n\n\n* for multiplication\n** for powers\n\n\n\n/ for division\n// for integer division\n\n\n\n\nThese work as you’d expect on numbers.\nThese operators are sometimes defined for other built-in data types too.\n\nWe can ‘sum’ strings (which really concatenates them)."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#operators-1",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#operators-1",
    "title": "Lecture 4",
    "section": "Operators",
    "text": "Operators\n\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\nIt works for lists too:\n\n\nstring = \"apples, \"\nprint(string * 3)\n\nWe can multiply strings!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#operators-2",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#operators-2",
    "title": "Lecture 4",
    "section": "Operators",
    "text": "Operators\nQ. Classwork 4.1\nUsing Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]"
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#casting-variables",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#casting-variables",
    "title": "Lecture 4",
    "section": "Casting Variables",
    "text": "Casting Variables\n\n\norig_number = 4.39898498\ntype(orig_number)\n\nmod_number = int(orig_number)\nmod_number\ntype(mod_number)\n\n\n\nSometimes we need to explicitly cast a value from one type to another.\n\nWe can do this using built-in functions like str(), int(), and float().\nIf we try these, Python will do its best to interpret the input and convert it to the output type we’d like and, if they can’t, the code will throw a great big error."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#tuples-and-immutability",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#tuples-and-immutability",
    "title": "Lecture 4",
    "section": "Tuples and (im)mutability",
    "text": "Tuples and (im)mutability\n\n\nA tuple is an object that is defined by parentheses and entries that are separated by commas, for example (15, 20, 32). (They are of type tuple.)\nTuples are immutable, while lists are mutable.\nImmutable objects, such as tuples and strings, can’t have their elements changed, appended, extended, or removed.\n\nMutable objects, such as lists, can do all of these things.\n\nIn everyday programming, we use lists and dictionaries more than tuples."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#dictionaries",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#dictionaries",
    "title": "Lecture 4",
    "section": "Dictionaries",
    "text": "Dictionaries\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"New York\": 36, \"Seoul\": 29}\n\ncities_to_temps.keys()\ncities_to_temps.values()\ncities_to_temps.items()\n\nAnother built-in Python type that is enormously useful is the dictionary.\n\nThis provides a mapping one set of variables to another (either one-to-one or many-to-one).\nIf you need to create associations between objects, use a dictionary.\n\nWe can obtain keys, values, or key-value paris from dictionaries."
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#running-on-empty",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#running-on-empty",
    "title": "Lecture 4",
    "section": "Running on Empty",
    "text": "Running on Empty\n\nBeing able to create empty containers is sometimes useful, especially when using loops.\nThe commands to create empty lists, tuples, dictionaries, and sets are lst = [], tup=(), dic={}, and st = set() respectively.\nQ. What is the type of an empty list?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-04-2025-0908.html#google-colab-settings",
    "href": "danl-lec/danl-299-lec-04-2025-0908.html#google-colab-settings",
    "title": "Lecture 4",
    "section": "Google Colab Settings",
    "text": "Google Colab Settings\nTurn off AI Assistance\n\nOn Google Colab\n\nFrom the top-right corner, click ⚙️\nClick “AI Assistance” from the side menu.\nDisable all options."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-1",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\n\nLet’s read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-2",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-2",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation’s value is missing.\n\nIs a value of a variable “XYZ” missing?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation’s value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The value_counts(dropna = False) method",
    "text": "Dealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-dropna-method",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-dropna-method",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method",
    "text": "Dealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-dropna-method-with-how",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-dropna-method-with-how",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with how",
    "text": "Dealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter’s default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-duplicated-method",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-duplicated-method",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method’s keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation’s uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value’s last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of “Douglas” and a Gender of “Male”. Then check which “Douglas” is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1001.html#pandas-basics",
    "href": "danl-lec/danl-299-lec-11-2025-1001.html#pandas-basics",
    "title": "Lecture 11",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#nba-dataframe",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#nba-dataframe",
    "title": "Lecture 7",
    "section": "nba DataFrame",
    "text": "nba DataFrame\n\n\nLet’s read the nba.csv file as nba:\n\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])"
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#dataframe-terminologies-variables-observations-and-values",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#dataframe-terminologies-variables-observations-and-values",
    "title": "Lecture 7",
    "section": "DataFrame Terminologies: Variables, Observations, and Values",
    "text": "DataFrame Terminologies: Variables, Observations, and Values\n\n\n\n\nEach variable is a column.\nEach observation is a row.\nEach value is a cell."
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#dataframe-terminologies",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#dataframe-terminologies",
    "title": "Lecture 7",
    "section": "DataFrame Terminologies",
    "text": "DataFrame Terminologies\nDot Operators, Methods, and Attributes\nDot operator\n\nThe dot operator (DataFrame.) is used for an attribute or a method on objects.\n\n\n\nMethod\n\nA method (DataFrame.METHOD()) is a function that we can call on a DataFrame to perform operations, modify data, or derive insights.\n\ne.g., nba.info()\n\n\n\nAttribute\n\nAn attribute (DataFrame.ATTRIBUTE) is a property that provides information about the DataFrame’s structure or content without modifying it.\n\ne.g., nba.dtype"
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#getting-a-summary-of-a-dataframe-with-.info",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#getting-a-summary-of-a-dataframe-with-.info",
    "title": "Lecture 7",
    "section": "Getting a Summary of a DataFrame with .info()",
    "text": "Getting a Summary of a DataFrame with .info()\n\n\nnba.info()    # method\n\nnba.shape     # attribute\nnba.dtypes    # attribute\nnba.columns   # attribute\nnba.count()   # method\n\n\n\nEvery DataFrame object has a .info() method that provides a summary of a DataFrame:\n\nVariable names (.columns)\nNumber of variables/observations (.shape)\nData type of each variable (.dtypes)\nNumber of non-missing values in each variable (.count())\n\nPandas often displays missing values as NaN."
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#getting-a-summary-of-a-dataframe-with-.describe",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#getting-a-summary-of-a-dataframe-with-.describe",
    "title": "Lecture 7",
    "section": "Getting a Summary of a DataFrame with .describe()",
    "text": "Getting a Summary of a DataFrame with .describe()\nnba.describe()\nnba.describe(include='all')\n\n.describe() method generates descriptive statistics that summarize the central tendency, dispersion, and distribution of each variable.\n\nIt can also process string-type variables if specified explicitly (include='all')."
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#selecting-a-variable-by-its-name",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#selecting-a-variable-by-its-name",
    "title": "Lecture 7",
    "section": "Selecting a Variable by its Name",
    "text": "Selecting a Variable by its Name\nnba_player_name_s = nba['Name']   # Series\nnba_player_name_s\n\nnba_player_name_df = nba[ ['Name'] ]   # DataFrame\nnba_player_name_df\n\nIf we want only a specific variable from a DataFrame, we can access the variable with its name using squared brackets, [ ].\n\nDataFrame[ 'var_1' ]\nDataFrame[ ['var_1'] ]"
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#selecting-multiple-variables-by-their-names",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#selecting-multiple-variables-by-their-names",
    "title": "Lecture 7",
    "section": "Selecting Multiple Variables by their Names",
    "text": "Selecting Multiple Variables by their Names\nnba_player_name_team = nba[ ['Name', 'Team'] ]\nnba_player_name_team\n\nIn order to specify multiple variables by their names, we need to pass in a Python list between the square brackets.\n\nDataFrame[ ['var_1', 'var_2', ... ] ]\nThis is also how we can relocate variables by the order specified in the list."
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#selecting-multiple-variables-with-select_dtypes",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#selecting-multiple-variables-with-select_dtypes",
    "title": "Lecture 7",
    "section": "Selecting Multiple Variables with select_dtypes()",
    "text": "Selecting Multiple Variables with select_dtypes()\n# To include only string variables\nnba.select_dtypes(include = \"object\")\n\n# To exclude string and integer variables\nnba.select_dtypes(exclude = [\"object\", \"int\"])\n\nWe can use the select_dtypes() method to select columns based on their data types.\n\nThe method accepts two parameters, include and exclude."
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#counting-with-.count",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#counting-with-.count",
    "title": "Lecture 7",
    "section": "Counting with .count()",
    "text": "Counting with .count()\n\n\nnba['Salary'].count()\nnba[['Salary']].count()\n\n\n\nThe .count() counts the number of non-missing values in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#counting-with-.value_counts",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#counting-with-.value_counts",
    "title": "Lecture 7",
    "section": "Counting with .value_counts()",
    "text": "Counting with .value_counts()\n\n\nnba['Team'].value_counts()\n\nnba[['Team']].value_counts()\n\n\n\nThe .value_counts() counts the number of occurrences of each unique value in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#counting-with-.nunique",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#counting-with-.nunique",
    "title": "Lecture 7",
    "section": "Counting with .nunique()",
    "text": "Counting with .nunique()\n\n\nnba[['Team']].nunique()\n\nnba.nunique()\n\n\n\nThe .nunique() counts the number of unique values in each variable in a DataFrame."
  },
  {
    "objectID": "danl-lec/danl-299-lec-07-2025-0922.html#pandas-basics",
    "href": "danl-lec/danl-299-lec-07-2025-0922.html#pandas-basics",
    "title": "Lecture 7",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 1-3 in Classwork 5!"
  },
  {
    "objectID": "listing-danl-299-hw.html",
    "href": "listing-danl-299-hw.html",
    "title": "DANL 299 - Homework",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nHomework 2\n\n\nPandas Basics\n\n\nSeptember 25, 2025\n\n\n\n\nHomework 1\n\n\nPersonal Website and Python Basics\n\n\nSeptember 11, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-1",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\n10 == 20\n10 == '10'\n\nBoolean data have either True or False value."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-2",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-2",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\n\n\n\n\n\n\n\n\nExisting booleans can be combined, which create a boolean when executed."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-3",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-3",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nConditions are expressions that evaluate as booleans."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-4",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-4",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nboolean_condition1 = 10 == 20\nprint(boolean_condition1)\n\nboolean_condition2 = 10 == '10'\nprint(boolean_condition2)\n\nThe == is an operator that compares the objects on either side and returns True if they have the same values\nQ. What does not (not True) evaluate to?\nQ. Classwork 4.2"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-5",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-5",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nname = \"Geneseo\"\nscore = 99\n\nif name == \"Geneseo\" and score &gt; 90:\n    print(\"Geneseo, you achieved a high score.\")\n\nif name == \"Geneseo\" or score &gt; 90:\n    print(\"You could be called Geneseo or have a high score\")\n\nif name != \"Geneseo\" and score &gt; 90:\n    print(\"You are not called Geneseo and you have a high score\")\n\nThe real power of conditions comes when we start to use them in more complex examples, such as if statements."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-6",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-6",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nOne of the most useful conditional keywords is in.\n\nThis one must pop up ten times a day in most coders’ lives because it can pick out a variable or make sure something is where it’s supposed to be.\n\nQ. Check if “a” is in the string “Sun Devil Arena” using in. Is “a” in “Anyone”?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-7",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-7",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nOne conditional construct we’re bound to use at some point, is the if-else chain:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-with-in",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#booleans-conditions-and-if-statements-with-in",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements with in",
    "text": "Booleans, Conditions, and if Statements with in\nfruits = [\"apple\", \"banana\", \"cherry\"]\n\nfavorite = \"banana\"\n\nif favorite in fruits:\n    print(f\"{favorite} is available!\")\nelse:\n    print(f\"{favorite} is not in the list.\")\n\nThe keyword in lets you check whether a value is present in a list, string, or other iterable.\n\nThis works seamlessly inside an if-else structure.\n\nUseful for membership tests such as:\n\nValidating if a company is in a stock list\n\nSeeing if a word exists in a sentence"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#indentation",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#indentation",
    "title": "Lecture 5",
    "section": "Indentation",
    "text": "Indentation\n\nWe have seen that certain parts of the code examples are indented.\nCode that is part of a function, a conditional clause, or loop is indented.\nIndention is actually what tells the Python interpreter that some code is to be executed as part of, say, a loop and not to executed after the loop is finished."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#indentation-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#indentation-1",
    "title": "Lecture 5",
    "section": "Indentation",
    "text": "Indentation\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nHere’s a basic example of indentation as part of an if statement.\nThe standard practice for indentation is that each sub-statement should be indented by 4 spaces."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#slicing-methods",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#slicing-methods",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\n\n\n\n\nWith slicing methods, we can get subset of the data object.\nSlicing methods can apply for strings, lists, arrays, and DataFrames.\nThe above example describes indexing in Python"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#strings",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#strings",
    "title": "Lecture 5",
    "section": "Strings",
    "text": "Strings\nstring = \"cheesecake\"\nprint( string[-4:] )\n\nFrom strings, we can access the individual characters via slicing and indexing.\n\n\n\nstring = \"cheesecake\"\nprint(\"String has length:\")\nprint( len(string) )\n\nlist_of_numbers = range(1, 20)\nprint(\"List of numbers has length:\")\nprint( len(list_of_numbers) )\n\n\n\nBoth lists and strings will allow us to use the len() command to get their length:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#string-related-functions",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#string-related-functions",
    "title": "Lecture 5",
    "section": "String-related Functions",
    "text": "String-related Functions\nDot operation\n\nIn Python, we can access attributes by using a dot notation (.).\nUnlike len(), some functions use a dot to access to strings.\nTo use those string functions, type (1) the name of the string, (2) a dot, (3) the name of the function, and (4) any arguments that the function needs:\n\nstring_name.some_function(arguments)."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#string-related-functions-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#string-related-functions-1",
    "title": "Lecture 5",
    "section": "String-related Functions",
    "text": "String-related Functions\ntasks = 'get gloves,get mask,give cat vitamins,call ambulance'\ntasks.split(',')\ntasks.split()\nSplit with split()\n\nWe can use the built-in string split() function to break a string into a list of smaller strings based on some separator.\n\nIf we don’t specify a separator, split() uses any sequence of white space characters—newlines, spaces, and tabs:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#string-related-functions-2",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#string-related-functions-2",
    "title": "Lecture 5",
    "section": "String-related Functions",
    "text": "String-related Functions\ncrypto_list = ['Yeti', 'Bigfoot', 'Loch Ness Monster']\ncrypto_string = ', '.join(crypto_list)\nprint('Found and signing book deals:', crypto_string)\nCombine by Using join()\n\njoin() collapses a list of strings into a single string."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#strings-and-slicing",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#strings-and-slicing",
    "title": "Lecture 5",
    "section": "Strings and Slicing",
    "text": "Strings and Slicing\n\nWe can extract a substring (a part of a string) from a string by using a slice.\nWe define a slice by using square brackets ([]), a start index, an end index, and an optional step count between them.\n\nWe can omit some of these.\n\nThe slice will include characters from index start to one before end:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#get-a-substring-with-a-slice",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#get-a-substring-with-a-slice",
    "title": "Lecture 5",
    "section": "Get a Substring with a Slice",
    "text": "Get a Substring with a Slice\n\n\n[:][ start :][: end ][ start : end ][ start : end : step ]\n\n\nletters = 'abcdefghij'\nletters[:]\n\n[:] extracts the entire sequence from start to end.\n\n\n\nletters = 'abcdefghij'\nletters[4:]\nletters[2:]\nletters[-3:]\nletters[-50:]\n\n[ start :] specifies from the start index to the end.\n\n\n\nletters = 'abcdefghij'\nletters[:3]\nletters[:-3]\nletters[:70]\n\n[: end ] specifies from the beginning to the end index minus 1.\n\n\n\nletters = 'abcdefghij'\nletters[2:5]\nletters[-26:-24]\nletters[35:37]\n\n[ start : end ] indicates from the start index to the end index minus 1.\n\n\n\nletters = 'abcdefghij'\nletters[2 : 6 : 2]   # From index 2 to 5, by steps of 2 characters\nletters[ : : 3]     # From the start to the end, in steps of 3 characters\nletters[ 6 : : 4 ]    # From index 19 to the end, by 4\nletters[ : 7 : 5 ]    # From the start to index 6 by 5:\nletters[-1 : : -1 ]   # Starts at the end and ends at the start\nletters[: : -1 ]\n\n[ start : end : step ] extracts from the start index to the end index minus 1, skipping characters by step."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#lists",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#lists",
    "title": "Lecture 5",
    "section": "Lists",
    "text": "Lists\n\nPython is\n\na zero-indexed language (things start counting from zero);\nleft inclusive;\nright exclusive when we are specifying a range of values."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#lists-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#lists-1",
    "title": "Lecture 5",
    "section": "Lists",
    "text": "Lists\nlist_example = ['one', 'two', 'three']\nlist_example[ 0 : 1 ]\nlist_example[ 1 : 3 ]\n\n\n\n\nWe can think of items in a list-like object as being fenced in.\n\nThe index represents the fence post."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#lists-2",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#lists-2",
    "title": "Lecture 5",
    "section": "Lists",
    "text": "Lists\n\n\n[index]Get an Item with a Slice\n\n\nGet an Item by [index]\nsuny = ['Geneseo', 'Brockport', 'Oswego', 'Binghamton', \n        'Stony Brook', 'New Paltz'] \n\nWe can extract a single value from a list by specifying its index:\n\n\n\nsuny[0]\nsuny[1]\nsuny[2]\nsuny[7]\n\nsuny[-1]\nsuny[-2]\nsuny[-3]\nsuny[-7]\n\n\n\n\n\nWe can extract a subsequence of a list by using a slice:\n\nsuny = ['Geneseo', 'Brockport', 'Oswego', 'Binghamton', \n        'Stony Brook', 'New Paltz'] \nsuny[0:2]    # A slice of a list is also a list.\n\n\nsuny[ : : 2]\nsuny[ : : -2]\nsuny[ : : -1]\n\nsuny[4 : ]\nsuny[-6 : ]\nsuny[-6 : -2]\nsuny[-6 : -4]"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#slicing-methods-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#slicing-methods-1",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\n\nQ. Classwork 4.3"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#functions",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#functions",
    "title": "Lecture 5",
    "section": "Functions",
    "text": "Functions\nint(\"20\") \nfloat(\"14.3\")\nstr(5)\nint(\"xyz\")\n\nA function can take any number and type of input parameters and return any number and type of output results.\nPython ships with more than 65 built-in functions.\nPython also allows a user to define a new function.\nWe will mostly use built-in functions."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#functions-arguments-and-parameters-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#functions-arguments-and-parameters-1",
    "title": "Lecture 5",
    "section": "Functions, Arguments, and Parameters",
    "text": "Functions, Arguments, and Parameters\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\")\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\", sep = \"!\")\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\", sep=\" \")\n\nWe invoke a function by entering its name and a pair of opening and closing parentheses.\nMuch as a cooking recipe can accept ingredients, a function invocation can accept inputs called arguments.\nWe pass arguments sequentially inside the parentheses (, separated by commas).\nA parameter is a name given to an expected function argument.\nA default argument is a fallback value that Python passes to a parameter if the function invocation does not explicitly provide one."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#functions-arguments-and-parameters-2",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#functions-arguments-and-parameters-2",
    "title": "Lecture 5",
    "section": "Functions, Arguments, and Parameters",
    "text": "Functions, Arguments, and Parameters\n\nQ. Classwork 4.4"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#repeat-with-while",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#repeat-with-while",
    "title": "Lecture 5",
    "section": "Repeat with while",
    "text": "Repeat with while\n\n\ncount = 1        \nwhile count &lt;= 5:\n    print(count)\n    count += 1\n\nWe first assigned the value 1 to count.\nThe while loop compared the value of count to 5 and continued if count was less than or equal to 5.\nInside the loop, we printed the value of count and then incremented its value by one with the statement count += 1.\n\n\n\nPython goes back to the top of the loop, and again compares count with 5.\nThe value of count is now 2, so the contents of the while loop are again executed, and count is incremented to 3.\nThis continues until count is incremented from 5 to 6 at the bottom of the loop.\nOn the next trip to the top, count &lt;= 5 is now False, and the while loop ends."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#asking-the-user-for-input",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#asking-the-user-for-input",
    "title": "Lecture 5",
    "section": "Asking the user for input",
    "text": "Asking the user for input\nstuff = input()\n# Type something and press Return/Enter on Console \n# before running print(stuff)\nprint(stuff)\n\nSometimes we would like to take the value for a variable from the user via their keyboard.\n\nThe input() function gets input from the keyboard.\nWhen the input() is called, the program stops and waits for the user to type something on Console (interactive Python interpreter).\nWhen the user presses Return or Enter on Console, the program resumes and input returns what the user typed as a string."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#cancel-with-break",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#cancel-with-break",
    "title": "Lecture 5",
    "section": "Cancel with break",
    "text": "Cancel with break\nwhile True:\n    user_input = input(\"Enter 'yes' to continue or 'no' to stop: \")\n    if user_input.lower() == 'no':\n        print(\"Exiting the loop. Goodbye!\")\n        break\n    elif user_input.lower() == 'yes':\n        print(\"You chose to continue.\")\n    else:\n        print(\"Invalid input, please enter 'yes' or 'no'.\")\n\nWhile loop is used to execute a block of code repeatedly until given boolean condition evaluated to False.\n\nwhile True loop will run forever unless we write it with a break statement.\n\nIf we want to loop until something occurs, but we’re not sure when that might happen, we can use an infinite loop with a break statement."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#repeat-with-while-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#repeat-with-while-1",
    "title": "Lecture 5",
    "section": "Repeat with while",
    "text": "Repeat with while\nSkip Ahead with continue\nwhile True:\n    value = input(\"Integer, please [q to quit]: \")\n    if value == 'q': # quit\n        break\n    number = int(value)\n    if number % 2 == 0: # an even number\n        continue\n    print(number, \"squared is\", number*number)\n\nSometimes, we don’t want to break out of a loop but just want to skip ahead to the next iteration for some reason.\nThe continue statement is used to skip the rest of the code inside a loop for the current iteration only."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#repeat-with-while-2",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#repeat-with-while-2",
    "title": "Lecture 5",
    "section": "Repeat with while",
    "text": "Repeat with while\nCheck break Use with else\n\nnumbers = [1, 3, 5]\nposition = 0\n\nwhile position &lt; len(numbers):\n    number = numbers[position]\n    if number &gt; 4:  # Condition changed to checking if the number is greater than 4\n        print('Found a number greater than 4:', number)\n        break\n    position += 1\nelse:  # break not called\n    print('No number greater than 4 found')\n\nWe can consider using while with else when we’ve coded a while loop to check for something, and breaking as soon as it’s found.\n\nConsider it a break checker."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\n\nSometimes we want to loop through a set of things such as a string of text, a list of words or a list of numbers.\n\nWhen we have a list of things to loop through, we can construct a for loop.\nA for loop makes it possible for you to traverse data structures without knowing how large they are or how they are implemented."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in-1",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\n\n\nLet’s see two ways to walk through a string here:\n\n\n\n\nword = 'thud'\noffset = 0\nwhile offset &lt; len(word):\n    print(word[offset])\n    offset += 1\n\nword = 'thud'\nfor letter in word:\n    print(letter)\n\n\n\nWhich one do you prefer?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in-2",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in-2",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nCancel with break\nword = 'thud'\nfor letter in word:\n    if letter == 'u':\n        break\n    print(letter)\n\nA break in a for loop breaks out of the loop, as it does for a while loop:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in-3",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in-3",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nSkip with continue\nword = 'thud'\nfor letter in word:\n    if letter == 'u':\n        continue\n    print(letter)\n\nInserting a continue in a for loop jumps to the next iteration of the loop, as it does for a while loop."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#loop-control-continue-pass-break",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#loop-control-continue-pass-break",
    "title": "Lecture 5",
    "section": "🔄 Loop Control: continue, pass, break",
    "text": "🔄 Loop Control: continue, pass, break\nfor num in range(1, 6):\n\n    if num == 2:\n        continue   # skip printing 2\n\n    if num == 3:\n        pass       # do nothing, move on\n\n    if num == 4:\n        break      # exit the loop\n\n    print(num)\n\nIn a for or while loop, you can alter flow with:\n\ncontinue → skips to the next loop iteration\n\npass → does nothing (placeholder)\n\nbreak → exits the loop completely"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#generate-number-sequences-with-range",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#generate-number-sequences-with-range",
    "title": "Lecture 5",
    "section": "Generate Number Sequences with range()",
    "text": "Generate Number Sequences with range()\n\nThe range() function returns a stream of numbers within a specified range, without first having to create and store a large data structure such as a list or tuple.\n\nThis lets us create huge ranges without using all the memory in our computers and crashing our program.\nrange() returns an iterable object, so we need to step through the values with for … in, or convert the object to a sequence like a list."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#for-in-range",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#for-in-range",
    "title": "Lecture 5",
    "section": "for … in range()",
    "text": "for … in range()\n\n\nfor x in range(0, 3):\n    print(x)\nlist( range(0, 3) )\n\n\nWe use range() similar to how we use slices: range( start, stop, step ).\n\nIf we omit start, the range begins at 0.\nThe only required value is stop; as with slices, the last value created will be just before stop.\nThe default value of step is 1, but we can change it."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in-4",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#iterate-with-for-and-in-4",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nCheck break Use with else\nword = 'thud'\nfor letter in word:\n    if letter == 'x':\n        print(\"Eek! An 'x'!\")\n        break\n    print(letter)\nelse:\n    print(\"No 'x' in there.\")\n\nSimilar to while, for has an optional else that checks whether the for completed normally.\n\nIf break was not called, the else statement is run."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#loop-with-while-and-for-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#loop-with-while-and-for-1",
    "title": "Lecture 5",
    "section": "Loop with while and for",
    "text": "Loop with while and for\nClass Exercises\n\nQ. Classwork 4.5\nQ. Classwork 4.6"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#list-comprehension",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#list-comprehension",
    "title": "Lecture 5",
    "section": "List Comprehension",
    "text": "List Comprehension\nWhat is List Comprehension?\n\n\nA concise way to create or modify lists.\nSyntax: [expression for item in iterable if condition]\n\n\nCreating a List of Squares:\n\nsquares = [x**2 for x in range(5)]\n\nFiltering Items:\n\nnumbers = [1, 2, 3, 4, 5, 6]\nevens = [x for x in numbers if x != 2]"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#dictionary-comprehension",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#dictionary-comprehension",
    "title": "Lecture 5",
    "section": "Dictionary Comprehension",
    "text": "Dictionary Comprehension\nWhat is Dictionary Comprehension?\n\n\nA concise way to create or modify dictionaries.\nSyntax: {key_expression: value_expression for item in iterable if condition}\n\n\nCreating a Dictionary of Squares:\n\nsquares_dict = {x: x**2 for x in range(5)}\n\nFiltering Dictionary Items:\n\n   my_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n   filtered_dict = {k: v for k, v in my_dict.items() if v != 2}\n\nSwapping Keys and Values:\n\noriginal_dict = {'a': 1, 'b': 2, 'c': 3}\nswapped_dict = {v: k for k, v in original_dict.items()}"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#modifying-a-list",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#modifying-a-list",
    "title": "Lecture 5",
    "section": "Modifying a List",
    "text": "Modifying a List\nAdding Items\n\n\nappend(): Adds an item to the end of the list.\n\nmy_list = [1, 2, 3]\nmy_list.append(4)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#modifying-a-list-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#modifying-a-list-1",
    "title": "Lecture 5",
    "section": "Modifying a List",
    "text": "Modifying a List\nDeleting Items\n\n\nremove(): Deletes the first occurrence of value in the list.\n\nmy_list = [1, 2, 3, 4, 2]\nmy_list.remove(2)\n\nList Comprehension: Removes items based on a condition.\n\nmy_list = [1, 2, 3, 4, 2]\nmy_list = [x for x in my_list if x != 2]  \n\ndel statement: Deletes an item by index or a slice of items.\n\nmy_list = [1, 2, 3, 4]\ndel my_list[1] \ndel my_list[1:3]"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#modifying-a-dictionary",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#modifying-a-dictionary",
    "title": "Lecture 5",
    "section": "Modifying a Dictionary",
    "text": "Modifying a Dictionary\nAdding/Updating Items\n\n\nupdate(): Adds new key-value pairs or updates existing ones.\n\nmy_dict = {'a': 1, 'b': 2}\nmy_dict.update({'c': 3})  \nmy_dict.update({'a': 10})"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#modifying-a-dictionary-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#modifying-a-dictionary-1",
    "title": "Lecture 5",
    "section": "Modifying a Dictionary",
    "text": "Modifying a Dictionary\nDeleting Items\n\n\nDictionary Comprehension: Removes items based on a condition.\n\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\nmy_dict = {k: v for k, v in my_dict.items() if v != 2}  \n\ndel statement: Deletes an item by key.\n\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\ndel my_dict['b']"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-1",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nException handlers\n\nIn some languages, errors are indicated by special function return values.\n\nPython uses exceptions: code that is executed when an associated error occurs.\n\nWhen we run code that might fail under some circumstances, we also need appropriate exception handlers to intercept any potential errors.\n\nAccessing a list or tuple with an out-of-range position, or a dictionary with a nonexistent key."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-2",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-2",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nErrors\nshort_list = [1, 2, 3]\nposition = 5\nshort_list[position]\n\nIf we don’t provide your own exception handler, Python prints an error message and some information about where the error occurred and then terminates the program:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-3",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-3",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nshort_list = [1, 2, 3]\nposition = 5\n\ntry:\n    short_list[position]\nexcept:\n    print('Need a position between 0 and', len(short_list)-1, ' but got',\n    position)\n\nRather than leaving things to chance, use try to wrap your code, and except to provide the error handling:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-4",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-4",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nshort_list = [1, 2, 3]\nposition = 5\ntry:\n    short_list[position]\nexcept:\n    print('Need a position between 0 and', len(short_list)-1, ' but got',\n    position)\n\nThe code inside the try block is run.\n\nIf there is an error, an exception is raised and the code inside the except block runs.\n\nIf there are no errors, the except block is skipped."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-5",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-5",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\n\n\nSpecifying a plain except with no arguments, as we did here, is a catchall for any exception type.\nIf more than one type of exception could occur, it’s best to provide a separate exception handler for each.\nWe get the full exception object in the variable name if we use the form:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-6",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-6",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\nshort_list = [1, 2, 3]\nwhile True:\n    value = input('Position [q to quit]? ')\n    if value == 'q':\n        break\n    try:\n        position = int(value)\n        print(short_list[position])\n    except IndexError as err:\n        print('Bad index:', position, '-', err)\n    except Exception as other:\n        print('Something else broke:', other)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-7",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-7",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\n\nThe example looks for an IndexError first, because that’s the exception type raised when we provide an illegal position to a sequence.\nIt saves an IndexError exception in the variable err, and any other exception in the variable other.\nThe example prints everything stored in other to show what you get in that object.\n\nInputting position 3 raised an IndexError as expected.\nEntering two annoyed the int() function, which we handled in our second, catchall except code."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-8",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#handle-errors-with-try-and-except-8",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nClass Exercises\n\nQ. Classwork 4.7"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\n\nPython is a general-purpose programming language and is not specialized for numerical or statistical computation.\nThe core libraries that enable Python to store and analyze data efficiently are:\n\npandas\nnumpy\nmatplotlib and seaborn"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-1",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-1",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\npandas\n\n\n\n\npandas provides Series and DataFrames which are used to store data in an easy-to-use format."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-2",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-2",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nnumpy\n\n\n\n\nnumpy, numerical Python, provides the array block (np.array()) for doing fast and efficient computations;"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-3",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-3",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nmatplotlib and seaborn\n\n\n\n\nmatplotlib provides graphics. The most important submodule would be matplotlib.pyplot.\nseaborn provides a general improvement in the default appearance of matplotlib-produced plots."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-4",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-4",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nimport statement\n\n\nA module is basically a bunch of related codes saved in a file with the extension .py.\nA package is basically a directory of a collection of modules.\nA library is a collection of packages\nWe refer to code of other module/package/library by using the Python import statement.\n\nimport LIBRARY_NAME\n\nThis makes the code and variables in the imported module available to our programming codes."
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-5",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#importing-modules-packages-and-libraries-5",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nimport statement\n\n\n\nas\n\nWe can use the as keyword when importing the module/package/library using its canonical names.\n\nimport LIBRARY as SOMETHING_SHORT\n\nfrom\n\nWe can use the from keyword when specifying Python module/package/library from which we want to import something.\n\nfrom LIBRARY import FUNCTION, PACKAGE, MODULE"
  },
  {
    "objectID": "danl-lec/danl-299-lec-05-2025-0910.html#installing-modules-packages-and-libraries",
    "href": "danl-lec/danl-299-lec-05-2025-0910.html#installing-modules-packages-and-libraries",
    "title": "Lecture 5",
    "section": "Installing Modules, Packages, and Libraries",
    "text": "Installing Modules, Packages, and Libraries\npip tool\n\n\n\n\nTo install a library LIBRARY on your Google Colab, run:\n\n!pip install LIBRARY\n\n\nTo install a library LIBRARY on your Anaconda Python, open your Spyder IDE, Anaconda Prompt, or Terminal and run:\n\npip install LIBRARY\n\n\n\nQ. Classwork 4.8"
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-1",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-1",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nTidy DataFrames\n\n\n\n\nThere are three interrelated rules that make a DataFrame tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-2",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-2",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\n\n\n\n\n\n\nA DataFrame can be given in a format unsuited for the analysis that we would like to perform on it.\n\nA DataFrame may have larger structural problems that extend beyond the data.\nPerhaps the DataFrame stores its values in a format that makes it easy to extract a single row but difficult to aggregate the data.\n\nReshaping a DataFrame means manipulating it into a different shape.\nIn this section, we will discuss pandas techniques for molding a DataFrame into the shape we desire."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#long-vs.-wide-dataframes",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#long-vs.-wide-dataframes",
    "title": "Lecture 12",
    "section": "Long vs. Wide DataFrames",
    "text": "Long vs. Wide DataFrames\n\n\nThe following DataFrames measure temperatures in two cities over two days.\n\n\nimport pandas as pd\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\ndf_wide = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday'],\n    'Miami': [80, 83],\n    'Rochester': [57, 62],\n    'St. Louis': [71, 75]\n})\n\ndf_long = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Wednesday'],\n    'City': ['Miami', 'Miami', 'Rochester', 'Rochester', 'St. Louis', 'St. Louis'],\n    'Temperature': [80, 83, 57, 62, 71, 75]\n})"
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#long-vs.-wide-dataframes-1",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#long-vs.-wide-dataframes-1",
    "title": "Lecture 12",
    "section": "Long vs. Wide DataFrames",
    "text": "Long vs. Wide DataFrames\n\nA DataFrame can store its values in wide or long format.\nThese names reflect the direction in which the data set expands as we add more values to it.\n\nA long DataFrame increases in height.\nA wide DataFrame increases in width."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#long-vs.-wide-dataframes-2",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#long-vs.-wide-dataframes-2",
    "title": "Lecture 12",
    "section": "Long vs. Wide DataFrames",
    "text": "Long vs. Wide DataFrames\n\nThe optimal storage format for a DataFrame depends on the insight we are trying to glean from it.\n\nWe consider making DataFrames longer if one variable is spread across multiple columns.\nWe consider making DataFrames wider if one observation is spread across multiple rows."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-3",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-3",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nmelt() and pivot()\n\n\n\n\nmelt() makes DataFrame longer.\npivot() makes DataFrame wider."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#make-dataframe-longer-with-melt",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#make-dataframe-longer-with-melt",
    "title": "Lecture 12",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#make-dataframe-longer-with-melt-1",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#make-dataframe-longer-with-melt-1",
    "title": "Lecture 12",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the “identifier”."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#make-dataframe-longer-with-melt-2",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#make-dataframe-longer-with-melt-2",
    "title": "Lecture 12",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#make-dataframe-wider-with-pivot",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#make-dataframe-wider-with-pivot",
    "title": "Lecture 12",
    "section": "Make DataFrame Wider with pivot()",
    "text": "Make DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-4",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-4",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet’s consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-5",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-5",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet’s consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2022\": [1, 2, 3, 1],\n             \"2023\": [2, 3, 4, 2],\n             \"2024\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-6",
    "href": "danl-lec/danl-299-lec-12-2025-1006.html#reshaping-dataframes-6",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet’s do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#workflow-for-file-management-1",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#workflow-for-file-management-1",
    "title": "Lecture 6",
    "section": "Workflow for File Management",
    "text": "Workflow for File Management\n\nSave your Jupyter Notebook for each class to a dedicated directory in your local laptop, Google Drive, or a new GitHub repo.\n\nGo to File and select Save …/ ( e.g., danl-210-lec-08-2025-0210.ipynb)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#workflow-for-file-management-2",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#workflow-for-file-management-2",
    "title": "Lecture 6",
    "section": "Workflow for File Management",
    "text": "Workflow for File Management\nYour Personal Website\n\nIn your local website project directory, avoid having\n\nAny file that exceeds 30 MB in size;\n.ipynb files you do not use for your website.\n\nYour website project directory should include files specifically dedicated to your website."
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#workflow-for-file-management-3",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#workflow-for-file-management-3",
    "title": "Lecture 6",
    "section": "Workflow for File Management",
    "text": "Workflow for File Management\nJupyter Notebooks for Your Webpage\n\nRun Python code cells in a Jupyter Notebook (.ipynb) on Google Colab. Then, download the Jupyter Notebook from Google Colab.\nUse the Finder/File Explorer to move the Jupyter Notebook file (.ipynb) to your website project directory. (If it is for a blog post, create a subdirectory in the posts directory, and move it to the subdirectory.)\nEdit _quarto.yml properly. Save the changes by clicking the floppy disk icon (💾).\nOn Terminal, run quarto render.\nOnce quarto render completes, view the index.html in your website working directory to see the HTML output.\nAfter confirming the HTML output, use the 3-step git commands (add-commit-push) on Terminal to update your online website."
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#pandas-basics",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#pandas-basics",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLearning Objectives\n\nLoading DataFrame with read_csv()\nGetting a Summary with info() and describe()\nSelecting and Relocating Variables with []\nCounting Values with value_counts(), nunique(), and count()\nSorting with sort_values() and sort_index()\nIndexing with set_index() and reset_index()\nLocating Observations and Values with loc[] and iloc[]\nMathematical & Vectorized Operations\nAdding, Removing, and Renaming Variables\nConverting Data Types with .astype()\nFiltering Observations"
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#pandas-basics-1",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#pandas-basics-1",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLearning Objectives\n\nDealing with Missing Values\nDealing wit Duplicates\nReshaping DataFrames with .melt() and .pivot()\nJoining DataFrames with .merge()\nConcatenating DataFrames"
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#data-collection",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#data-collection",
    "title": "Lecture 6",
    "section": "Data Collection",
    "text": "Data Collection\nLearning Objectives\n\nScrapping web tables with .read_html()\nScrapping web data with selenium\nCollecting web data with Application Programming Interfaces (APIs)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#pandas-group-operations-data-visualization",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#pandas-group-operations-data-visualization",
    "title": "Lecture 6",
    "section": "Pandas Group Operations & Data Visualization",
    "text": "Pandas Group Operations & Data Visualization\nLearning Objectives\n\nUsing Custom Functions and Anonymous Functions\nGrouping DataFrames with groupby(), .agg(), and .transform()\nVisualizing DataFrames with seaborn"
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#series-and-dataframe",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#series-and-dataframe",
    "title": "Lecture 6",
    "section": "Series and DataFrame",
    "text": "Series and DataFrame\n\n\n\n\nSeries: a collection of a one-dimensional object containing a sequence of values.\nDataFrame: a collection of Series columns with an index."
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#importing-a-data-set-with-read_csv",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#importing-a-data-set-with-read_csv",
    "title": "Lecture 6",
    "section": "Importing a data set with read_csv()",
    "text": "Importing a data set with read_csv()\n\n\nA CSV (comma-separated values) is a plain-text file that uses a comma to separate values (e.g., nba.csv).\nThe CSV is widely used for storing data, and we will use this throughout the module.\nWe use the read_csv() function to load a CSV data file.\n\nimport pandas as pd\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")\ntype(nba)\nnba\n\n\nThe DataFrame is the workhorse of the pandas library and the data structure."
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#importing-a-data-set-with-read_csv-1",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#importing-a-data-set-with-read_csv-1",
    "title": "Lecture 6",
    "section": "Importing a data set with read_csv()",
    "text": "Importing a data set with read_csv()\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])\nnba\n\nWe can use the parse_dates parameter to coerce the values into datetimes."
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#loading-data-1",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#loading-data-1",
    "title": "Lecture 6",
    "section": "Loading Data",
    "text": "Loading Data\nMounting Google Drive on Google Colab\n\n\nfrom google.colab import drive, files\ndrive.mount('/content/drive')\nfiles.upload()\n\ndrive.mount('/content/drive')\n\nTo mount your Google Drive on Google colab:\n\nfiles.upload()\n\nTo initiate uploading a file on Google Drive:\n\n\n\n\nTo find a pathname of a CSV file in Google Drive:\n\nClick 📁 from the sidebar menu\ndrive ➡️ MyDrive …\nHover a mouse cursor on the CSV file\nClick the vertical dots\nClick “Copy path”"
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#loading-data-2",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#loading-data-2",
    "title": "Lecture 6",
    "section": "Loading Data",
    "text": "Loading Data\nColab’s Interactive DataFrame Display\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()  # Enabling an interactive DataFrame display\nnba\n\nColab includes an extension that renders pandas DataFrames into interactive displays."
  },
  {
    "objectID": "danl-lec/danl-299-lec-06-2025-0917.html#loading-data-3",
    "href": "danl-lec/danl-299-lec-06-2025-0917.html#loading-data-3",
    "title": "Lecture 6",
    "section": "Loading Data",
    "text": "Loading Data\nAnother Interactive DataFrame Display\n# !pip install itables\nfrom itables import init_notebook_mode, show\ninit_notebook_mode(all_interactive=False)\nshow(nba)\n\nitables provides similar interactive displays for DataFrames.\n\nFor a blog post, itables‘s interactive displays may work better than google.colab’ ones."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-1",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-1",
    "title": "Lecture 13",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more DataFrames based on common data values in those DataFrames.\n\nThis task is known in the database world as performing a “join.”\nWe can do this with the merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-2",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-2",
    "title": "Lecture 13",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nJoin, Relational Data, and Keys\n\n\n\n\n\n\n\n\nThe variables that are used to connect each pair of DataFrames are called keys.\nEach observation in a DataFrame is often uniquely identified by key variable(s).\nThe key variable enables relationships between the DataFrames to be defined."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the “key” variable.\nThe grey column represents the “value” variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-1",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-1",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nInner Join\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n# the default value for 'how' is 'inner'\n# so it doesn't actually need to be specified\nmerge_inner_1 = pd.merge(x, y, on='key')\nmerge_inner_2 = pd.merge(x, y, on='key', how='inner')\nmerge_inner_3 = x.merge(y, on='key')\nmerge_inner_4 = x.merge(y, on='key', how='inner')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-2",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-2",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLeft Join\n\nA left join keeps all observations in x.\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-3",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-3",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nRight Join\n\nA right join keeps all observations in y.\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-4",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-4",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nOuter (Full) Join\n\nA full join keeps all observations in x and y.\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-5",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-5",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: one-to-many\n\nOne DataFrame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key':[1, 2, 2, 3],\n    'val_x':['x1', 'x2', 'x3', 'x4']})\n\ny = pd.DataFrame({\n    'key':[1, 2],\n    'val_y':['y1', 'y2'] })\none_to_many = x.merge(y, on='key', \n                         how='left')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-6",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-6",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: many-to-many\n\nBoth DataFrames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key':[1, 2, 2, 3],\n  'val_x':['x1','x2','x3','x4']})\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', \n                          how='left')\n\n\n\nIn practice, it is better to avoid the many-to-many join."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-7",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-7",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDefining the key columns\n\n\nIf the left and right columns do not have the same name for the key variables, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = \n  x.merge(y, left_on = 'key_x', \n             right_on = 'key_y', \n             how = 'left')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-8",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#joining-dataframes-with-merge-8",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLet’s do Part 2 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-1",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-1",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\n\nConcatenation involves combining multiple DataFrames by adding rows or columns. This method is useful:\n\nWhen merging datasets that were split into parts;\nWhen appending new data to an existing dataset.\n\nLet’s consider the following example DataFrames:\n\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-2",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-2",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nConcatenating the DataFrames on top of each other uses the concat() method.\n\nrow_concat = pd.concat([df1, df2, df3])\n\n\nAll of the DataFrames to be concatenated are passed in a list.\n\npd.concat( [DataFrame_1, DataFrame_2, ... , DataFrame_N] )"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-3",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-3",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nConcatenating columns is very similar to concatenating rows.\n\nThe main difference is the axis parameter in the concat() method.\nThe default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion.\nIf we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\n\n\npd.concat([df1, df2, df3], axis = \"columns\")\npd.concat([df1, df2, df3], axis = \"columns\", ignore_index = True)  \n\nignore_index=True to reset the column indices"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-4",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-4",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd a Series?\n\n\nLet’s consider a new Series and concatenate it with df1:\n\n# create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\n\n# attempt to add the new row to a DataFrame\ndf = pd.concat([df1, new_row_series])\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-5",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-5",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd a Series?\n\n\nTo fix the problem, we need turn our Series into a DataFrame.\n\nThis DataFrame contains one row of data, and the column names are the ones the data will bind to.\n\n\nnew_row_df = pd.DataFrame(\n  # note the double brackets to create a \"row\" of data\n  data =[ [\"n1\", \"n2\", \"n3\", \"n4\"] ],\n  columns = df1.columns,\n)\n\ndf = pd.concat([df1, new_row_df])\n\n\nHow about this?\n\npd.concat([df1, new_row_series], axis = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-6",
    "href": "danl-lec/danl-299-lec-13-2025-1006.html#data-concatenation-6",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet’s do Part 3 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#why-data-analytics",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#why-data-analytics",
    "title": "Lecture 2",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nFill in the gaps left by traditional business and economics classes.\n\nPractical skills that will benefit your future career.\nNeglected skills like how to actually find datasets in the wild and clean them.\n\nData analytics skills are largely distinct from (and complementary to) the core quantitative works familiar to business undergrads.\n\nData visualization, cleaning and wrangling; databases; machine learning; etc.\n\nIn short, we will cover things that I wish someone had taught me when I was undergraduate."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#you-at-the-end-of-this-course",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#you-at-the-end-of-this-course",
    "title": "Lecture 2",
    "section": "You, at the end of this course",
    "text": "You, at the end of this course"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#why-data-analytics-1",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#why-data-analytics-1",
    "title": "Lecture 2",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nData analysts use analytical tools and techniques to extract meaningful insights from data.\n\nSkills in data analytics are also useful for business analysts, market analysts, financial analysts, human resource analysts, or economists.\n\nBreau of Labor Statistics forecasts that the projected growth rate of the employment in the industry related to data analytics from 2021 to 2031 is 36%.\n\nThe average growth rate for all occupations is 5%."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#why-r-python-and-databases",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#why-r-python-and-databases",
    "title": "Lecture 2",
    "section": "Why R, Python, and Databases?",
    "text": "Why R, Python, and Databases?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#why-r-python-and-databases-1",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#why-r-python-and-databases-1",
    "title": "Lecture 2",
    "section": "Why R, Python, and Databases?",
    "text": "Why R, Python, and Databases?\nStack Overflow Trends\n\n\nStack Overflow is the most popular Q & A website specifically for programmers and software developers in the world.\nSee how programming languages have trended over time based on use of their tags in Stack Overflow from 2008 to 2023.\n\n\n\n\nMost Popular Languagues\n\n\nData Science and Big Data"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#data-analytics-and-generative-artificial-intelligence-ai",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#data-analytics-and-generative-artificial-intelligence-ai",
    "title": "Lecture 2",
    "section": "Data Analytics and Generative Artificial Intelligence (AI)",
    "text": "Data Analytics and Generative Artificial Intelligence (AI)\n\n\nData Analytics and Big Data Trend\nFrom 2008 to 2025\n\n\nProgrammers in 2025"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#data-analytics-and-generative-ai",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#data-analytics-and-generative-ai",
    "title": "Lecture 2",
    "section": "Data Analytics and Generative AI",
    "text": "Data Analytics and Generative AI\n\nGenerative AI refers to a category of AI that is capable of generating new content, ranging from text, images, and videos to music and code.\n\n\n\nIn the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input.\n\nThese include large language model (LLM) chatbots (e.g., ChatGPT, Claude, Gemini, Copilot, Grok).\n\nChatGPT (Chat Generative Pre-trained Transformer) is a chatbot developed by OpenAI and launched on November 30, 2022.\n\nBy January 2023, it had become what was then the fastest-growing consumer software application in history."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#data-analytics-and-generative-ai-1",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#data-analytics-and-generative-ai-1",
    "title": "Lecture 2",
    "section": "Data Analytics and Generative AI",
    "text": "Data Analytics and Generative AI\n\nUsers around the world have explored how to best utilize GPT for writing essays and programming codes.\n\n\n\n\nIs AI a threat to data analytics?\n\nFundamental understanding of the subject matter is still crucial for effectively utilizing AI’s capabilities.\n\n\n\n\n\nIf you use Generative AI such as ChatGPT, please try to understand what ChatGPT gives you.\n\nCopying and pasting it without any understanding harms your learning opportunity."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-r",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-r",
    "title": "Lecture 2",
    "section": "What is R?",
    "text": "What is R?\n\nR is a programming language and software environment designed for statistical computing and graphics.\nR has become a major tool in data analysis, statistical modeling, and visualization.\n\nIt is widely used among statisticians and data scientists for developing statistical software and performing data analysis.\nR is open source and freely available."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-rstudio",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-rstudio",
    "title": "Lecture 2",
    "section": "What is RStudio?",
    "text": "What is RStudio?\n\nRStudio is an integrated development environment (IDE) for R.\n\nAn IDE is a software application that provides comprehensive facilities (e.g., text code editor, graphical user interface (GUI)) to computer programmers for software development.\n\nRStudio is a user-friendly interface that makes using R easier and more interactive.\n\nIt provides a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging, and workspace management.\n\nWe will use a free cloud version of RStudio, which is Posit Cloud."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-python",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-python",
    "title": "Lecture 2",
    "section": "What is Python?",
    "text": "What is Python?\n\nPython is a versatile programming language known for its simplicity and readability.\nPython has become a dominant tool in various fields including data analysis, machine learning, and web development.\n\nIt is widely used among developers, data scientists, and researchers for building applications and performing data-driven tasks.\nPython is open source and has a vast ecosystem of libraries and frameworks."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-jupyter",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-jupyter",
    "title": "Lecture 2",
    "section": "What is Jupyter?",
    "text": "What is Jupyter?\n\nJupyter is an open-source integrated development environment (IDE) primarily for Python, though it supports many other languages.\n\nJupyter provides a notebook interface that allows users to write and execute code in a more interactive and visual format.\n\nJupyter Notebook is a user-friendly environment that enhances coding, data analysis, and visualization.\n\nIt offers a web-based interface that combines live code, equations, visualizations, and narrative text.\nJupyter is widely used for data science, machine learning, and research, enabling easy sharing and collaboration.\n\nYou can use a free cloud version of Jupyter, which is Google Colab.\n\nGoogle Colab can be used for R as well."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#python-vs.-r",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#python-vs.-r",
    "title": "Lecture 2",
    "section": "Python vs. R",
    "text": "Python vs. R"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-git",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-git",
    "title": "Lecture 2",
    "section": "What is Git?",
    "text": "What is Git?\n\n\n\n\n\\(\\quad\\)\n\nGit is the most popular version control tool for any software development.\n\nIt tracks changes in a series of snapshots of the project, allowing developers to revert to previous versions, compare changes, and merge different versions.\nIt is the industry standard and ubiquitous for coding collaboration."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-github",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-github",
    "title": "Lecture 2",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\nGitHub is a web-based hosting platform for Git repositories to store, manage, and share code.\nOur course website is hosted on a GitHub repository.\nCourse contents will be posted not only in Brightspace but also in my GitHub repositories (“repos”).\nGithub is useful for many reasons, but the main reason is how user friendly it makes uploading and sharing code."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-github-1",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#what-is-github-1",
    "title": "Lecture 2",
    "section": "What is GitHub?",
    "text": "What is GitHub?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-1",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-1",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nAnaconda\n\nTo install Anaconda, go to the following download page:\n\nhttps://www.anaconda.com/products/distribution.\nClick the “Download” button."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-2",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-2",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR programming\n\nThe R language is available as a free download from the R Project website at:\n\nWindows: https://cran.r-project.org/bin/windows/base/\nMac: https://cran.r-project.org/bin/macosx/\nDownload the file of R that corresponds to your Mac OS (Big Sur, Apple silicon arm64, High Sierra, El Capitan, Mavericks, etc.)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-3",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-3",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR Studio\n\n\nThe RStudio Desktop is available as a free download from the following webpage:\n\nhttps://www.rstudio.com/products/rstudio/download/#download\n\n\n\n\n\n\nFor Mac users, try the following steps:\n\nRun RStudio-*.dmg file.\nFrom the Pop-up menu, click the RStudio icon.\nWhile clicking the RStudio icon, drag it to the Applications directory."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-4",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-4",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\nScript Pane is where you write R commands in a script file that you can save.\n\n\n\nAn R script is simply a text file containing R commands.\nRStudio will color-code different elements of your code to make it easier to read.\n\n\n\n\n\n\n\n\nTo open an R script,\n\nFile \\(&gt;\\) New File \\(&gt;\\) R Script\n\n\n\n\n\n\nTo save the R script,\n\nFile \\(&gt;\\) Save"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-5",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-5",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\nConsole Pane allows you to interact directly with the R interpreter and type commands where R will immediately execute them."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-6",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-6",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\nEnvironment Pane is where you can see the values of variables, data frames, and other objects that are currently stored in memory.\nType below in the Console Pane, and then hit Enter:\n\na &lt;- 1"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-7",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-7",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\nPlots Pane contains any graphics that you generate from your R code."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-8",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-8",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR Packages and tidyverse\n\nR packages are collections of R functions, compiled code, and data that are combined in a structured format.\n\n\n\nThe tidyverse is a collection of R packages designed for data science that share an underlying design philosophy, grammar, and data structures.\n\nThe tidyverse packages work harmoniously together to make data manipulation, exploration, and visualization more.\nWe will use several R packages from tidyverse throughout the course. (e.g., ggplot2, dplyr, tidyr)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-9",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-9",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nInstalling R packages with install.packages(\"packageName\")\n\nR packages can be easily installed from within R using functions install.packages(\"packageName\").\n\nTo install the R package tidyverse, type and run the following from R console:\n\n\n\ninstall.packages(\"tidyverse\")\n\nWhile running the above codes, you may encounter the question below from the R Console:\n\n\n\n\nMac: “Do you want to install from sources the packages which need compilation?” from Console Pane.\n\n\n\nWindows: “Would you like to use a personal library instead?” from Pop-up message.\n\n\n\n\nType no in the R Console, and then hit Enter."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-10",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-10",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nLoading R packages with library(packageName)\n\nOnce installed, a package is loaded into an R session using library(packageName) so that its functions and data can be used.\n\nTo load the R package tidyverse, type and run the following command from a R script:\n\n\nlibrary(tidyverse)\ndf_mpg &lt;- mpg\n\n\nmpg is the data.frame provided by the R package ggplot2, one of the R pakcages in tidyverse."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-11",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#installing-the-tools-11",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Options Setting\n\n\n\n\n\nThis option menu is found by menus as follows:\n\nTools \\(&gt;\\) Global Options\n\nCheck the boxes as in the left.\nChoose the option Never for  Save workspace to .RData on exit:"
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#building-a-personal-website-on-github",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#building-a-personal-website-on-github",
    "title": "Lecture 2",
    "section": "Building a Personal Website on GitHub",
    "text": "Building a Personal Website on GitHub\n\nFollow steps described in Classwork 1."
  },
  {
    "objectID": "danl-lec/danl-299-lec-02-2025-0827.html#lets-practice-markdown",
    "href": "danl-lec/danl-299-lec-02-2025-0827.html#lets-practice-markdown",
    "title": "Lecture 2",
    "section": "Let’s Practice Markdown!",
    "text": "Let’s Practice Markdown!\n\nJupyter Notebook, Quarto, and GitHub-based Discussion Boards use markdown as its underlying document syntax.\nLet’s do Classwork 2."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#nba-dataframe",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#nba-dataframe",
    "title": "Lecture 9",
    "section": "nba DataFrame",
    "text": "nba DataFrame\n\n\nLet’s read the nba.csv file as nba:\n\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])"
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#mathematical-operations",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#mathematical-operations",
    "title": "Lecture 9",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\nnba.max()\nnba.min()\n\nThe max() method returns a Series with the maximum value from each variable.\nThe min() method returns a Series with the minimum value from each variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#mathematical-operations-1",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#mathematical-operations-1",
    "title": "Lecture 9",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\n\n\nnba.sum()\nnba.mean()\nnba.median()\nnba.quantile(0.75) # 0 to 1\nnba.std()\n\nnba.sum(numeric_only = True)\nnba.mean(numeric_only = True)\nnba.median(numeric_only = True)\nnba.quantile(0.75, numeric_only=True)\nnba.std(numeric_only = True)\n\n\n\nThe sum()/mean()/median() method returns a Series with the sum/mean/median of the values in each variable.\nThe quantile() method returns a Series with the percentile value of the values in each variable (e.g., 25th, 75th, 90th percentile).\nThe std() method returns a Series with the standard deviation of the values in each variable.\nTo limit the operation to numeric volumes, we can pass True to the sum()/mean()/median()/std() method’s numeric_only parameter."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#vectorized-operations",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#vectorized-operations",
    "title": "Lecture 9",
    "section": "Vectorized Operations",
    "text": "Vectorized Operations\nnba[\"Salary_2x\"] = nba[\"Salary\"] + nba[\"Salary\"]\nnba[\"Name_w_Position\"] = nba[\"Name\"] + \" (\" + nba[\"Position\"] + \")\"\nnba[\"Salary_minus_Mean\"] = nba[\"Salary\"] - nba[\"Salary\"].mean()\n\npandas performs a vectorized operation on Series or a variable in DataFrame.\n\nThis means an element-by-element operation.\nThis enables us to apply functions and perform operations on the data efficiently, without the need for explicit loops."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#adding-and-removing-variables",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#adding-and-removing-variables",
    "title": "Lecture 9",
    "section": "Adding and Removing Variables",
    "text": "Adding and Removing Variables\n\n\nHere we use [] to add variables:\n\nnba['Salary_k'] = nba['Salary'] / 1000\nnba['Salary_2x'] = nba['Salary'] + nba['Salary']\nnba['Salary_3x'] = nba['Salary'] * 3"
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#removing-variables-with-dropcolumns-...",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#removing-variables-with-dropcolumns-...",
    "title": "Lecture 9",
    "section": "Removing Variables with drop(columns = ... )",
    "text": "Removing Variables with drop(columns = ... )\n\n\nWe can use .drop(columns = ...) to drop variables:\n\nnba.drop(columns = \"Salary_k\")\nnba.drop(columns = [\"Salary_2x\", \"Salary_3x\"])"
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#renaming-variables-with-nba.columns",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#renaming-variables-with-nba.columns",
    "title": "Lecture 9",
    "section": "Renaming Variables with nba.columns",
    "text": "Renaming Variables with nba.columns\n\n\nDo you recall the .columns attribute?\n\nnba.columns\n\nWe can rename any or all of a DataFrame’s columns by assigning a list of new names to the attribute:\n\nnba.columns = [\"Team\", \"Position\", \"Date of Birth\", \"Income\"]"
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "title": "Lecture 9",
    "section": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )\nnba.rename( columns = { \"Date of Birth\": \"Birthday\" } )\n\nThe above rename() method renames the variable Date of Birth to Birthday."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#renaming-rows-with-rename-index-existing-one-new-one",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#renaming-rows-with-rename-index-existing-one-new-one",
    "title": "Lecture 9",
    "section": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )\nnba = nba.rename(\n    index = { \"LeBron James\": \"LeBron Raymone James\" }\n)\n\nThe above rename() method renames the observation LeBron James to LeBron Raymone James."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-1",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-1",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() Method",
    "text": "Converting Data Types with the astype() Method\n\n\nLet’s read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-2",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-2",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\n\n\nWhat values are in the Mgmt variable?\n\n\nemp[\"Mgmt\"].astype(bool)\n\nThe astype() method converts a Series’ values to a different data type.\n\nIt can accept a single argument: the new data type."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-3",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-3",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Mgmt\"] = emp[\"Mgmt\"].astype(bool)\n\nThe above code overwrites the Mgmt variable with our new Series of Booleans."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-4",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-4",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"].astype(int)\n\nThe above code tries to coerce the Salary variable’s values to integers with the astype() method.\n\nPandas is unable to convert the NaN values to integers."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#fill-missing-values-with-the-fillna-method",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#fill-missing-values-with-the-fillna-method",
    "title": "Lecture 9",
    "section": "Fill Missing Values with the fillna() method",
    "text": "Fill Missing Values with the fillna() method\nemp[\"Salary\"].fillna(0)\n\nThe fillna() method replaces a Series’ missing values with the argument we pass in.\nThe above example provides a fill value of 0.\n\nNote that our choice of value can distort the data; 0 is passed solely for the sake of example."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-5",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-5",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0).astype(int)\n\nThe above code overwrites the Salary variable with our new Series of integers."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-6",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-6",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n\nPandas includes a special data type called a category,\n\nIt is ideal for a variable consisting of a small number of unique values relative to its total number of values.\nE.g., gender, weekdays, blood types, planets, and income groups."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-pd.to_datetime-method",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-pd.to_datetime-method",
    "title": "Lecture 9",
    "section": "Converting Data Types with the pd.to_datetime() method",
    "text": "Converting Data Types with the pd.to_datetime() method\n# Below two are equivalent:\nemp[\"Start Date\"] = pd.to_datetime(emp[\"Start Date\"])\nemp[\"Start Date\"] = emp[\"Start Date\"].astype('datetime64[ns]')\n\nThe pd.to_datetime() function is used to convert a Series, DataFrame, or a single variable of a DataFrame from its current data type into datetime format."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-7",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#converting-data-types-with-the-astype-method-7",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\n\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0)\nemp = emp.astype({'Mgmt': 'bool', \n                  'Salary': 'int',\n                  'Gender': 'category',\n                  'Start Date': 'datetime64[ns]',\n                  'Team': 'category'})\n\nWe can provide a dictionary of variable-type pairs to astype()."
  },
  {
    "objectID": "danl-lec/danl-299-lec-09-2025-0929.html#pandas-basics",
    "href": "danl-lec/danl-299-lec-09-2025-0929.html#pandas-basics",
    "title": "Lecture 9",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Question 1 in Classwork 6!"
  },
  {
    "objectID": "danl-rw/danl-299-project.html#esg_proj_2024_data",
    "href": "danl-rw/danl-299-project.html#esg_proj_2024_data",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "1. esg_proj_2024_data",
    "text": "1. esg_proj_2024_data\n\nThe esg_proj_2024_data DataFrame which provides a list of companies and associated information, including ESG scores.\n\n\nimport pandas as pd\nurl_2024 = \"https://bcdanl.github.io/data/esg_proj_2024_data.csv\"\nesg_proj_2024_data = pd.read_csv(url_2024)\n\n\n\n\n  \n\n\n\n\nVariable Description\n\nSymbol: a company’s ticker;\nCompany Name: a company name;\nSector: a sector a company belongs to;\nIndustry: an industry a company belongs to;\nCountry: a country a company belongs to;\nMarket_Cap: a company’s market capitalization as of December 20, 2024 (Source: Nasdaq’s Stock Screener).\n\nA company’s market capitalization is the value of the company that is traded on the stock market, calculated by multiplying the total number of shares by the present share price.\n\nIPO_Year: the year a company first went public by offering its shares to be traded on a stock exchange.\nTotal_ESG: The overall ESG (Environmental, Social, and Governance) risk score, summarizing the company’s exposure to ESG-related risks as of March 31, 2024. A lower score indicates lower risk.\nEnvironmental: The company’s exposure to environmental risks (e.g., emissions, energy use, environmental policy) as of March 31, 2024. A lower score indicates lower risk.\nSocial: The company’s exposure to social risks (e.g., labor practices, human rights, diversity, and customer relations) as of March 31, 2024. A lower score indicates lower risk.\nGovernance: The company’s exposure to governance-related risks (e.g., board structure, executive pay, shareholder rights, transparency) as of March 31, 2024. A lower score indicates lower risk.\nControversy: A score reflecting the severity of recent ESG-related controversies involving the company as of March 31, 2024. Higher scores typically indicate greater or more serious controversies."
  },
  {
    "objectID": "danl-rw/danl-299-project.html#esg_proj_2025",
    "href": "danl-rw/danl-299-project.html#esg_proj_2025",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "2. esg_proj_2025",
    "text": "2. esg_proj_2025\n\nThe esg_proj_2025 DataFrame provides a list of companies and associated information.\n\n\nurl_2025 = \"https://bcdanl.github.io/data/esg_proj_2025.csv\"\nesg_proj_2025 = pd.read_csv(url_2025)\n\n\n\n\n  \n\n\n\n\nVariable Description\n\nMarket_Cap: a company’s market capitalization as of March 29, 2025."
  },
  {
    "objectID": "danl-rw/danl-299-project.html#stock_history_2023",
    "href": "danl-rw/danl-299-project.html#stock_history_2023",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "3. stock_history_2023",
    "text": "3. stock_history_2023\n\nThe stock_history_2023 DataFrame contains daily historical stock market data for the year 2023.\n\n\nurl = \"https://bcdanl.github.io/data/stock_history_2023.csv\"\nstock_history_2023 = pd.read_csv(url)\n\n\n\n\n  \n\n\n\nVariable Description\n\nSymbol: Company’s stock ticker\nDate: Trading date\nYear: Trading year\nOpen: Opening price on the date\nHigh: Highest price on the date\nLow: Lowest price on the date\nClose: Closing price on the date\nVolume: Trading volume\nDividend: Cash dividend paid per share on the date (if any), as reported by Yahoo Finance\nStock_Split: The ratio of any stock split that occurred on the given date."
  },
  {
    "objectID": "danl-rw/danl-299-project.html#data-collection",
    "href": "danl-rw/danl-299-project.html#data-collection",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "1. Data Collection",
    "text": "1. Data Collection\nFor data collection, include only the companies that are common to both the esg_proj_2024_data and esg_proj_2025 DataFrames.\n\nScraping web data falls into a legal gray area. In the U.S., scraping publicly available information is not illegal, but it is not always clearly allowed either.\n\nMost companies do not go after individuals for minor or non-commercial violations of their Terms of Service (ToS). Still, if the scraping causes harm, it can lead to legal trouble.\n\nTips for Collecting Data from Yahoo! Finance:\n\nScrape at a reasonable and moderate rate. To avoid overloading servers, use time.sleep(random.uniform(5, y)) between page visits.\nThe method of explicit waits are not required, but they are helpful for ensuring elements load before scraping.\nBe aware that some companies may not have data available for Environmental, Social, or Governance Risk Scores, or Controversy Level.\nConsider starting with the following setup for Selenium web-scrapping\n\n\n# %%\n# =============================================================================\n# Setup libraries\n# =============================================================================\nimport time\nimport random\nimport pandas as pd\nimport os\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\n# %%\n# =============================================================================\n# Setup working directory\n# =============================================================================\nwd_path = 'PATHNAME_OF_YOUR_WORKING_DIRECTORY'\nos.chdir(wd_path)\n\n\n# %%\n# =============================================================================\n# Setup WebDriver with options\n# =============================================================================\noptions = Options()\noptions.add_argument(\"window-size=1400,1200\")  # Set window size\noptions.add_argument('--disable-blink-features=AutomationControlled')  # Prevent detection of automation by disabling blink features\noptions.page_load_strategy = 'eager'  # Load only essential content first, skipping non-critical resources\n\ndriver = webdriver.Chrome(options=options)\n\n\na. ESG Data\n\nFor each company in the esg_proj_2025 DataFrame, employ the Python selenium library to gather ESG Risk Ratings, along with the Controversy Level from the Sustainability section of each company’s webpage on Yahoo! Finance, such as:\n\nApple Inc. (AAPL)\nMicrosoft Corporation (MSFT)\n\n\n\n\n\nb. Historical Stock Data\n\nFor each company found in both the esg_proj_2024_data and esg_proj_2025 DataFrames, employ the selenium library to retrieve:\n\nDaily stock prices from January 1, 2024, to March 31, 2025\n\ne.g., https://finance.yahoo.com/quote/MSFT/history/?p=MSFT&period1=1704067200&period2=1743446400\n1704067200 = January 1, 2024\n1743446400 = March 31, 2025\n\n\nNote: GOOGLEFINANCE function in Google Sheets is freely available for retrieving current or historical stock data.\n\nAlthough our course does not cover Google Sheets, you are welcome to use it to collect historical stock data if you prefer.\nIf you choose Google Sheets’ GOOGLEFINANCE() for collecting historical stock data, please share your Google Sheets with Prof. Choe.\n\n\n\n\nDividend Cleaning\nIf you scrape historical data tables from each company’s page on Yahoo Finance (e.g., MSFT Historical Data), you can construct a DataFrame similar to the df_all DataFrame shown below.\nThe df_all DataFrame contains stock data for Apple Inc., Microsoft, and Nvidia from the beginning of 2024 through the end of Q1 2025:\nimport pandas as pd\ndf_all = pd.read_csv('https://bcdanl.github.io/data/aapl_msft_nvda_2024_2025.csv')\n\n\n\n  \n\n\nNote that some rows in the df_all DataFrame include dividend declarations rather than price and volume data (e.g., Apple Inc. on February 10, 2025; Microsoft on February 20, 2025). These dividend entries appear in the Open/High/Low/Close/Adj Close/Volume columns as strings like “0.25 Dividend”.\n\nNote: Apple Inc’s “0.25 Dividend” means that on that specific date, Apple Inc issued a cash dividend of $0.01 per share.\n\nTo separate these dividend entries from the actual stock trading data, we use the str.contains() method:\n# Filter rows where the 'Open' column contains the word 'Dividend' (these represent dividend entries)\ndf_dividend = df_all[df_all['Open'].str.contains('Dividend', na=False)]\n\n# Filter out dividend rows to keep only stock price data\ndf_stock = df_all[~df_all['Open'].str.contains('Dividend', na=False)]\n\nAt this point:\n\ndf_stock does not include dividend announcements.\ndf_dividend includes only dividend announcements.\n\n\nWe now clean and format the dividend information:\n# Select only relevant columns for dividend data\ndf_dividend = df_dividend[['Date', 'Symbol', 'Open']]\n\n# Copy 'Open' column (which contains dividend information) into a new column named 'Dividend'\ndf_dividend['Dividend'] = df_dividend['Open']\n\n# Keep only the necessary columns: Date, Symbol, and Dividend\ndf_dividend = df_dividend[['Date', 'Symbol', 'Dividend']]\n\n# Remove the text \" Dividend\" from the Dividend column to isolate the numeric value\ndf_dividend['Dividend'] = df_dividend['Dividend'].str.replace(' Dividend', '')\n\n\n\nStock Split Cleaning\nSimilarly, some row in the df_stock DataFrame from the “Dividend Cleaning” subsection includes stock splits rather than price and volume data (e.g., Nvidia on June 10, 2024). These stock split entries appear in the Open/High/Low/Close/Adj Close/Volume columns as strings like “10:1 Stock Splits”.\nTo separate these stock split entries from the actual stock trading data, again we use the str.contains() method:\n# Filter rows where the 'Open' column contains the word 'Split' (these represent stock split entries)\ndf_split = df_stock[df_stock['Open'].str.contains('Split', na=False)]\n\n# Filter out dividend rows to keep only stock price data\ndf_stock = df_stock[~df_stock['Open'].str.contains('Split', na=False)]\n\nAt this point:\n\ndf_stock includes only daily stock trading information.\ndf_split includes only stock splits.\n\n\nWe now clean and format the split information:\n# Select only relevant columns for dividend data\ndf_split = df_split[['Date', 'Symbol', 'Open']]\n\n# Copy 'Open' column (which contains dividend information) into a new column named 'Split'\ndf_split['Split'] = df_split['Open']\n\n# Keep only the necessary columns: Date, Symbol, and Split\ndf_split = df_split[['Date', 'Symbol', 'Split']]\n\n# Remove the text \" Stock Splits\" from the Split column to isolate the numeric value\ndf_split['Split'] = df_split['Split'].str.replace(' Stock Splits', '')\n\nNote: NVDA’s “10:1 Stock Split” means that each existing share was split into 10 shares.\n\nIf you owned 1 share before June 10, 2024, you would own 10 shares after the split.\nTo maintain consistency, Yahoo Finance retroactively adjusts all historical prices and volumes to reflect stock splits.\n\nFor example, the table below shows NVDA’s adjusted stock prices and volumes from June 7–11, 2024:\n\n\n\n\n  \n\n\n\n\n\nExtracting the year from a datetime variable\n\nTo extract the year from a datetime variable in a pandas DataFrame, you can use the .dt.year accessor.\n\n# Sample DataFrame with string dates\ndata = {\n    'Symbol': ['AAPL', 'MSFT', 'GOOG'],\n    'Date': ['2024-12-29', '2024-12-30', '2025-01-03'],\n    'Close': [130.21, 265.78, 122.34]\n}\n\ndf = pd.DataFrame(data)\n\n# Convert 'Date' column to datetime\ndf['Date'] = df['Date'].astype('datetime64[ns]')\n\n# Extract year from 'Date' variable\ndf['Year'] = df['Date'].dt.year"
  },
  {
    "objectID": "danl-rw/danl-299-project.html#data-analysis",
    "href": "danl-rw/danl-299-project.html#data-analysis",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "2. Data Analysis",
    "text": "2. Data Analysis\n\nIf you are unable to complete the data collection tasks, please use the esg_proj_2024_data and stock_history_2023 DataFrames for your data analysis.\nIf you successfully completed the data collection tasks, you may “optionally” incorporate the stock_history_2023 DataFrame into your analysis as an additional data source.\nBelow are the key components in the data analysis webpage.\n\nTitle: A clear and concise title that gives an idea of the project topics.\nIntroduction:\n\nBackground: Provide context for the research questions, explaining why they are significant, relevant, or interesting.\nStatement of the Problem: Clearly articulate the specific problem or issue the project will address.\n\nData Collection: Use a Python script (*.py) to write the code and the comment on how to retrieve ESG data and historical stock data using Python selenium.\n\nDo NOT provide your code for data collection in your webpage. You should submit your Python script for data collection to Brightspace.\n\nDescriptive Statistics\n\n\nProvide both grouped and un-grouped descriptive statistics and distribution plots for the ESG data and the finance/accounting data\nOptionally, provide correlation heat maps using corr() and seaborn.heatmap(). Below provides the Python code for creating a correlation heatmap.\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Sample DataFrame with varied correlations\ndata = {\n    'Revenue': [100, 200, 300, 400, 500],  \n    'Profit': [20, 40, 60, 80, 100],       \n    'n_Employee': [50, 45, 40, 35, 30], \n    'n_Customer': [10, 11, 12, 13, 14]  \n}\n\n# Create a DataFrame from the dictionary\ndf = pd.DataFrame(data)\n\n# Calculate the correlation matrix of the DataFrame\ncorr = df.corr()\n\n# Set up the matplotlib figure size\nplt.figure(figsize=(8, 6))\n\n# Generate a heatmap in seaborn:\n# - 'corr' is the correlation matrix\n# - 'annot=True' enables annotations inside the squares with the correlation values\n# - 'cmap=\"coolwarm\"' assigns a color map from cool to warm (blue to red)\n# - 'fmt=\".2f\"' formats the annotations to two decimal places\n# - 'linewidths=.5' adds lines between each cell\nsns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n\n# Title of the heatmap\nplt.title('Correlation Heatmap with Varied Correlations')\n\n# Display the heatmap\nplt.show()\n\n\n\n\n\nExploratory Data Analysis:\n\nExplore the trend of ESG scores from 2024 to 2025.\nAdditionally, list the questions you aim to answer.\nAddress the questions through data visualization with seaborn (or lets-plot) and pandas methods and attributes.\n\nSignificance of the Project:\n\nExplain its implications for real-world applications, business strategies, or public policy.\n\nReferences\n\nList all sources cited in the project.\nLeave a web address of the reference if that is from the web.\nIndicate if the code and the write-up are guided by generative AI, such as ChatGPT. There will be no penalties on using any generative AI.\nClearly state if the code and the write-up result from collaboration with colleagues. There will be no penalties for collaboration, provided that the shared portions are clearly indicated."
  },
  {
    "objectID": "danl-rw/danl-299-project.html#interpreting-esg-data-on-yahoo-finance",
    "href": "danl-rw/danl-299-project.html#interpreting-esg-data-on-yahoo-finance",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "Interpreting ESG Data on Yahoo Finance 🧾",
    "text": "Interpreting ESG Data on Yahoo Finance 🧾\nIn Yahoo Finance, the ESG data helps investors evaluate a company’s sustainability profile and exposure to long-term environmental, social, and governance risks. Here’s how to interpret each metric:\n\n🔢 Total ESG Risk Score\n\nWhat it means: A composite score reflecting the company’s overall exposure to ESG-related risks.\nHow to interpret:\n\nLower score = lower risk → Better ESG performance.\n\nHigher score = higher risk → More vulnerable to ESG-related issues.\n\nExample: A company with total_ESG = 15 is considered to have lower ESG risk than one with total_ESG = 30.\n\n\n\n\n🌍 Environmental Risk Score\n\nWhat it measures: Exposure to environmental risks such as:\n\nCarbon emissions\n\nEnergy efficiency\n\nWaste management\n\nClimate change strategy\n\n\nInterpretation:\n\nLower score → better environmental practices.\nHigher score → more environmental liabilities or poor sustainability measures.\n\n\n\n\n👥 Social Risk Score\n\nWhat it measures: Exposure to social risks, including:\n\nLabor practices\n\nHuman rights\n\nInclusive culture and representation\nCustomer and community relations\n\n\nInterpretation:\n\nLower score = better social responsibility.\nHigher score = more risk from labor issues, PR problems, etc.\n\n\n\n\n🏛 Governance Risk Score\n\nWhat it measures: Exposure to governance-related risks, such as:\n\nBoard structure and independence\n\nExecutive compensation\n\nShareholder rights\n\nTransparency and ethics\n\n\nInterpretation:\n\nLower score suggests better corporate oversight.\nHigher score suggests poor governance structures.\n\n\n\n\n🚨 Controversy Level\n\nWhat it measures: Reflects recent ESG-related controversies involving the company.\nScale: Usually ranges from 0 (no controversies) to 5 (severe and ongoing issues).\nInterpretation:\n\nLow score (0–1): Minimal or no controversies.\nHigh score (4–5): Major controversies — potential reputational or legal risks.\nNote: A company may have good ESG scores but still be flagged due to a high controversy score.\n\n\n\n\n🧠 ESG Score Summary\n\n\n\nMetric\nGood Score\nBad Score\n\n\n\n\ntotal_ESG\nLow\nHigh\n\n\nEnvironmental\nLow\nHigh\n\n\nSocial\nLow\nHigh\n\n\nGovernance\nLow\nHigh\n\n\nControversy\n0–1\n4–5"
  },
  {
    "objectID": "danl-rw/danl-299-project.html#general-tips-on-data-visualization",
    "href": "danl-rw/danl-299-project.html#general-tips-on-data-visualization",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "General Tips on Data Visualization 📈",
    "text": "General Tips on Data Visualization 📈\n\nDistribution\nWhen describing the distribution of a variable, we are typically interested in several key characteristics:\n\nCenter: The central tendency of the data, such as the mean or median, which indicates the typical or average value.\nSpread: How spread the values are within the variable, showing the range and standard deviation of values.\nCommon Values: Identifying frequent values and the mode.\nRare Values: Recognizing unusual or infrequent values.\nShape: The overall shape of the distribution, such as whether it’s symmetric, skewed left or right, or having multiple groups with multiple peaks.\n\n\n\n\n\n\n\n\n\nRelationship Between Two Variables\n\nStart with determining whether the two variables have a positive association, a negative association, or no association.\n\n\nE.g., A negative slope in the fitted line indicates that sales decrease as the price increases, while a positive slope would indicate that sales increase with price. A zero slope means that there is no relationship between sales and price; changes in price do not affect sales.\n\n\n\n\n\n\n\n\nInput on the x-axis; output on the y-axis\n\n\nBy convention, the input (or predictor) variable is plotted on the x-axis, and the output (or response) variable on the y-axis.\nThis helps visualize potential relationships—though it shows correlation, not necessarily causation.\nCorrelation does not necessarily mean causation.\n\n\nWhen a question asks you to describe how the relationship varies by another categorical variable, examine both the direction of the slope (negative, positive, or none) from the fitted line and the steepness of the slope (steep or shallow).\n\n\nThe slope of the fitted straight line is the rate at which the “y” variable (like grades) changes as the “x” variable (like study hours) changes. In simple terms, it shows how much one thing goes up or down when the other thing changes.\nFor example, a comment such as, “The plot shows a negative relationship between sales and price” does not address how the relationship differs by brand.\n\n\nThe focus is on the relationship, not the distribution.\n\n\nWhile adding a comment on the distribution of a single variable can be helpful, the question is primarily about the relationship between the two variables.\n\n\n\n\nTime Trend of a Variable\nHere are some general tips for describing the time trend of a variable:\n\nStart with Identifying the Overall Trend\n\n\nLook for the general direction of the trend over time.\n\nIs it moving upward, downward, or remaining relatively constant?\n\n\n\nNote Patterns and Cycles\n\n\nIdentify any repeating patterns, such as seasonal fluctuations (e.g., monthly or quarterly changes) or long-term cycles.\n\nThese can reveal consistent influences that affect the variable over time.\n\n\n\nHighlight Any Significant Fluctuations\n\n\nDescribe any sharp increases, decreases, or irregular spikes in the data.\n\n\n\n\n\n\n\n\n\nInterpreting Visualization\n\nBe specific.\n\nAvoid vague statements. Below examples do not actually explain what the patterns are.\n\n“The plot shows how the time trend of a stock price varies across sectors, with each sector having a unique best fitting line and scatter pattern”\n“The trend shows the evolution of stock price in the market over time”\n\nClearly describe what is the pattern—and how it differs across categories.\n\nAdd Narration:\n\nConnect the visualization to real-world phenomena and/or your idea that could help explain it, adding insight into what is happening."
  },
  {
    "objectID": "danl-rw/danl-299-project.html#project-write-up",
    "href": "danl-rw/danl-299-project.html#project-write-up",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "Project Write-up",
    "text": "Project Write-up\n\n\n\n\n\n\n\n\n\n\n\n\nAttribute\nVery Deficient (1)\nSomewhat Deficient (2)\nAcceptable (3)\nVery Good (4)\nOutstanding (5)\n\n\n\n\n1. Quality of research questions\n• Not stated or very unclear• Entirely derivative• Anticipate no contribution\n• Stated somewhat confusingly• Slightly interesting, but largely derivative• Anticipate minor contributions\n• Stated explicitly• Somewhat interesting and creative• Anticipate limited contributions\n• Stated explicitly and clearly• Clearly interesting and creative• Anticipate at least one good contribution\n• Articulated very clearly• Highly interesting and creative• Anticipate several important contributions\n\n\n2. Quality of data visualization\n• Very poorly visualized• Unclear• Unable to interpret figures\n• Somewhat visualized• Somewhat unclear• Difficulty interpreting figures\n• Mostly well visualized• Mostly clear• Acceptably interpretable\n• Well organized• Well thought-out visualization• Almost all figures clearly interpretable\n• Very well visualized• Outstanding visualization• All figures clearly interpretable\n\n\n3. Quality of exploratory data analysis\n• Little or no critical thinking• Little or no understanding of data analytics concepts with Python\n• Rudimentary critical thinking• Somewhat shaky understanding of data analytics concepts with Python\n• Average critical thinking• Understanding of data analytics concepts with Python\n• Mature critical thinking• Clear understanding of data analytics concepts with Python\n• Sophisticated critical thinking• Superior understanding of data analytics concepts with Python\n\n\n4. Quality of business/economic analysis\n• Little or no critical thinking• Little or no understanding of business/economic concepts\n• Rudimentary critical thinking• Somewhat shaky understanding of business/economic concepts\n• Average critical thinking• Understanding of business/economic concepts\n• Mature critical thinking• Clear understanding of business/economic concepts\n• Sophisticated critical thinking• Superior understanding of business/economic concepts\n\n\n5. Quality of writing\n• Very poorly organized• Very difficult to read• Many typos and grammatical errors\n• Somewhat disorganized• Somewhat difficult to read• Numerous typos and grammatical errors\n• Mostly well organized• Mostly easy to read• Some typos and grammatical errors\n• Well organized• Easy to read• Very few typos or grammatical errors\n• Very well organized• Very easy to read• No typos or grammatical errors\n\n\n6. Quality of Jupyter Notebook usage\n• Very poorly organized• Many redundant warning/error messages• Inappropriate code to produce outputs\n• Somewhat disorganized• Numerous warning/error messages• Misses important code\n• Mostly well organized• Some warning/error messages• Provides appropriate code\n• Well organized• Very few warning/error messages• Provides advanced code\n• Very well organized• No warning/error messages• Proposes highly advanced code"
  },
  {
    "objectID": "danl-rw/danl-299-project.html#data-collection-1",
    "href": "danl-rw/danl-299-project.html#data-collection-1",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "Data Collection",
    "text": "Data Collection\n\n\n\n\n\n\n\n\n\nEvaluation\nDescription\nCriteria\n\n\n\n\n1 (Very Deficient)\n- Very poorly implemented- Data is unreliable.\n- Poor web scraping practices with selenium, leading to unreliable or incorrect data from Yahoo Finance.- Inadequate use of pandas, resulting in poorly structured DataFrames.\n\n\n2 (Somewhat Deficient)\n- Somewhat effective implementation- Data has minor reliability issues.\n- Basic web scraping with selenium that sometimes fails to capture all relevant data accurately.- Basic use of pandas, but with occasional issues in data structuring.\n\n\n3 (Acceptable)\n- Effective web scraping with selenium, capturing most required data from Yahoo Finance.- Adequate use of pandas to structure data in a mostly logical format.\n\n\n\n4 (Very Good)\n- Well-implemented and organized- Data is reliable.\n- Thorough web scraping with selenium that consistently captures accurate and complete data from Yahoo Finance.- Skillful use of pandas for clear and logical data structuring.\n\n\n5 (Outstanding)\n- Exceptionally implemented- Data is highly reliable.\n- Expert web scraping with selenium, capturing detailed and accurate data from Yahoo Finance without fail.- Expert use of pandas to create exceptionally well-organized DataFrames that facilitate easy analysis."
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html",
    "href": "danl-cw/danl-299-cw-07.html",
    "title": "Classwork 7",
    "section": "",
    "text": "ny_pincp = pd.read_csv('https://bcdanl.github.io/data/NY_pinc_wide.csv')\n\nThe following is the ny_pincp DataFrame:\n\n\n\n\n  \n\n\n\n\nMake ny_pincp longer.\nAnswer:\n\n\n\n\n\ncovid = pd.read_csv('https://bcdanl.github.io/data/covid19_cases.csv')\n\nThe following is the covid DataFrame:\n\n\n\n\n  \n\n\n\n\n\nMake a wide-form DataFrame of covid whose variable names are from countriesAndTerritories and values are from cases.\n\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#question-1",
    "href": "danl-cw/danl-299-cw-07.html#question-1",
    "title": "Classwork 7",
    "section": "",
    "text": "ny_pincp = pd.read_csv('https://bcdanl.github.io/data/NY_pinc_wide.csv')\n\nThe following is the ny_pincp DataFrame:\n\n\n\n\n  \n\n\n\n\nMake ny_pincp longer.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#question-2",
    "href": "danl-cw/danl-299-cw-07.html#question-2",
    "title": "Classwork 7",
    "section": "",
    "text": "covid = pd.read_csv('https://bcdanl.github.io/data/covid19_cases.csv')\n\nThe following is the covid DataFrame:\n\n\n\n\n  \n\n\n\n\n\nMake a wide-form DataFrame of covid whose variable names are from countriesAndTerritories and values are from cases.\n\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#variables-in-flights-dataframe",
    "href": "danl-cw/danl-299-cw-07.html#variables-in-flights-dataframe",
    "title": "Classwork 7",
    "section": "Variables in flights DataFrame",
    "text": "Variables in flights DataFrame\n\nyear, month, day: Date of departure.\ndep_time, arr_time: Actual departure and arrival times (format HHMM or HMM), local tz.\nsched_dep_time, sched_arr_time: Scheduled departure and arrival times (format HHMM or HMM), local tz.\ndep_delay, arr_delay: Departure and arrival delays, in minutes. Negative times represent early departures/arrivals.\ncarrier: Two letter carrier abbreviation. See airlines DataFrame to get full names.\nflight: Flight number.\ntailnum: Plane tail number. See planes DataFrame for additional metadata.\norigin, dest: Origin and destination. See airports DataFrame for additional metadata.\nair_time: Amount of time spent in the air, in minutes.\ndistance: Distance between airports, in miles.\nhour, minute: Time of scheduled departure broken into hour and minutes.\ntime_hour: Scheduled date and hour of the flight as a datetime64. Along with origin, can be used to join flights data to weather DataFrame"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#question-3",
    "href": "danl-cw/danl-299-cw-07.html#question-3",
    "title": "Classwork 7",
    "section": "Question 3",
    "text": "Question 3\nThe following is the flights DataFrame:\n\n\n\n\n  \n\n\n\n\nThe following is the weather DataFrame:\n\n\n\n\n  \n\n\n\n\nMerge the flights and weather DataFrames so that all observations from flights are retained in the resulting DataFrame.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#question-4",
    "href": "danl-cw/danl-299-cw-07.html#question-4",
    "title": "Classwork 7",
    "section": "Question 4",
    "text": "Question 4\nThe following is the airlines DataFrame:\n\n\n\n\n  \n\n\n\n\n\nIdentify the airlines (by full name) that have the top five dep_delay values in the flights DataFrame.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#question-5",
    "href": "danl-cw/danl-299-cw-07.html#question-5",
    "title": "Classwork 7",
    "section": "Question 5",
    "text": "Question 5\n\nConsider the following two airlines:\n\nDelta Air Lines Inc. (DL)\nUnited Air Lines Inc. (UA)\n\nDetermine which airline has a higher proportion of flights with a dep_delay greater than 30 minutes.\nHint: numpy.where() is like an if-else statement, which can be very useful.\n\nThe following is an example of numpy.where():\n\n\n\nimport pandas as pd\nimport numpy as np\n\n# Sample DataFrame with temperatures\ndf = pd.DataFrame({\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Temperature': [12, 22, 7, 25, 30]\n})\n\n# Categorize temperatures using numpy.where\ndf['Category'] = np.where(df['Temperature'] &lt; 10, 'Cold', 'Not Cold')\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#question-6",
    "href": "danl-cw/danl-299-cw-07.html#question-6",
    "title": "Classwork 7",
    "section": "Question 6",
    "text": "Question 6\n\nWrite a Pandas code to concatenate the two given DataFrames along rows.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#question-7",
    "href": "danl-cw/danl-299-cw-07.html#question-7",
    "title": "Classwork 7",
    "section": "Question 7",
    "text": "Question 7\n\nWrite a Pandas code to concatenate the two given DataFrames along columns.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-299-cw-07.html#question-8",
    "href": "danl-cw/danl-299-cw-07.html#question-8",
    "title": "Classwork 7",
    "section": "Question 8",
    "text": "Question 8\n\nConsider the following Pandas Series:\n\ns6 = pd.Series(['S6', 'Scarlette Fisher', 205], index=['student_id', 'name', 'marks'])\n\nWrite a Pandas code to append s6 to the DataFrame student_data1.\nHint 1: Consider creating a DataFrame of s6.\n\npd.DataFrame(s6)\n\nHint 2: DataFrame.T returns the transpose of the DataFrame, swapping rows and columns."
  },
  {
    "objectID": "danl-cw/danl-299-cw-04.html",
    "href": "danl-cw/danl-299-cw-04.html",
    "title": "Classwork 4",
    "section": "",
    "text": "Using Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-299-cw-04.html#question-1",
    "href": "danl-cw/danl-299-cw-04.html#question-1",
    "title": "Classwork 4",
    "section": "",
    "text": "Using Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-299-cw-04.html#question-2",
    "href": "danl-cw/danl-299-cw-04.html#question-2",
    "title": "Classwork 4",
    "section": "Question 2",
    "text": "Question 2\nFor each expression below, what is the value of the expression? Explain thoroughly.\n\n20 == '20'\n\n\nx = 4.0\ny = .5\n\nx &lt; y or 3*y &lt; x\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-299-cw-04.html#question-3",
    "href": "danl-cw/danl-299-cw-04.html#question-3",
    "title": "Classwork 4",
    "section": "Question 3",
    "text": "Question 3\n\nfare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\n\nWrite a Python code that uses slicing and the print() function to print out the following message:\n\nThe total trip cost is: $12.80\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-299-cw-04.html#question-4",
    "href": "danl-cw/danl-299-cw-04.html#question-4",
    "title": "Classwork 4",
    "section": "Question 4",
    "text": "Question 4\n\nlist_variable = [100, 144, 169, 1000, 8]\n\nWrite a Python code that uses print() and max() functions to print out the largest value in the list, list_variable, as follows:\n\nThe largest value in the list is: 1000\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-299-cw-04.html#question-5",
    "href": "danl-cw/danl-299-cw-04.html#question-5",
    "title": "Classwork 4",
    "section": "Question 5",
    "text": "Question 5\n\nvals = [3, 2, 1, 0]\n\n\nUse a while loop to print each value of the list [3, 2, 1, 0], one at a time.\nUse a for loop to print each value of the list [3, 2, 1, 0], one at a time.\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-299-cw-04.html#question-6",
    "href": "danl-cw/danl-299-cw-04.html#question-6",
    "title": "Classwork 4",
    "section": "Question 6",
    "text": "Question 6\n\nAssign the value 7 to the variable guess_me, and the value 1 to the variable number.\nWrite a while loop that compares number with guess_me.\n\nPrint ‘too low’ if number is less than guess me.\nIf number equals guess_me, print ‘found it!’ and then exit the loop.\nIf number is greater than guess_me, print ‘oops’ and then exit the loop.\nIncrement number at the end of the loop.\n\nWrite a for loop that compares number with guess_me.\n\nPrint ‘too low’ if number is less than guess me.\nIf number equals guess_me, print ‘found it!’ and then exit the loop.\nIf number is greater than guess_me, print ‘oops’ and then exit the loop.\nIncrement number at the end of the loop.\n\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-299-cw-03.html",
    "href": "danl-cw/danl-299-cw-03.html",
    "title": "Classwork 3",
    "section": "",
    "text": "_quarto.yml configures the website:\n\nIt determines the structure of the website.\n\ne.g., Navigation bar, themes, HTML options, etc.\n\nIf _quarto.yml is edited, use quarto render to render all qmd and ipynb files.\n\nindex.qmd renders index.html, the front page of the website.\n\nDo not create Quarto files something like index2.qmd within the working directory.\n\nblog-listing.qmd configures the blog listing page.\nposts directory includes sub-directories of blog posts.\nimg directory can be used to store picture files.\n\n\n\n\nA file in the working directory can have its own web address.\n\nFor example, if you have resume-example.pdf in your working directory, it has the web address, https://USERNAME.github.io/resume-example.pdf.\n\nWhen naming a file in the website, do not have any space in a file name!\nBe systematic when naming a series of files in the website.\n\nE.g., danl-210-cw-01.ipynb, danl-210-cw-02.ipynb, danl-210-cw-03.ipynb.\n\n\n\n\n\n\n\nRules\n\nOne blog post corresponds to:\n\n\nOne sub-directory in the posts directory.\nOne *.ipynb (or *.qmd) file.\n\n\nPut all files for one blog post (e.g., *.ipynb (or *.qmd), *.png) in one corresponding sub-directory in the posts directory.\nWhen inserting an image file to a blog post, use a relative path, i.e., a file name of the image file.\n\n\n\n\n\n\n\nDecorate your website:\n\n\nReplace YOUR NAME with your name in _quarto.yml and index.qmd.\nDescribe yourself in index.qmd.\nAdd the picture (png) file of your profile photo to img directory. Then correct img/profile.png in index.qmd accordingly.\nCorrect links for your resumé, linkedin, email, and social media.\n\n\nAdd a menu of “Project” to the navigation bar using danl_proj_nba.ipynb.\nAdd a drop-down menu of “Python Data Analysis” to the navigation bar.\n\n\nUnder the menu of “Python Data Analysis”, add links for the following webpage:\n\nPandas Basics using pandas_basic.ipynb\nSeaborn Basics using seaborn_basic.ipynb\n\n\n\nUse the 3-step git commands (git add, git commit, and git push) to update your website.\n\n\n\n\n\n\nQuarto - Creating a Website\nQuarto - HTML Basics\nQuarto - HTML Code Blocks\nQuarto - HTML Theming\nQuarto - Creating a Blog"
  },
  {
    "objectID": "danl-cw/danl-299-cw-03.html#website-files",
    "href": "danl-cw/danl-299-cw-03.html#website-files",
    "title": "Classwork 3",
    "section": "",
    "text": "_quarto.yml configures the website:\n\nIt determines the structure of the website.\n\ne.g., Navigation bar, themes, HTML options, etc.\n\nIf _quarto.yml is edited, use quarto render to render all qmd and ipynb files.\n\nindex.qmd renders index.html, the front page of the website.\n\nDo not create Quarto files something like index2.qmd within the working directory.\n\nblog-listing.qmd configures the blog listing page.\nposts directory includes sub-directories of blog posts.\nimg directory can be used to store picture files.\n\n\n\n\nA file in the working directory can have its own web address.\n\nFor example, if you have resume-example.pdf in your working directory, it has the web address, https://USERNAME.github.io/resume-example.pdf.\n\nWhen naming a file in the website, do not have any space in a file name!\nBe systematic when naming a series of files in the website.\n\nE.g., danl-210-cw-01.ipynb, danl-210-cw-02.ipynb, danl-210-cw-03.ipynb."
  },
  {
    "objectID": "danl-cw/danl-299-cw-03.html#blogging",
    "href": "danl-cw/danl-299-cw-03.html#blogging",
    "title": "Classwork 3",
    "section": "",
    "text": "Rules\n\nOne blog post corresponds to:\n\n\nOne sub-directory in the posts directory.\nOne *.ipynb (or *.qmd) file.\n\n\nPut all files for one blog post (e.g., *.ipynb (or *.qmd), *.png) in one corresponding sub-directory in the posts directory.\nWhen inserting an image file to a blog post, use a relative path, i.e., a file name of the image file."
  },
  {
    "objectID": "danl-cw/danl-299-cw-03.html#practice-problems",
    "href": "danl-cw/danl-299-cw-03.html#practice-problems",
    "title": "Classwork 3",
    "section": "",
    "text": "Decorate your website:\n\n\nReplace YOUR NAME with your name in _quarto.yml and index.qmd.\nDescribe yourself in index.qmd.\nAdd the picture (png) file of your profile photo to img directory. Then correct img/profile.png in index.qmd accordingly.\nCorrect links for your resumé, linkedin, email, and social media.\n\n\nAdd a menu of “Project” to the navigation bar using danl_proj_nba.ipynb.\nAdd a drop-down menu of “Python Data Analysis” to the navigation bar.\n\n\nUnder the menu of “Python Data Analysis”, add links for the following webpage:\n\nPandas Basics using pandas_basic.ipynb\nSeaborn Basics using seaborn_basic.ipynb\n\n\n\nUse the 3-step git commands (git add, git commit, and git push) to update your website."
  },
  {
    "objectID": "danl-cw/danl-299-cw-03.html#references",
    "href": "danl-cw/danl-299-cw-03.html#references",
    "title": "Classwork 3",
    "section": "",
    "text": "Quarto - Creating a Website\nQuarto - HTML Basics\nQuarto - HTML Code Blocks\nQuarto - HTML Theming\nQuarto - Creating a Blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DANL 299: Data Preparation and Management, Fall 2025",
    "section": "",
    "text": "Welcome! 👋\n\\(-\\) Explore, Learn, and Grow with Data Analytics! 🌟"
  },
  {
    "objectID": "index.html#bullet-lecture",
    "href": "index.html#bullet-lecture",
    "title": "DANL 299: Data Preparation and Management, Fall 2025",
    "section": "\\(\\bullet\\,\\) 🚀 Lecture",
    "text": "\\(\\bullet\\,\\) 🚀 Lecture\n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nLecture 1\n\n\nSyllabus and Course Outline\n\n\nAugust 25, 2025\n\n\n\n\nLecture 2\n\n\nPrologue; DANL Tools; Building a Website; Markdown\n\n\nAugust 27, 2025\n\n\n\n\nLecture 3\n\n\nGetting Started with Jupyter Notebook and Quarto\n\n\nSeptember 4, 2025\n\n\n\n\nLecture 4\n\n\nPy Basics - Variables, Data Types, Operators, Casting, Containers\n\n\nSeptember 8, 2025\n\n\n\n\nLecture 5\n\n\nPy Basics - if-else; Slicing; Functions; while & for; List & Dict; try-except\n\n\nSeptember 10, 2025\n\n\n\n\nLecture 6\n\n\npandas - Loading Data\n\n\nSeptember 17, 2025\n\n\n\n\nLecture 7\n\n\npandas - Getting a Data Summary; Selecting Variables; Counting\n\n\nSeptember 22, 2025\n\n\n\n\nLecture 8\n\n\npandas - Sorting Methods; Setting a New Index; Locating Observations/Values\n\n\nSeptember 24, 2025\n\n\n\n\nLecture 9\n\n\npandas - Adding, Removing, & Renaming Variables; Data Types\n\n\nSeptember 29, 2025\n\n\n\n\nLecture 10\n\n\npandas - Filtering by a Condition\n\n\nOctober 1, 2025\n\n\n\n\nLecture 11\n\n\npandas - Missing Values; Duplicates\n\n\nOctober 2, 2025\n\n\n\n\nLecture 12\n\n\npandas - Reshaping DataFrames\n\n\nOctober 6, 2025\n\n\n\n\nLecture 13\n\n\npandas - Joining DataFrames; Concatenating DataFrames\n\n\nOctober 8, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-classwork",
    "href": "index.html#bullet-classwork",
    "title": "DANL 299: Data Preparation and Management, Fall 2025",
    "section": "\\(\\bullet\\,\\) ⌨️ Classwork",
    "text": "\\(\\bullet\\,\\) ⌨️ Classwork\n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nClasswork 1\n\n\nBuilding a Personal Website using Git, GitHub, and RStudio with Quarto\n\n\nAugust 25, 2025\n\n\n\n\nClasswork 2\n\n\nMarkdown Basics\n\n\nAugust 27, 2025\n\n\n\n\nClasswork 3\n\n\nQuarto Website Basics\n\n\nSeptember 4, 2025\n\n\n\n\nClasswork 4\n\n\nPython Basics\n\n\nSeptember 8, 2025\n\n\n\n\nClasswork 5\n\n\nPandas - Loading, Summarizing, Selecting, Counting, Sorting, and Indexing Data\n\n\nSeptember 22, 2025\n\n\n\n\nClasswork 6\n\n\nPandas - Convering Data Types; Filtering Data; Missing Values/Duplicates\n\n\nSeptember 29, 2025\n\n\n\n\nClasswork 7\n\n\nPandas - Reshaping DataFrames; Joining DataFrames; Data Concatenation\n\n\nOctober 6, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-homework",
    "href": "index.html#bullet-homework",
    "title": "DANL 299: Data Preparation and Management, Fall 2025",
    "section": "\\(\\bullet\\,\\) 💻 Homework",
    "text": "\\(\\bullet\\,\\) 💻 Homework\n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nHomework 1\n\n\nPersonal Website and Python Basics\n\n\nSeptember 11, 2025\n\n\n\n\nHomework 2\n\n\nPandas Basics\n\n\nSeptember 25, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "danl-wk/wk-03.html",
    "href": "danl-wk/wk-03.html",
    "title": "Week 3",
    "section": "",
    "text": "In our week 3, we will start practicing Python basics"
  },
  {
    "objectID": "danl-wk/wk-03.html#lecture-slides",
    "href": "danl-wk/wk-03.html#lecture-slides",
    "title": "Week 3",
    "section": "🏫 Lecture Slides",
    "text": "🏫 Lecture Slides\n\nLecture 4 — Python Basics I\nView Slides\n\nLecture 5 — Python Basics II\nView Slides\n\n🎥 Looking for lecture recordings? You can only find those on Brightspace.\n\nUseful Keyboard Shortcuts for Lecture Slides\n\nCTRL + Shift + F: Search\nM: Toggle menu\nE: PDF export/printing mode"
  },
  {
    "objectID": "danl-wk/wk-03.html#classwork",
    "href": "danl-wk/wk-03.html#classwork",
    "title": "Week 3",
    "section": "✍️ Classwork",
    "text": "✍️ Classwork\n🚧 Please complete Classwork 4 to practice basics in Python programming."
  },
  {
    "objectID": "danl-wk/wk-03.html#recommended-reading",
    "href": "danl-wk/wk-03.html#recommended-reading",
    "title": "Week 3",
    "section": "📚 Recommended Reading",
    "text": "📚 Recommended Reading\n\nCheck the end of slides for the list of references cited in the lecture."
  },
  {
    "objectID": "danl-wk/wk-03.html#discussion",
    "href": "danl-wk/wk-03.html#discussion",
    "title": "Week 3",
    "section": "💬 Discussion",
    "text": "💬 Discussion\nWelcome to our Week 3 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 3.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 3 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-06.html",
    "href": "danl-wk/wk-06.html",
    "title": "Week 6",
    "section": "",
    "text": "In Week 6, we’ll finish up lectures on Pandas basics."
  },
  {
    "objectID": "danl-wk/wk-06.html#lecture-slides",
    "href": "danl-wk/wk-06.html#lecture-slides",
    "title": "Week 6",
    "section": "🏫 Lecture Slides",
    "text": "🏫 Lecture Slides\n\nLecture 10 — Filtering by a Condition\nView Slides\nLecture 11 - Missing Values; Duplicates\nView Slides\nLecture 12 - Reshaping DataFrames\nView Slides\nLecture 13 - Joining DataFrames\nView Slides\n\n🎥 Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-06.html#classwork",
    "href": "danl-wk/wk-06.html#classwork",
    "title": "Week 6",
    "section": "✍️ Classwork",
    "text": "✍️ Classwork\n\nClasswork 5 - Loading, Summarizing, Selecting, Counting, Sorting, and Indexing Data\nView Classwork\nClasswork 6 - Convering Data Types; Filtering Data; Missing Values/Duplicates\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-06.html#discussion",
    "href": "danl-wk/wk-06.html#discussion",
    "title": "Week 6",
    "section": "💬 Discussion",
    "text": "💬 Discussion\nWelcome to our Week 5 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 5.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 5 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-04.html",
    "href": "danl-wk/wk-04.html",
    "title": "Week 4",
    "section": "",
    "text": "In Week 4, we’ll wrap up Python basics and then move on to Pandas, a powerful library for data analysis with DataFrames."
  },
  {
    "objectID": "danl-wk/wk-04.html#lecture-slides",
    "href": "danl-wk/wk-04.html#lecture-slides",
    "title": "Week 4",
    "section": "🏫 Lecture Slides",
    "text": "🏫 Lecture Slides\n\nLecture 4 — Python Basics I\nView Slides\n\nLecture 5 — Python Basics II\nView Slides\n\nLecture 7 — Pandas Basics - Loading Data\nView Slides\n\nLecture 8 — Pandas Basics\nView Slides\n\n🎥 Looking for lecture recordings? You can only find those on Brightspace.\n\nUseful Keyboard Shortcuts for Lecture Slides\n\nCTRL + Shift + F: Search\nM: Toggle menu\nE: PDF export/printing mode"
  },
  {
    "objectID": "danl-wk/wk-04.html#classwork",
    "href": "danl-wk/wk-04.html#classwork",
    "title": "Week 4",
    "section": "✍️ Classwork",
    "text": "✍️ Classwork\n🚧 Please complete Classwork 4 to practice basics in Python programming."
  },
  {
    "objectID": "danl-wk/wk-04.html#recommended-reading",
    "href": "danl-wk/wk-04.html#recommended-reading",
    "title": "Week 4",
    "section": "📚 Recommended Reading",
    "text": "📚 Recommended Reading\n\nCheck the end of slides for the list of references cited in the lecture."
  },
  {
    "objectID": "danl-wk/wk-04.html#discussion",
    "href": "danl-wk/wk-04.html#discussion",
    "title": "Week 4",
    "section": "💬 Discussion",
    "text": "💬 Discussion\nWelcome to our Week 4 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 4.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 4 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Course Information\n\nInstructor: Byeong-Hak Choe\nEmail: bchoe@geneseo.edu\nPhone: (585) 245-5425\nClass Websites:\n\nGitHub Course Website\nBrightspace Course Shell\n\nOffice: South Hall 227B\nOffice Hours:\n\nMondays and Wednesdays 3:30 P.M. – 5:00 P.M.\nBy appointment via email\n\n\n\n\nCourse Description\nThis course aims to provide overview of how one can manipulate, process, clean, crunch, and collect data with hands-on and practical case studies that show you how to solve a broad set of data analysis problems effectively. We will use a computing development environment, Jupyter Notebook, which is a shell and notebook for exploratory computing. This course will cover topics such as (1) loading, cleaning, transforming, merging, and reshaping data, (2) creating informative visualizations, (3) dataset slicing, dicing, and summarizing, and (4) collecting data via web scraping and application programming interfaces (APIs). We will cover these topics to solve real-world data analysis problems with thorough, detailed examples. Computing is done in Python. Throughout the course, students will gain hands-on experience with Python and its data analysis libraries (e.g., pandas, seaborn, requests, selenium), along with practical applications of git and GitHub. We will use Python in a Jupyter Notebook environment, along with practical applications of Git and GitHub.\n\n\nSchool of Business Mission\nThe School of Business at SUNY Geneseo is committed to exceptional business and economics education within the context of a strong liberal arts tradition. The School is distinguished by a uniquely accomplished and dedicated faculty, motivated and capable students, a robust professional development program, and the engaged support of alumni, employers, and business leaders. Students acquire strong quantitative, analytical, and communication skills while preparing for professional success as socially conscious contributors. We strive for teaching excellence, and we recognize that high-quality faculty scholarship and professional activities increase our impact on knowledge, practice, and pedagogy.\n\n\nBachelor of Arts in Data Analytics Program Competency Goals\n\nCompetency Goal 1: Our learners will have strong analytical skills.\nCompetency Goal 2: Our learners will have strong quantitative skills.\nCompetency Goal 3: Our learners will have effective communications skills.\nCompetency Goal 4: Our learners will have a thorough understanding of various functional areas of business.\nCompetency Goal 5: Our learners will have a multidimensional understanding of social responsibility.\n\n\n\nCourse Learning Outcomes\n\nUnderstand methods and attributes of numerous data set objects represented in Python Programming;\nKnow how to perform a multitude of data operations in Python Programming such as grouping, pivoting, and joining;\nKnow how to manipulate, process, and clean all types of data sets (including broken and incomplete) in Python for data analytics applications;\nKnow how to effectively present and visualize resulting data;\nKnow how to effectively collect data;\nUnderstand how to solve broad set of data analytics problems and describe how Python Programming is used strategically and tactically for them.\n\n\n\nCourse Requirements\n\nHomework: 5 assignments\nProject: There will be one project on a personal website.\nExams: 2 midterms and 1 final\nTools:\n\nRStudio Desktop\n\nTerms of Use\n\nAnaconda Distribution\n\nTerms of Service\n\nGoogle Colab\n\nTerms of Service\n\nGitHub\n\nSite Policy\n\nBrightspace\n\nPrivacy Policy\n\nMicrosoft Teams\n\nServices Agreement\n\n\n\n\n\nProject\n\nAgenda: Unifying ESG Metrics with Financial Analysis\n\nDeliverables: Code + write-up published on team websites\n\nGrading based on: data collection, EDA, business/economic analysis, and website usage\n\n\n\nRecommended References\nWe will be drawing material from a wide variety of sources for this course; as such, there is no single, required textbook per se.\n\nPython for Data Analysis – Wes McKinney\nPython Programming for Data Science – Beuzen\n\nCoding for Economists – Turrell\n\nPython for Econometrics in Economics – Raters\n\nQuantEcon Data Science\n\nQuarto Guide\n\n\n\nCourse Schedule\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopic\nNotes\n\n\n\n\n1\nAug 25–29\nInstalling Tools\n\n\n\n2\nSep 2–5\nPython Basics (Part 1)\nLabor Day (Sep 1)\n\n\n3\nSep 8–12\nPython Basics (Part 2)\nHW 1\n\n\n4\nSep 15–19\nDataFrame operations with pandas (Part 1)\n\n\n\n5\nSep 22–26\nDataFrame operations with pandas (Part 2)\n\n\n\n6\nSep 29–Oct 3\nDataFrame operations with pandas (Part 3)\nHW 2\n\n\n7\nOct 6–10\nDataFrame operations with pandas (Part 4)\nMidterm Exam I\n\n\n8\nOct 15–17\nWeb scraping with pandas.read_html()\nFall Break (Oct 13–14)\n\n\n9\nOct 20–24\nWeb scraping with Selenium (Part 1)\n\n\n\n10\nOct 27–31\nWeb scraping with Selenium (Part 2)\nHW 3\n\n\n11\nNov 3–7\nWeb scraping with Selenium (Part 3)\n\n\n\n12\nNov 10–14\nData Collection with APIs (Part 1)\nHW 4\n\n\n13\nNov 17–21\nData Collection with APIs (Part 2)\nMidterm Exam II\n\n\n14\nNov 24–25\nDataFrame Group operations (Part 2)\nThanksgiving Break (Nov 26–28)\n\n\n15\nDec 1–5\nDataFrame Group operations (Part 3)\n\n\n\n16\nDec 8\nDataFrame Group operations (Part 4)\nHW 5\n\n\n\n\nExam Schedule\n\nMidterm Exam 1: during class time in the week 7 (Oct 6–10)\nMidterm Exam 2: during class time in the week 13 (Nov 17–21)\nFinal Exam: To be determined  \n\n\n\n\nAttendance\nStudents are allowed up to four absences without penalty. Additional absences may affect your grade unless they are formally excused. If you must miss class for a standard excused reason (e.g., illness, family emergency, transportation issues), please notify me at bchoe@geneseo.edu so the absence can be recorded appropriately.\nRegular attendance is expected, as discussions, activities, and projects are central to your learning. If you anticipate challenges that may affect your attendance, please reach out—I am happy to work with you to help you stay on track.\n\n\nGrading\n\nTotal Percentage Grade\n\nAttendance: 5%\n\nHomework: 20% (single lowest homework score dropped)\n\nProject: 25%\n\nExams: 50%\n\n\n\\[\n\\begin{align}\n\\quad\\\\\n&\\text{(Total Percentage Score)} \\\\\n= &\\quad\\; 0.05 \\times \\text{(Attendance)} \\\\\n&+ 0.05 \\times \\text{(Quiz \\& Participation)}\\\\\n&+ 0.20 \\times \\text{(Homework)}\\\\\n&+ 0.20 \\times \\text{(Project)}\\\\\n&+ 0.50 \\times \\text{(Exams)}\n\\end{align}\n\\]\n\nExam Score Calculations\n\n\\[\n\\begin{align}\n&\\quad(\\text{Midterm Exam Score})\\\\\n&= \\max\\left\\{0.50 \\times \\text{(Midterm 1 Score)} + 0.50 \\times \\text{(Midterm 2 Score)},\\right.\\\\\n&\\qquad\\quad\\;\\;\\,\\left.0.33 \\times \\text{(Midterm 1 Score)} + 0.67 \\times \\text{(Midterm 2 Score)}\\right\\}.\n\\end{align}\n\\]\n\nThe Midterm Exam Score will be the higher of the following two calculations:\n\nThe simple average of Midterm Exam 1 and Midterm Exam 2\nThe weighted average, with one-third weight on Midterm Exam 1 and two-thirds weight on Midterm Exam 2\n\n\n\\[\n\\begin{align}\n&\\quad(\\text{Total Exam Score})\\\\\n&= \\max\\left\\{0.50 \\times \\text{(Midterm Exam Score)} + 0.50 \\times \\text{(Final Exam Score)},\\right.\\\\\n&\\qquad\\quad\\;\\;\\,\\left.0.25 \\times \\text{(Midterm Exam Score)} + 0.75 \\times \\text{(Final Exam Score)}\\right\\}.\n\\end{align}\n\\]\n\nThe Total Exam Score will be the higher of the following two calculations:\n\nThe simple average of Midterm Exam and Final Exam\nThe weighted average, with one-fourth weight on Midterm Exam and three-forth weight on Final Exam.\n\nLetter Grade Scale\nTotal percentage scores are converted to letter grades according to the following ranges:\n\n\\[\n\\begin{align}\n100 &≥ A ≥ 93 &gt; A− ≥ 90\\\\\n90 &&gt; B+ ≥ 87 &gt; B ≥ 83 &gt; B− ≥ 80\\\\\n80 &&gt; C+ ≥ 77 &gt; C ≥ 73 &gt; C− ≥ 70\\\\\n70 &&gt; D ≥ 60 &gt; E\n\\end{align}\n\\]\n\n\nPolicies\n\nMake-up Exams\nMake-up exams will not be given unless you have either a medically verified excuse or an absence excused by the University. For religious obligations, notify the instructor by email at least two weeks in advance to set an alternative time. A missed exam without an excused absence earns a grade of zero.\n\n\nArtificial Intelligence (AI)\nUnless AI tools are explicitly permitted for homework or in-class quizzes, you must complete your work independently. Using tools like ChatGPT for any aspect of coursework is a form of academic dishonesty and undermines the development of your own skills. If you have questions, please ask.\n\n\n\n\n\n\n📝 If you use AI for a particular assignment and/or project, you must also:\n\n📝 You must document which AI platforms and tools you used.\n📤 You must include your prompts and AI outputs with your assignment submission.\n🧠 You must include a reflection on your AI usage and learning process.\n\n\n\n\nAcademic Integrity and Plagiarism\nAll homework assignments and exams must be your original work. Academic dishonesty will not be tolerated. Examples include:\n\nRepresenting the work, thoughts, or ideas of another person as your own\n\nAllowing others to represent your work, thoughts, or ideas as theirs\n\nBeing complicit in academic dishonesty by suspecting or knowing of it and not taking action\n\nSee: Academic Dishonesty Policy and Procedures and Plagiarism Tutorial Brightspace Link\n\n\n\n\nAccessibility\nSUNY Geneseo is dedicated to providing an equitable and inclusive educational experience for all students. The Office of Accessibility (OAS) will coordinate reasonable accommodations for persons with disabilities to ensure equal access to academic programs, activities, and services offered by SUNY Geneseo.\nStudents with approved accommodations may submit a semester request to renew their academic accommodations. More information on the process for requesting academic accommodations is on the OAS website.\nQuestions? Contact the OAS by email, phone, or in-person:\nOffice of Accessibility Services\nErwin Hall 22\n585-245-5112\naccess@geneseo.edu\n\n\nPublic Health and Class Attendance\nIf you are experiencing symptoms associated with COVID on a day that class meets in-person, do not attend. Communicate proactively about absences and contact the Dean of Students if you expect to be out for an extended period.\n\n\nReligious Observations and Class Attendance\nNew York State Education Law 224-a stipulates that “any student in an institution of higher education who is unable, because of [their] religious beliefs, to attend classes on a particular day or days shall, because of such absence on the particular day or days, be excused from any examination or any study or work requirements” (see General Classroom Policies for more information). SUNY Geneseo has a commitment to inclusion and belonging, and I want to stress my respect for the diverse identities and faith traditions of students in my class. If you anticipate an absence due to religious observations, please contact me as soon as possible in advance to discuss your needs and arrange make up plans. The New York State Department of Civil Service maintains a calendar of major religious observations.\n\n\nMilitary Obligations and Class Attendance\nFederal and New York State law requires institutions of higher education to provide an excused leave of absence from classes without penalty to students enrolled in the National Guard or armed forces reserves who are called to active duty. If you are called to active military duty and need to miss classes, please let me know and consult as soon as possible with the Dean of Students.\n\n\nBias-Related Incidents\n\n“We are here to listen, to learn, to teach, to debate, to change, to grow. We should all be safe to pursue these goals at SUNY Geneseo while being who we are. Together, we commit ourselves to pluralism, cultivating a community that respects difference and promotes a sense of inclusion and belonging.”\n\nAs this excerpt from our Community Commitment to Diversity, Equity, and Inclusion states, here at SUNY Geneseo, we want to provide a space where everyone feels welcome to learn and grow in their identities as well as in their role as students, faculty, and staff. If in the unfortunate instance you witness or experience an incident of bias, we encourage you to reach out to the Chief Diversity Officer, Director of Multicultural Affairs, and/or our University Police Department. You may also choose to report it through the bias-related incident reporting form. In trying to create an environment that facilitates growth through diverse thoughts and ideas, reporting incidents of bias - including threats, vandalism, and microaggressive behaviors - can help bring a better understanding of our campus climate as well as provide opportunities for learning and restoring harm.\n\n\n\nPersonal Health, Well-being, and Basic Needs\n\nWell-Being\nPrioritizing well-being can support the achievement of academic goals and alleviate stress. Eating nutritious foods, getting enough sleep, exercising, avoiding drugs and alcohol, maintaining healthy relationships, and building in time to relax all help promote a healthy lifestyle and general well-being. Your health and wellbeing are foundational to your ability to learn, and if you find that you are feeling unwell (physically or mentally) and it is impacting your ability to complete your coursework, please reach out. In a similar way, I will occasionally ask for some patience and flexibility on your part.\nIf I am slow responding to an email, if I take some time to grade an assignment, or if I am a bit late posting course materials, please be patient (and feel free to send me a ‘nudge’; I will not be offended). You will never suffer any disadvantage in the course because of delays on my part. Remember that we are all in this together.\n\n\nBasic Needs Statement\nIn order to foster a sense of belonging and connection, a state of financial, mental, emotional and physical stability must be achieved. If you are facing food insecurity, displacement, an emergency, crisis, or health-related or medical expense, you are not alone. Concerns about academic performance, health situations, family health and wellness (including the loss of a loved one), interpersonal relationships and commitments, and other factors can contribute to stress. Students are strongly encouraged to communicate their needs to faculty and staff and seek support if they are experiencing unmanageable stress or are having difficulties with daily functioning. The Dean of Students (585-245-5706) can assist and provide direction to appropriate campus resources. For more information, visit the Dean of Students Office website.\n\n\nMental Health\nAs a student, you may experience a range of challenges that can impact your mental health and thus impact your learning; common examples include increased anxiety, shifts in mood, strained relationships, difficulties related to substance use, trouble concentrating, and lack of motivation, among many others. These experiences may reduce your ability to participate fully in daily activities and affect your academic performance.\nSUNY Geneseo offers free, confidential counseling for students through Student Health and Counseling, and seeking support for your mental health can be key to your success at college. You can learn more about the various mental health services available on campus online. To request a counseling appointment, please complete the online form.\n\n\nGuidelines for Attendance and Public Health\nSUNY Geneseo is a residential liberal arts college where we all learn together in a shared space. This classroom community is vital for engaging in discussions, solving problems, and answering questions together. Learning is an active process, and it requires engagement - on my part and yours. I promise to create an interactive and collaborative classroom space, and in return I expect you to attend and engage in the activities.\nIt’s possible that some of you may get sick over the course of the semester. Because we want you to be successful and because we value your contribution to the course, we expect you to prioritize attendance. If you are not feeling well and your symptoms do not allow you to attend class, stay home (except to go to the health center), rest, and take care of yourself. You can find more guidelines from the Center for Disease Control for precautions when sick which cover flu, COVID, and other illnesses.\nI expect you to communicate with me directly about your absences. I can support you to keep up with class if you are out for an illness, but I need you to take responsibility for being transparent and clear in letting me know when you are out and why. Although I can work with you on keeping up, you may miss some course content and extended absences may impact your ability to realize your full potential in this class. For extended absences (i.e., more than a couple of days of classes), you should contact the Dean of Students who can assist with reaching out to your faculty.\n\n\nFood Security for SUNY Geneseo Students\nSUNY Geneseo is committed to supporting students who are experiencing food insecurity. If you’re unfamiliar with the phrase “food insecurity,” you can learn more at the following link on Feeding America’s website: Understanding Food Insecurity.\nKnights’ Harvest Pantry, our on-campus food pantry, is a collaborative initiative supported by Campus Auxiliary Services (CAS) and facilitated by trained student volunteers. The program is advised by the Assistant Director of Student Volunteerism and Community Engagement in partnership with the Geneseo Opportunities for Leadership Development (GOLD) program.\nStudents who are in need can confidentially request a bag of food and basic hygiene supplies through our website. These bags typically include non-perishable items and, when available, fresh fruits, vegetables, meat, and dairy products. Pickups take place at the GOLD Leadership Center in MacVittie College Union, Room 114.\nWe are committed to protecting student privacy and promoting dignity, while also working to destigmatize food insecurity on our campus. If Knights’ Harvest Pantry does not fully meet your needs or if you’d prefer to discuss your situation privately, please reach out to Cheyenne DeMarco, Assistant Director of Student Volunteerism and Community Engagement, at cdemarco@geneseo.edu for a one-on-one consultation.\nPlease note that Knights’ Harvest Pantry is closed during official SUNY breaks, including Fall Break, Winter Intersession, Spring Break, and summer between semesters. During these times, students are encouraged to access the Geneseo-Groveland Emergency Food Pantry, located at 31 Center Street, Geneseo, NY 14454. For updates on pantry hours, events, and additional support opportunities, follow us on Instagram or Facebook: @knightsharvestgeneseo. For questions or support, contact Cheyenne DeMarco at cdemarco@geneseo.edu or (585) 245-5893.\n\n\nEmergency Funding\nThe college has three sources of emergency funding for students experiencing short-term financial crises. The Camiolo Student Emergency Loan Fund (SELF) provides short-term loans to students for situations both temporary and beyond their control. The SELF was established with the expectation that students who use the fund seek to “pay it forward” as soon as they are able by contributing to the fund so other students can be helped, too. While there is not a legal obligation, the donors hope that student loan recipients respect and honor the value of community and helping others in their time of crisis. The One Knight Student Aid Emergency Fund assists Geneseo students who are facing financial emergencies mainly related to the COVID-19 pandemic. The fund offers grants (one-time award) depending on a student’s documented financial need. For those students expecting a refund from financial aid, a Temple Hill loan of up to $500 can be offered prior to the approved loan dispersal. If you are experiencing financial hardship, please contact the Dean of Students (585-245-5706), who can assist and provide direction to appropriate campus resources.\n\n\n\nSUNY Geneseo’s Commitments, Mission and Values\nSUNY Geneseo has several core documents that articulate our shared commitments and learning objectives. These include:\n\nSUNY Geneseo Mission, Vision and Values\nCommunity Commitment to Diversity, Equity, and Inclusion\nSustainability as a Core Value\nGeneseo Learning Outcomes for Baccalaureate Education\n\n\n\nDisclaimer\nThe syllabus may be subject to change during the semester. If it is changed, you will be notified via email and Brightspace.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-299-hw-01.html",
    "href": "danl-hw/danl-299-hw-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Please submit your Jupyter Notebook for Part 2 in Homework 1 to Brightspace with the name below:\n\ndanl-299-hw1-LASTNAME-FIRSTNAME.ipynb\n( e.g., danl-299-hw1-choe-byeonghak.ipynb )\n\nThe due is September 22, 2025, 5:15 P.M.\nPlease note that the use of generative AI tools (e.g., ChatGPT, Copilot) is prohibited for this assignment.\nPlease send Prof. Choe an email (bchoe@geneseo.edu) if you have any questions."
  },
  {
    "objectID": "danl-hw/danl-299-hw-01.html#question-0",
    "href": "danl-hw/danl-299-hw-01.html#question-0",
    "title": "Homework 1",
    "section": "Question 0",
    "text": "Question 0\nProvide your GitHub username."
  },
  {
    "objectID": "danl-hw/danl-299-hw-01.html#question-1",
    "href": "danl-hw/danl-299-hw-01.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1\n\nQ1a\n\nCreate a list of integers from 1 to 10.\nAppend the number 11 to the list and remove the number 5.\n\n\n\n\nQ1b\n\nConsider the following dictionary of three employees and their salaries:\n\ndict_salaries = {'Alice': 50000, 'Bob': 60000, 'Charlie': 70000}\n\nAdd a new employee 'Dana' with a salary of 65000.\nUpdate 'Alice'’s salary to 55000.\nPrint all employee names and their salaries."
  },
  {
    "objectID": "danl-hw/danl-299-hw-01.html#question-2",
    "href": "danl-hw/danl-299-hw-01.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2\n\nQ2a\n\nAssign a variable salary to 75000.\nUse an if-elif-else statement to print:\n\n'Low' if salary is less than 50,000\n'Medium' if salary is between 50,000 and 99,999\n'High' if salary is 100,000 or more\n\n\n\n\n\n\nQ2b\n\nAssign two variables, role and salary, to 'Manager' and 85000, respectively.\nUse nested if-else statements to print:\n\n'Eligible for bonus' if the role is 'Manager' and the salary is greater than 80,000.\n'Eligible for raise' if the role is 'Analyst' and the salary is less than 60,000.\n'No action needed' for all other cases."
  },
  {
    "objectID": "danl-hw/danl-299-hw-01.html#question-3",
    "href": "danl-hw/danl-299-hw-01.html#question-3",
    "title": "Homework 1",
    "section": "Question 3",
    "text": "Question 3\n\nQ3a\n\nConsider the following list of salaries:\n\nlist_salaries = [45000, 60000, 75000, 120000, 30000]\n\nCalculate the average salary.\nUse a for loop to print whether each salary is 'Above Average' or 'Below Average'.\n\n\n\n\n\nQ3b\n\nStart with a salary of 50000.\nUse a while loop to increase the salary by 5000 each year until it exceeds 80000.\nPrint the salary after each increment.\n\n\n\n\n\nQ3c\n\nConsider the following dictionary of employee salaries:\n\nsalaries = {'Alice': 50000, 'Bob': 60000, 'Charlie': 70000, 'Dana': 45000}\n\nUse a for loop to print the names of employees who earn more than 55000.\n\n\n\n\n\nQ3d\ndata_list = [42, 3.14, 'Data Analytics', True, None, [1, 2, 3], {'key': 'value'}, (4, 5)]\n\nGiven the list above, print the data type of each element using the type() function in a for loop. In the loop:\n\nConvert the integer 42 to a string.\nConvert the float 3.14 to a string, then back to a float.\nConvert the boolean True to an integer."
  },
  {
    "objectID": "danl-hw/danl-299-hw-01.html#question-4",
    "href": "danl-hw/danl-299-hw-01.html#question-4",
    "title": "Homework 1",
    "section": "Question 4",
    "text": "Question 4\n\nQ4a\nConsider the variables a and b:\na = 10\nb = 0\n\nUse a try-except block to print the result of a / b.\n\nIf there is an error, print 'Cannot divide by zero!'.\n\n\n\n\n\n\nQ4b\n\nConsider the following dictionary of salaries with some missing (None) values:\n\nsalaries = {'Alice': 50000, 'Bob': None, 'Charlie': 70000, 'Dana': None, 'Eve': 80000}\n\nUse a for loop with a try-except block to calculate the total of non-missing salaries."
  },
  {
    "objectID": "danl-hw/danl-299-hw-01.html#question-5",
    "href": "danl-hw/danl-299-hw-01.html#question-5",
    "title": "Homework 1",
    "section": "Question 5",
    "text": "Question 5\n\nImport the math library and calculate the square root of 81 using the sqrt() function provided by the math library."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-1",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\n\nLet’s read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-2",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-2",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation’s value is missing.\n\nIs a value of a variable “XYZ” missing?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation’s value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The value_counts(dropna = False) method",
    "text": "Dealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-dropna-method",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-dropna-method",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method",
    "text": "Dealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-dropna-method-with-how",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-dropna-method-with-how",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with how",
    "text": "Dealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter’s default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-duplicated-method",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-duplicated-method",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method’s keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation’s uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value’s last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of “Douglas” and a Gender of “Male”. Then check which “Douglas” is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-299-lec-11-2025-1002.html#pandas-basics",
    "href": "danl-lec/danl-299-lec-11-2025-1002.html#pandas-basics",
    "title": "Lecture 11",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-1",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-1",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nTidy DataFrames\n\n\n\n\nThere are three interrelated rules that make a DataFrame tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-2",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-2",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\n\n\n\n\n\n\nA DataFrame can be given in a format unsuited for the analysis that we would like to perform on it.\n\nA DataFrame may have larger structural problems that extend beyond the data.\nPerhaps the DataFrame stores its values in a format that makes it easy to extract a single row but difficult to aggregate the data.\n\nReshaping a DataFrame means manipulating it into a different shape.\nIn this section, we will discuss pandas techniques for molding a DataFrame into the shape we desire."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#long-vs.-wide-dataframes",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#long-vs.-wide-dataframes",
    "title": "Lecture 12",
    "section": "Long vs. Wide DataFrames",
    "text": "Long vs. Wide DataFrames\n\n\nThe following DataFrames measure temperatures in two cities over two days.\n\n\nimport pandas as pd\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\ndf_wide = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday'],\n    'Miami': [80, 83],\n    'Rochester': [57, 62],\n    'St. Louis': [71, 75]\n})\n\ndf_long = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Wednesday'],\n    'City': ['Miami', 'Miami', 'Rochester', 'Rochester', 'St. Louis', 'St. Louis'],\n    'Temperature': [80, 83, 57, 62, 71, 75]\n})"
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#long-vs.-wide-dataframes-1",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#long-vs.-wide-dataframes-1",
    "title": "Lecture 12",
    "section": "Long vs. Wide DataFrames",
    "text": "Long vs. Wide DataFrames\n\nA DataFrame can store its values in wide or long format.\nThese names reflect the direction in which the data set expands as we add more values to it.\n\nA long DataFrame increases in height.\nA wide DataFrame increases in width."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#long-vs.-wide-dataframes-2",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#long-vs.-wide-dataframes-2",
    "title": "Lecture 12",
    "section": "Long vs. Wide DataFrames",
    "text": "Long vs. Wide DataFrames\n\nThe optimal storage format for a DataFrame depends on the insight we are trying to glean from it.\n\nWe consider making DataFrames longer if one variable is spread across multiple columns.\nWe consider making DataFrames wider if one observation is spread across multiple rows."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-3",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-3",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nmelt() and pivot()\n\n\n\n\nmelt() makes DataFrame longer.\npivot() makes DataFrame wider."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#make-dataframe-longer-with-melt",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#make-dataframe-longer-with-melt",
    "title": "Lecture 12",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#make-dataframe-longer-with-melt-1",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#make-dataframe-longer-with-melt-1",
    "title": "Lecture 12",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the “identifier”."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#make-dataframe-longer-with-melt-2",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#make-dataframe-longer-with-melt-2",
    "title": "Lecture 12",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#make-dataframe-wider-with-pivot",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#make-dataframe-wider-with-pivot",
    "title": "Lecture 12",
    "section": "Make DataFrame Wider with pivot()",
    "text": "Make DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-4",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-4",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet’s consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-5",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-5",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet’s consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2022\": [1, 2, 3, 1],\n             \"2023\": [2, 3, 4, 2],\n             \"2024\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-6",
    "href": "danl-lec/danl-299-lec-12-2025-1008.html#reshaping-dataframes-6",
    "title": "Lecture 12",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet’s do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-1",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-1",
    "title": "Lecture 13",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more DataFrames based on common data values in those DataFrames.\n\nThis task is known in the database world as performing a “join.”\nWe can do this with the merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-2",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-2",
    "title": "Lecture 13",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nJoin, Relational Data, and Keys\n\n\n\n\n\n\n\n\nThe variables that are used to connect each pair of DataFrames are called keys.\nEach observation in a DataFrame is often uniquely identified by key variable(s).\nThe key variable enables relationships between the DataFrames to be defined."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the “key” variable.\nThe grey column represents the “value” variable."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-1",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-1",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nInner Join\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n# the default value for 'how' is 'inner'\n# so it doesn't actually need to be specified\nmerge_inner_1 = pd.merge(x, y, on='key')\nmerge_inner_2 = pd.merge(x, y, on='key', how='inner')\nmerge_inner_3 = x.merge(y, on='key')\nmerge_inner_4 = x.merge(y, on='key', how='inner')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-2",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-2",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLeft Join\n\nA left join keeps all observations in x.\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-3",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-3",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nRight Join\n\nA right join keeps all observations in y.\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-4",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-4",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nOuter (Full) Join\n\nA full join keeps all observations in x and y.\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-5",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-5",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: one-to-many\n\nOne DataFrame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key':[1, 2, 2, 3],\n    'val_x':['x1', 'x2', 'x3', 'x4']})\n\ny = pd.DataFrame({\n    'key':[1, 2],\n    'val_y':['y1', 'y2'] })\none_to_many = x.merge(y, on='key', \n                         how='left')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-6",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-6",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: many-to-many\n\nBoth DataFrames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key':[1, 2, 2, 3],\n  'val_x':['x1','x2','x3','x4']})\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', \n                          how='left')\n\n\n\nIn practice, it is better to avoid the many-to-many join."
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-7",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-7",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDefining the key columns\n\n\nIf the left and right columns do not have the same name for the key variables, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = \n  x.merge(y, left_on = 'key_x', \n             right_on = 'key_y', \n             how = 'left')"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-8",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#joining-dataframes-with-merge-8",
    "title": "Lecture 13",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLet’s do Part 2 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-1",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-1",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\n\nConcatenation involves combining multiple DataFrames by adding rows or columns. This method is useful:\n\nWhen merging datasets that were split into parts;\nWhen appending new data to an existing dataset.\n\nLet’s consider the following example DataFrames:\n\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-2",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-2",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nConcatenating the DataFrames on top of each other uses the concat() method.\n\nrow_concat = pd.concat([df1, df2, df3])\n\n\nAll of the DataFrames to be concatenated are passed in a list.\n\npd.concat( [DataFrame_1, DataFrame_2, ... , DataFrame_N] )"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-3",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-3",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nConcatenating columns is very similar to concatenating rows.\n\nThe main difference is the axis parameter in the concat() method.\nThe default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion.\nIf we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\n\n\npd.concat([df1, df2, df3], axis = \"columns\")\npd.concat([df1, df2, df3], axis = \"columns\", ignore_index = True)  \n\nignore_index=True to reset the column indices"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-4",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-4",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd a Series?\n\n\nLet’s consider a new Series and concatenate it with df1:\n\n# create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\n\n# attempt to add the new row to a DataFrame\ndf = pd.concat([df1, new_row_series])\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-5",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-5",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd a Series?\n\n\nTo fix the problem, we need turn our Series into a DataFrame.\n\nThis DataFrame contains one row of data, and the column names are the ones the data will bind to.\n\n\nnew_row_df = pd.DataFrame(\n  # note the double brackets to create a \"row\" of data\n  data =[ [\"n1\", \"n2\", \"n3\", \"n4\"] ],\n  columns = df1.columns,\n)\n\ndf = pd.concat([df1, new_row_df])\n\n\nHow about this?\n\npd.concat([df1, new_row_series], axis = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-6",
    "href": "danl-lec/danl-299-lec-13-2025-1008.html#data-concatenation-6",
    "title": "Lecture 13",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet’s do Part 3 of Classwork 7!"
  }
]