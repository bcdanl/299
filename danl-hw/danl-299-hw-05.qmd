---
title: Homework 5
subtitle: Pandas Group Operations
date: 2026-02-07
from: markdown+emoji
format:
  html:
    code-fold: true
execute: 
  eval: false
language: 
  code-summary: "Click to Check the Answer!"
---

```{r}
#| include: false
#| eval: true

library(tidyverse)
```


# Direction

- Please email your **Python Script** for **Part 1 and Part 2 in Homework 5** with the name below:

  - `danl_210_hw5_LASTNAME_FIRSTNAME.py`\
  ( e.g., `danl_210_hw5_choe_byeonghak.py` )

- The due for **Part 1 and Part 2 in Homework 5** is February 25, Wednesday, 2026, 11:59 P.M.

- The due for **Part 3 in Homework 5** is February 28, Saturday, 2026, 11:59 P.M.

- Please send Prof. Choe an email ([bchoe@geneseo.edu](mailto::bchoe@geneseo.edu)) if you have any questions.

<br>

# Part 1. Spotify Data with Group Operation

<br>
<p align="center">
  <img src="https://bcdanl.github.io/lec_figs/spotify.png" width="400px">
</p>

<br>

Below is `spotify` `DataFrame` that reads the file `spotify_all.csv` containing data of Spotify users' playlist information (Source: [Spotify Million Playlist Dataset Challenge](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge)).

```{.python}
spotify = pd.read_csv('https://bcdanl.github.io/data/spotify_all.csv')
```


```{r}
#| eval: true
#| echo: false
#| warning: false

rmarkdown::paged_table(readr::read_csv('https://bcdanl.github.io/data/spotify_all.csv'),
                       options = list(rows.print = 25))
```

<br>

## Variable Description

- `pid`: playlist ID; unique ID for playlist
- `playlist_name`: a name of playlist
- `pos`: a position of the track within a playlist (starting from 0)
- `artist_name`: name of the track’s primary artist
- `track_name`: name of the track
- `duration_ms`: duration of the track in milliseconds
- `album_name`: name of the track’s album


## Definition of a Song
- In Part 2, a **song** is defined as a combination of a `artist_name` value and a `track_name` value.

- E.g., the following provides the 12 distinct songs with the same `track_name`---**I Love You**:

```{r}
#| eval: true
#| echo: false
#| warning: false

library(tidyverse)

rmarkdown::paged_table(
  read_csv('https://bcdanl.github.io/data/spotify_all.csv') |> 
  count(artist_name, track_name) |> 
  filter(track_name == 'I Love You') |> 
  select(-n), 
  options = list(rows.print = 12)
)
```

<br>

## Question 1
Write code with pandas `groupby()` to calculate the total duration (in minutes) of each playlist and then sort by the total duration in descending order to identify the playlists from longest to shortest total playtime.


<br>


## Question 2

Write code with pandas `groupby()` to identify the top five songs with the highest frequency of appearances in the `spotify` DataFrame.

<br>

## Question 3

- Write code with pandas `groupby()` to create a DataFrame that contains information about how often each song occurs within the `spotify` DataFrame.
  - In this new DataFrame, each observation should represent a distinct song.

- Then, identify top 5% songs based on their frequency of appearances.



<br>


## Question 4
Write code with pandas `groupby()` to list all artists who have more than 50 unique songs in the `sportify` DataFrame.

<br>




## Question 5
Write code with pandas `groupby()` to create a DataFrame that identifies all the playlists featuring the song "One Dance" by Drake.



<br>

## Question 6
Write code with pandas `groupby()` to identify the longest and shortest duration songs (based on `duration_ms`) for each unique artist.

<br>



## Question 7
Write code with pandas `groupby()` to find the same song(s) appearing more than once in the same playlist.



<br>



## Question 8
Write code with pandas `groupby()` to filter all songs that appear in more than 100 different playlists.


<br><br>


# Part 2. Shoes Online Shoping


<br>
<p align="center">
  <img src="https://bcdanl.github.io/lec_figs/shoes-online.png" width="600px">
</p>

<br>


Below is `shoes` `DataFrame` that reads the file `onlinestore_shoes_simple.csv` containing data of "shoes" search information from an online store.

```{.python}
shoes = pd.read_csv('https://bcdanl.github.io/data/onlinestore_shoes_simple.csv')
```

```{.python}
import pandas as pd
import numpy as np
shoes = pd.read_csv('https://bcdanl.github.io/data/onlinestore_shoes_simple.csv')
```

```{r}
#| eval: true
#| echo: false
#| warning: false

df <- read_csv('https://bcdanl.github.io/data/onlinestore_shoes_simple.csv')

rmarkdown::paged_table(df,
                       options = list(rows.print = 25))
```


## Variable Description

| Variable                          | Description                                                                 |
|----------------------------------|-----------------------------------------------------------------------------|
| `id`                             | Unique identifier for the product                                           |
| `brandId`                        | Unique identifier for the brand                                            |
| `brandName`                      | Name of the brand                                                          |
| `name`                           | Product name or title                                                      |
| `reviewCount`                    | Number of customer reviews                                                 |
| `reviewStarRating`               | Average star rating from customer reviews                                  |
| `current_p`                      | Current price                   |
| `clearance_p`                    | Clearance price  (`NA` if not available for clearance)           |

- If the product is **on clearance**, the product’s `current_p` equals its `clearance_p`.

<br>



## Question 9
Add a new variable `discount_pct` to the `shoes` DataFrame that shows the percentage markdown for clearance items (0 % for non-clearance).

$$
(\text{Discount Percentage}) = 100 \times \frac{(\text{Current Price}) - (\text{Clearnace Price})}{(\text{Current Price})}
$$

- Note that the value of `discount_pct` is zero for all observations.



<br>



## Question 10
For each brand, compute the interquartile range (IQR) of its `current_p`.


<br>

## Question 11
List the top 20 brands with the highest average star rating, considering only brands that have at least 1000 reviews total.



<br>

## Question 12
For each brand, compute the proportion of products on clearance. Return the result sorted from highest to lowest proportion.



<br>


## Question 13
For every brand, calculate the correlation between product price (`current_p`) and star rating. Keep only brands with more than 100 products.


<br>

## Question 14
Identify "premium" products inside each brand as those priced above the 90th percentile of that brand. Among these premium items, what fraction are on clearance overall?


<br>

## Question 15

After binning `current_p` into price quartiles with `pd.qcut()`, count the number of clearance products for each brand–quartile combination.


- Below explains `pd.qcut()`:
```{.python}
shoes["price_qtile"] = pd.qcut(shoes["current_p"], 4, labels=["Q1","Q2","Q3","Q4"])
```

1.	`pd.qcut(shoes["current_p"], 4, …)`
	-	`qcut` stands for "quantile cut."
	-	Given the series of prices, it computes the 0th, 25th, 50th, 75th, and 100th percentiles.
	-	It then assigns each product to one of four bins so that each bin contains (as close as possible to) the same number of products.
2.	`labels=["Q1","Q2","Q3","Q4"]`
	-	Instead of getting the default interval‐notation (e.g. (10.0, 25.5]), each bin is labeled "Q1" through "Q4."
	-	"Q1" will be the lowest 25% of prices, "Q2" the next 25%, and so on, up to "Q4" for the top‐priced 25%.
3.	Assignment into `shoes["price_qtile"]`
	-	The result is a categorical variable in your `shoes` DataFrame.
	-	You can now easily group or filter by "Q1", "Q2", etc., rather than working with numeric cut‐points.
	

<br>

## Question 16
- For each brand in the `shoes` DataFrame, add a new variable `rev_scaled` that re-scales `reviewCount` to the [0, 1] range.
  - The product with the highest `reviewCount` within its brand has a value 1 in the `rev_scaled` variable.
  - The product with the lowest `reviewCount` within its brand has a value 0 in the `rev_scaled` variable.



<br><br>

# Part 3: Enhance Your Blogs with Data Visualizations

> **Tip:** Consider using generative AI to polish your visualizations.

## Spotify Blog (Homework 2)

Add the following section to your **Spotify** blog:

- **Code**  
  1. Use pandas to identify the ten artists with the most tracks.  
  2. Use seaborn to plot the distribution of `pos` for each of those artists.
- **Description**  
  Write 2–3 sentences explaining how the `pos` distribution differs across these top ten artists.

## Holiday Movie Blog (Homework 3)

Add the following section to your **Holiday Movie** blog:

- **Code**  
  1. Use pandas to select the five genres with the highest film counts.  
  2. Use numpy to add a new variable, log of `num_votes`.
  3. Use seaborn to plot the relationship between log of `num_votes` and `average_rating`, grouping by genre and coloring or faceting by `title_type`.
- **Description**  
  Write 2–3 sentences describing how the log of `num_votes` vs. `average_rating` relationship varies among the top five genres and between different `title_type`s.
